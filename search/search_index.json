{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#recent-updates","title":"Recent Updates","text":"<ul> <li>VSCode Server</li> <li>Ghost CMS</li> <li>RuTorrent</li> <li>Invidious</li> <li>Ghost CMS Docker</li> <li>yt-dlp oauth</li> <li>Uptime Kuma</li> <li>Tunneling Minecraft Server TCP/UDP Geyser with Nginx</li> <li>YouTube Archive</li> <li>Webtop (openbox-ubuntu)</li> </ul>"},{"location":"mkdocs/","title":"Mkdocs","text":""},{"location":"mkdocs/#mkdocs-gotchas","title":"Mkdocs Gotchas","text":"<ul> <li><code>yaml</code> highlighting is broken with <code>mdx-breakless-lists</code></li> <li>when using heading <code>#</code>, if there are no line breaks between headings, any lists that is after content of the second heading will not be rendered properly, even with <code>mdx-breakless-lists</code></li> <li>furthermore, if using lists right after a <code>yaml</code> code block, the list will also not be rendered correctly</li> <li></li> <li>when referencing a subheading in another file, mkdocs uses <code>[](file.md#heading-with-space)</code> while obsidian uses <code>[](file.md#heading%20with%20space)</code></li> <li>Before switching from lists to normal content, a line break is needed, otherwise the text below will be rendered with a indent</li> <li>mkdocs subheadings <code>[](#subheadings)</code> must be in lower case</li> </ul>"},{"location":"mkdocs/#admonitioncallouts","title":"Admonition/Callouts","text":"Mkdocs native callout <p>callout content mkdocs</p> <p>Nested</p> <p>Nesting</p> <ul> <li><code>???</code> is also valid syntax for mkdocs</li> <li><code>???+</code> makes the callout collapsible and opens by default, while <code>???-</code> makes it closed by default <pre><code>!!! notes \"Title\"\n    content\n</code></pre> Obsidian callouts requires the plugin <code>mkdocs-callouts</code></li> </ul> Obsidian Native Callout <p>Callout content mkdocs</p> <p>Nested callout</p> <p>callout</p> <pre><code>&gt; [!notes]+/- Callout title\n&gt; Callout content\n</code></pre> <ul> <li>obsidian callout syntax also follows the same <code>+</code>,<code>-</code> for collapsing, it is to be inserted after the brackets</li> </ul> <p>Available callouts include <code>notes</code>, <code>info</code>, <code>warning</code>, <code>danger</code>, <code>success</code>, <code>failure</code>, <code>example</code>, <code>abstract</code>, <code>tip</code>, <code>question</code>, <code>bug</code>.  </p>"},{"location":"mkdocs/#keys-caret-mark-tilde","title":"Keys, Caret, Mark, Tilde","text":"<p>Keys <code>++ctrl+alt+plus++</code> Ctrl+Alt++ mark highlighting tilde strikethrough</p>"},{"location":"mkdocs/#tabbed-content","title":"Tabbed Content","text":"Tab 1Tab 2 <p>Tab 1 content mkdocs Second line here.</p> <p>Tab 2 content</p> <p><pre><code>=== \"Tab Name\"\n    Tab content\n</code></pre> </p> <ul> <li>not supported in obsidian</li> </ul>"},{"location":"mkdocs/#attr_list","title":"attr_list","text":"<p>Fancy Buttons mkdocs <code>[button text](link.md){ .md-button }</code> Tooltip I\u2019m a tooltip that you can hover or click. <code>[tooltip](https://link \"hover text\")</code> Annotation I\u2019m an annotation, but you need to click the plus icon (1) to show. (2) </p> <ol> <li>annotation 1</li> <li>annotation 2 <pre><code>Annotation location 1 (1), location (2)\n{ .annotate }\n1. annotation text to be shown\n</code></pre> </li> </ol> <p>Footnote Insert footnote like <code>[^1]</code> <sup>1</sup></p> <ul> <li>for inserting footnote <code>[^1]</code></li> <li><code>[^1]:</code> at the end to explain the footnote; not supported in obsidian</li> </ul>"},{"location":"mkdocs/#code-highlighting","title":"Code Highlighting","text":"<pre><code>from python import python\npython.run(arg1=123, arg2=\"mystr\")[2]\n</code></pre> <pre><code>#!/bin/bash\nvar=\"myvar\"\necho $var+3\n</code></pre> <pre><code># yaml highlighting has to be `yaml` not `yml` and it's broken\n---\nversion: \"2.1\"\nservices:\n  clarkson:\n    image: lscr.io/linuxserver/clarkson\n    container_name: clarkson\n    environment:\n\n      - PUID=1000\n      - PGID=1000\n    ports:\n      - 3000:3000\n    restart: unless-stopped\n</code></pre> <ol> <li> <p>explaining the footnote.\u00a0\u21a9</p> </li> </ol>"},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-tailscale/","title":"Basic Server Setup, Caddy, Docker, Tailscale","text":""},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-tailscale/#basics","title":"Basics","text":""},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-tailscale/#creating-the-vm-in-oracle-cloud","title":"Creating the VM in oracle cloud","text":"<ol> <li>Go to instances, new instance.</li> <li>Select the Always Free image, ARM or x86, recommended 4GB RAM.</li> <li>Choose Ubuntu image.</li> <li>Download the SSH key and name it accordingly.</li> </ol>"},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-tailscale/#ssh-keys","title":"SSH Keys","text":"<p>Using PuttyGen.</p> <ul> <li>Place the key in <code>./ssh/openssh_keys</code></li> <li>Open PuttyGen, conversion -&gt; import keys</li> <li>Save the key files as ppk file in root folder of <code>./ssh</code></li> </ul> <p>Putty</p> <ul> <li>Grab the IP address in the cloud console</li> <li>Give a name in saved sessions</li> <li>Go to behavior, choose these options</li> <li>Under Data, make sure Terminal-type string is xterm-256color</li> <li>Under Terminal -&gt; Features, check \u201cdisable application keypad mode\u201d to fix issues with nano</li> <li>The private key needs to be load in Connection -&gt; SSH -&gt; Auth -&gt; Credentials</li> </ul> <p></p> <p></p> <p>To get the IP address of the VPS at any time</p> <pre><code>curl ifconfig.me\n</code></pre> <p>Useful packages to install <pre><code>htop iotop iftop fio curl gnupg wget neofetch ca-certificates lsb-release fzf screen firewalld net-tools bash-completion\n</code></pre></p>"},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-tailscale/#docker","title":"Docker","text":"<p>https://docs.docker.com/engine/install/ubuntu/ <pre><code>sudo apt-get update\nsudo apt-get install \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n\nsudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin docker-compose\n</code></pre></p> <pre><code>sudo groupadd docker \\\nsudo usermod -aG docker ubuntu\nnewgrp docker # activate docker group immediately\n</code></pre> <p>The machine needs to be rebooted from Oracle Cloud console to finish installation.</p>"},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-tailscale/#caddy","title":"Caddy","text":""},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-tailscale/#docker-version-install","title":"Docker Version Install","text":"<p>Detailed information on installing Caddy has moved to caddy If Nginx is installed alongside Caddy, it needs to be changed to listen on port 81 instead. <pre><code>sudo nano /etc/nginx/sites-enabled/default\n</code></pre></p> <ul> <li>change the <code>server</code> block\u2019s <code>listen</code> from 80 to 81 <pre><code>sudo service nginx restart\n</code></pre></li> </ul>"},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-tailscale/#port-forwarding","title":"Port Forwarding","text":"<p>On the Oracle Cloud side, login and go to <code>Virtual Cloud Networks</code>, click the one that\u2019s available, then the default subnet, this will bring up the <code>Security Lists</code> </p> <ul> <li>this is an example of SSH port, configure by <code>Add Ingress Rules</code> and add the ports accordingly; it\u2019s also possible to allow everything and install a firewall in the OS itself</li> </ul> <p>On the Linux machine, either use <code>iptables</code> or <code>firewall-cmd</code></p> Firewall-cmd (recommended)iptables <pre><code>sudo firewall-cmd --zone=public --add-port 19132/tcp --permanent\nsudo firewall-cmd --zone=public --add-port 19132/udp --permanent\nsudo firewall-cmd --zone=public --add-port 25565/tcp --permanent\nsudo firewall-cmd --zone=public --add-port 25565/udp --permanent\nsudo firewall-cmd --zone=public --add-port 80/tcp --permanent\nsudo firewall-cmd --zone=public --add-port 443/tcp --permanent\nsudo firewall-cmd --zone=public --add-port 5800/tcp --permanent\nsudo firewall-cmd --reload\n</code></pre> <p><code>sudo iptables -I INPUT 6 -m state --state NEW -p tcp --dport 443 -j ACCEPT sudo iptables -I INPUT 6 -m state --state NEW -p tcp --dport 80 -j ACCEPT sudo iptables -I INPUT 6 -m state --state NEW -p tcp --dport 25565 -j ACCEPT sudo iptables -I INPUT 6 -m state --state NEW -p tcp --dport 19132 -j ACCEPT sudo iptables -I INPUT 6 -m state --state NEW -p udp --dport 25565 -j ACCEPT sudo iptables -I INPUT 6 -m state --state NEW -p udp --dport 19132 -j ACCEPT sudo iptables -I INPUT 6 -m state --state NEW -p udp --dport 51820 -j ACCEPT sudo netfilter-persistent save</code> ^4f1e6a</p>"},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-tailscale/#troubleshooting","title":"Troubleshooting","text":"<p>For firewall-cmd, use this command to check all open ports.</p> <pre><code>sudo firewall-cmd --list-all\n</code></pre> <p>Using netstat, or pipe it to grep</p> <pre><code>netstat -tln\n# | grep 8080 etc...\n</code></pre>"},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-tailscale/#tailscale","title":"Tailscale","text":"<p>Installation and setup of basic services is covered in tunneling basic services. For usage such as exit-node and subnet-routes.</p>"},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-tailscale/#exit-nodesubnet-routes","title":"Exit Node/Subnet Routes","text":"<p>First need to enable IP forwarding. <pre><code>echo 'net.ipv4.ip_forward = 1' | sudo tee -a /etc/sysctl.conf\necho 'net.ipv6.conf.all.forwarding = 1' | sudo tee -a /etc/sysctl.conf\nsudo sysctl -p /etc/sysctl.conf\n</code></pre> When using with firewalld, additional configuration is needed such as masquerade. <pre><code>sudo firewall-cmd --add-masquerade --zone=public --permanent \nsudo firewall-cmd --add-interface=tailscale0 --zone=trusted --permanent\nsudo firewall-cmd --reload\n</code></pre> Basic command to advertise as exit-node and subnet routes <pre><code>sudo tailscale up --advertise-exit-node --advertise-subnet-routes=10.10.120.0/24\n</code></pre> When connect tailscale in CLI, additional arguments is needed to accept routes (the command below also activate exit node) <pre><code>sudo tailscale up --advertise-exit-node --accept-routes\n</code></pre> To enable these features, need to go to admin console, go to each machine settings, <code>Edit Route Settings</code> and enable exit-node or subnet routes.</p>"},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-tailscale/#advanced","title":"Advanced","text":"<p>Tunneling Jellyfin and other web services with tailscale and caddy</p> <p>Minecraft Tunneling</p>"},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-tailscale/#archived","title":"Archived","text":"<p>Basic Setup + Docker</p> <ol> <li>Installing Caddy web server (simple to use reverse proxy), lightweight, easy and no need for docker. (Nginx is also a good candidate for reverse proxy as the command is easy to memorize and does not require consulting documentation sites. However, the syntax for nginx is extremely complex compared to caddy and might not be easily memorized.</li> </ol> <p>https://caddyserver.com/docs/install#debian-ubuntu-raspbian</p> <pre><code>sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy net-tools\n# net-tools is good utility, optionally can install firewall-cmd or nginx\n# sudo apt install firewalld nginx\n</code></pre> <p>Basic Caddy Syntax (if applicable) If the server that is being setup or restored needs functional service like bookstack or uptime-kuma, reverse proxy is needed. <pre><code>sudo nano /etc/caddy/Caddyfile\n</code></pre></p> <pre><code>{\n    email weebly2x10@gmail.com\n}\n\nyour-uptime-kuma.yoursubdomain.duckdns.org {\n        reverse_proxy http://127.0.0.1:3001\n}\n\nwiki.yoursubdomain.duckdns.org {\n        reverse_proxy http://127.0.0.1:6975\n}\n</code></pre>"},{"location":"Cloud%20VPS/jdownloader/","title":"JDownloader","text":""},{"location":"Cloud%20VPS/jdownloader/#basic-setup","title":"Basic Setup","text":""},{"location":"Cloud%20VPS/jdownloader/#configuring-jdownloader","title":"Configuring JDownloader","text":"<ul> <li>Go to the JDownloader WebUI</li> <li>Go to Settings</li> <li>Under general, change the max number of downloads (2) and DL per hoster (1) to minimize issues</li> </ul> <ul> <li>Go to MyJDownloader and configure MyJDownloader account</li> </ul> <ul> <li>Go to extension modules, install and enable \u201cfolderwatch\u201d</li> </ul> <p>The configuration for JDownloader is complete and should appear and be functional in WebUI. Advanced JDownloader documentation will be covered in detailed in another section. It is recommended to close port 5800 after configuring to prevent others accessing.</p> <p>After setting up JDownloader and it appears well in WebUI.</p> <p>The section is useless now as UHDMV has shutdown and it\u2019s pointless to setup multiple automated JDownloader server on VPS.</p>"},{"location":"Cloud%20VPS/jdownloader/#settings-for-jdownloader","title":"Settings for JDownloader","text":"<p>Debloat settings  https://rentry.org/jdownloader2 Advanced Settings <code>GraphicalUserInterfaceSettings: Banner</code> -&gt; disable <code>GraphicalUserlnterfaceSettings: Premium Alert Task Column</code> - &gt; disable <code>GraphicalUserInterfaceSeftings: Premium Alert Speed Column</code> -&gt; disable <code>GraphicalUserInterfaceSettings: Premium Alert ETA Column</code> -&gt; disable <code>GraphicalUsserInterfaceSeftings: Special Deal Oboom Dialog Visible On Startup</code> -&gt; disable <code>GraphicalUsserInterfaceSeftings: Special Deals</code>\u00a0-&gt; disable <code>GraphicalUsserInterfaceSeftings: Donate Button State</code>\u00a0-&gt; <code>Hidden (automode)</code></p>"},{"location":"Cloud%20VPS/jdownloader/#theming","title":"Theming","text":"<p><code>GraphicalUserInterfaceSettings: Look And Feel Theme</code> - &gt; <code>BLACK_EYE</code> For Colors <code>LAFSettings: Color For</code></p> <ul> <li>Panel background and header background and alternate row background- <code>#ff222222</code></li> <li>Selected Rows Background - <code>#ff666666</code></li> <li>Package Row Background - <code>#ff333333</code></li> <li>Mouse Over Row Background - <code>#ff666666</code></li> <li>Panel Header Foreground, Tooltip Foreground, Selected Rows Foreground, Package Row Foreground, Mouse Over Row Foreground, Alternate Row Foreground,  Account Temp Error Row Foreground, Account Error Row Foreground- <code>#ffffffff</code><ul> <li>basically, change all the black values to white when searching for <code>color fore</code>, change everything except blue colors and error color</li> </ul> </li> <li>Enabled Text Color, Speed Meter Text, Speed Meter Average Text, Config Panel Description Text, Config Header Text Color - <code>#ffffffff</code></li> <li>Disabled Text Color - <code>#ff666666</code><ul> <li>basically, when searching for <code>color text</code>, change all to white except for disabled text</li> </ul> </li> </ul>"},{"location":"Cloud%20VPS/tunneling-basic-services-jellyfin-web-with-caddy-and-tailscale/","title":"Tunneling Basic Services (Jellyfin, Web) with Caddy and Tailscale","text":"<p>This procedure is not reproducible yet. Rigorous testing is still required before being documented. Here are the known procedures.</p> <p>The purpose is to tunnel normal web or network intensive traffic such as Jellyfin when faced with CG-NAT or similar situations (in this case locked down dorm internet), also configure hardware transcoding (in this case NVENC, but Intel QSV for future) to mitigate limitations with Canadian ISP(s).</p>"},{"location":"Cloud%20VPS/tunneling-basic-services-jellyfin-web-with-caddy-and-tailscale/#jellyfin","title":"Jellyfin","text":""},{"location":"Cloud%20VPS/tunneling-basic-services-jellyfin-web-with-caddy-and-tailscale/#install","title":"Install","text":"<p>https://jellyfin.org/downloads/server Download and run the server installer. Configure Jellyfin to your liking.</p>"},{"location":"Cloud%20VPS/tunneling-basic-services-jellyfin-web-with-caddy-and-tailscale/#tailscale","title":"Tailscale","text":""},{"location":"Cloud%20VPS/tunneling-basic-services-jellyfin-web-with-caddy-and-tailscale/#windows","title":"Windows","text":"<p>https://tailscale.com/download/windows Download, install and login.</p>"},{"location":"Cloud%20VPS/tunneling-basic-services-jellyfin-web-with-caddy-and-tailscale/#linux","title":"Linux","text":"<pre><code>curl -fsSL https://tailscale.com/install.sh | sh\n</code></pre> <pre><code>sudo tailscale up\n</code></pre> <p>All the tailscale management is done in the WebUI.</p> <p></p> <p>The Windows client is given a tailscale network IP address in 100 range. Check if Windows client is pingable on server.</p> <pre><code>ping 100.x.y.z #100.79.28.31\n</code></pre> <p>Check if Jellyfin is running and tunneled properly on Oracle cloud. It should get a webpage html rather than unable to resolve host etc.</p> <pre><code>curl http://100.x.y.z:8096\n</code></pre>"},{"location":"Cloud%20VPS/tunneling-basic-services-jellyfin-web-with-caddy-and-tailscale/#reverse-proxy","title":"Reverse Proxy","text":"<p>basic-server-setup-caddy-docker-tailscale</p> <p>Caddy installation and syntax is can be found on this page. Replace 127.0.0.1 with the tailscale IP address.</p> <pre><code>{\n    email weebly2x10@gmail.com\n}\n\nmovies.yoursubdomain.duckdns.org {\n        reverse_proxy http://100.x.y.z:8096\n}\n</code></pre> <p>It is possible to set use the root domain (yoursub.duckdns.org) or a subfolder domain (movies.yousub.duckdns.org) for Jellyfin. After configuring the Caddyfile.</p> <pre><code>sudo systemctl reload caddy\n</code></pre> <p>Use netstat to check port 80, 443 is being listened. Make sure to port forward Oracle VPS.</p> <p>Other Services</p> <p>Follow the same syntax as the caddy file provided, if the root domain is used, then a subdomain must be used for other services.</p> <p>Results</p> <p>Inconclusive yet, more testing required.</p>"},{"location":"Cloud%20VPS/tunneling-minecraft-server-tcp-only-with-nginx/","title":"Tunneling Minecraft Server TCP/UDP Geyser with Nginx","text":"<p>After setting up the VPS and configuring Tailscale. Ensure hosts are connectible via <code>ping &lt;tailscale-ip&gt;</code>.</p>"},{"location":"Cloud%20VPS/tunneling-minecraft-server-tcp-only-with-nginx/#nginx","title":"Nginx","text":"<p><pre><code>sudo apt install nginx # Install Nginx\n</code></pre> Change default port to listen to <code>81</code> (this is not needed if another reverse proxy is installed or needed). Edit the <code>listen 80</code> to <code>listen 81</code>. The line after is not relevant if not using IPv6. In the case of Oracle Cloud, only IPv4 is used. <pre><code>sudo nano /etc/nginx/sites-enabled/default\n</code></pre> <pre><code>server {\n        listen 81 default_server;\n        listen [::]:81 default_server;\n</code></pre></p>"},{"location":"Cloud%20VPS/tunneling-minecraft-server-tcp-only-with-nginx/#configuration","title":"Configuration","text":"<p>Edit <code>/etc/nginx/nginx.conf</code> add these these <code>stream</code> lines <pre><code>sudo nano /etc/nginx/nginx.conf\n</code></pre> <pre><code>stream {\n     server {\n           listen 25565;\n           proxy_pass &lt;tailscale_ip&gt;:25565;\n    }\n    server {\n           listen 19132 udp;\n           proxy_pass &lt;tailscale_ip&gt;:19132;\n    }\n}\n</code></pre></p> <ul> <li>it is also possible to add <code>25565 udp</code></li> </ul> <p>Reload nginx if required. <pre><code>sudo service reload nginx\n</code></pre></p>"},{"location":"Cloud%20VPS/tunneling-minecraft-server-tcp-only-with-nginx/#firewall","title":"Firewall","text":"<p>Allow firewall connection. First ensure firewall-cmd is installed. If not, install the package <code>firewalld</code>. <pre><code>sudo firewall-cmd --zone=public --add-port 19132/tcp --permanent\nsudo firewall-cmd --zone=public --add-port 19132/udp --permanent\nsudo firewall-cmd --zone=public --add-port 25565/tcp --permanent\nsudo firewall-cmd --zone=public --add-port 25565/udp --permanent\nsudo firewall-cmd --reload\n</code></pre></p>"},{"location":"Cloud%20VPS/tunneling-minecraft-server-tcp-only-with-nginx/#results","title":"Results","text":"<p>In Minecraft client, by typing the public IP address of the Oracle Cloud it will connect. It\u2019s also an option to use Duckdns to make the cloud IP address more recognizable. </p> <p>The server address is permanent and unchanging.</p> <p>The performance depends on the location of VPS. There will be significant loss in responsiveness if the tunnel VPS is far away from the host server.  In this example, the host server is in Vancouver while the VPS is located in Toronto (3500/7000km). The round-trip to connect to the tunneled server added 150ms of latency (from Minecraft mobile app), the speed difference is also visualized in the image above. There is no difference between the <code>/tps</code> command as in both cases it\u2019s 20 all around.</p>"},{"location":"Computer%20Stuff/demucs-nvidia/","title":"Demucs Nvidia","text":"<p>Demucs is an music separation tool that has potential for a karaoke setup.</p> <p>https://github.com/facebookresearch/demucs</p> <p>https://www.youtube.com/watch?v=9QnFMKWEFcI&amp;t=585s</p> <p>https://docs.google.com/document/d/1XMmLrz-Tct1Hdb_PatcwEeBrV9Wrt15wHB1xhkB2oiY/edit</p> <p>Installation on PC with Nvidia</p> <ol> <li>Firstly install Anaconda. Download Anaconda for Windows https://www.anaconda.com/products/distribution</li> <li>Install PyTorch. https://pytorch.org/get-started/locally/. Select the correct version of pytorch.</li> <li>Install ffmpeg. [https://www.gyan.dev/ffmpeg/builds/]](assets/gallery/2022-12/TwJimage.png)</li> </ol> <p>Demucs</p> <p>After installing the prerequesties.</p> <p>Open \u201cAnaconda terminal\u201d and type</p> <pre><code>python.exe -m pip install -U demucs\n</code></pre> <pre><code>pip install PySoundFile \n</code></pre> <p>Running Demucs</p> <pre><code>demucs \"C:\\path\\to\\music\\file.mp3\"\n</code></pre> <p>This will run demucs with CUDA GPU acceleration, make sure to put the path in double quote. The extracted file will be found in the directory where you run the command eg. the default Anaconda prompt starts in ~/separated</p>"},{"location":"Computer%20Stuff/yt-dlp%20oauth/","title":"yt-dlp oauth","text":"<p>Using yt-dlp may need oauth2 plugin in order to use on VPS or download private videos.</p>"},{"location":"Computer%20Stuff/yt-dlp%20oauth/#linux","title":"Linux","text":"<p>Download https://github.com/coletdjnz/yt-dlp-youtube-oauth2/releases Add the zip file into this folder, make it if not exist <code>mkdir -p</code> <pre><code>~/.yt-dlp/plugins\n</code></pre> Then run <code>yt-dlp -v</code> and make sure <code>oauth2</code> appears in the log.</p>"},{"location":"Computer%20Stuff/yt-dlp%20oauth/#setup","title":"Setup","text":"<p><pre><code>yt-dlp --username oauth2 --password '' https://youtube.com/private-video\n</code></pre> It will prompt to go to https://www.google.com/device to enter a code.</p> <p>After registered device, setup <code>.netrc</code> and add these contents <pre><code>touch ${HOME}/.netrc\nchmod a-rwx,u+rw ${HOME}/.netrc\n</code></pre> <pre><code>machine youtube login oauth2 password \"\"\n</code></pre></p> <p>Now every-time when running the program, must append <code>--netrc</code> as an option <pre><code>yt-dlp --netrc https://youtube.com/watch?v=private\n</code></pre></p>"},{"location":"Computer%20Stuff/yt-dlp%20oauth/#window","title":"Window","text":"<p>Similar setup to Linux, except the recommendation location of plugins and <code>netrc</code> file Install the plugins into  <pre><code>$env:appdata/yt-dlp/plugins\n</code></pre> Similarly, the <code>.netrc</code> file can be created in home directory so it\u2019s picked up by yt-dlp <pre><code>$env:userprofile\n</code></pre></p>"},{"location":"Docker%20Apps/01-docker-infra/","title":"01 Docker Infrastructure","text":""},{"location":"Docker%20Apps/01-docker-infra/#filesystem","title":"Filesystem","text":""},{"location":"Docker%20Apps/01-docker-infra/#compose","title":"Compose","text":"<p>All <code>docker-compose.yml</code> files are stored in <code>~/docker</code> folder, which then by default is under the network <code>docker_default</code>.</p> <ul> <li>by default for newly created apps, a new folder is created and <code>docker-compose.yml</code> is created for that app for testing<ul> <li>once app testing is complete, the compose file can be moved docker root folder if appropriate or remain</li> </ul> </li> <li>some apps can be grouped together and these compose files are in the root docker folder such as <code>media.yml</code>, <code>network.yml</code>, the grouping allows multiple services to be managed by a single compose. For grouping, some of the property can include<ul> <li>the apps share common properties such as <code>arrs</code> apps</li> <li>it is preferable for apps to live in same network, eg. <code>teslamate</code></li> <li>a large app requiring multiple containers eg. <code>frontend</code>, <code>mysql</code> etc..</li> <li>apps share similar/same category, such as <code>qBittorrent</code> and <code>nzbget</code> can be put together in <code>downloader.yml</code> even though they do not have common properties or require same networking</li> </ul> </li> </ul>"},{"location":"Docker%20Apps/01-docker-infra/#storage","title":"Storage","text":"<p>The storage used for all containers are bind mount.</p> <ul> <li>application configs are stored in <code>~/docker/[app]</code><ul> <li>if an app has multiple components needing persistence (eg. app with database, helpers), a folder will be created as such <code>~/docker/[app]/postgres</code> etc.</li> </ul> </li> <li>apps that also store non-config data (such as music, documents etc.) and not using a lot of space can bind mount <code>/mnt/nvme/share</code> (a directory on local or another SSD) for fast data access and without spinning up HDD</li> <li>exceptions are home assistant or its related home automation containers and these are stored at <code>/srv/homeassistant</code></li> </ul>"},{"location":"Docker%20Apps/01-docker-infra/#backup","title":"Backup","text":"<p>The entire docker root folder is copied to a NFS share on another computer. With exception of minecraft and home assistant which a specialized method is used.</p>"},{"location":"Docker%20Apps/01-docker-infra/#network","title":"Network","text":"<p>With <code>docker-compose</code>, a new network is created with the name of folder the compose is located, while it\u2019s possible to change network, it is not straightforward, therefore, there is no points in manually defining networks unless required.</p> <p>Public <code>172.80.0.0/16</code> - bridge network for public facing applications with reverse proxy, this way when configuring Nginx Proxy Manager, all it need is to enter <code>container_name:80</code> rather than IP address.</p> <ul> <li>Nginx Proxy Manager - <code>172.80.44.3</code></li> <li>Other containers will use docker DHCP to get address</li> <li>Containers that need to public facing can attach to this network Media <code>172.96.0.0/16</code> - bridge network for arrs, downloader and management applications for easy interconnection when configuring Minecraft <code>172.255.255.0/24</code> - bridge network for Minecraft related networks</li> <li>Minecraft server (mcserver) - <code>172.255.255.65</code></li> </ul>"},{"location":"Docker%20Apps/01-docker-infra/#categories","title":"Categories","text":"<p>Media Apps - apps related to media acquisition, curation and other functions services for Jellyfin Networking - reverse proxy, DNS, VPN and related services Home Automation - home assistant and its associated functions VNC - containers based on jlesage-vnc-apps or Linuxserver Kasm images, usually desktop apps run in a browser via noVNC Management - tools for managing docker containers or entire server Games - game servers and associated tools Filesharing - apps that share files to other clients Documentation - notes and operation procedures for server infrastructure Authentication - services that handle single sign-on (SSO) with users</p>"},{"location":"Docker%20Apps/02-docker-ratings/","title":"Ratings","text":"<p>Docker App Rating consist of a table that look at the docker app and evaluate its configurations, deployment and usage against some quality of life features such as easy backup/restore, migration, user mapping, time zone logs, single-sign on with multi-user support etc. These ratings will change as more testing are done.</p> Docker Apps Rating U/GID TZ SSO/Users Existing FS Portable Subfolder \u274e \u2705* \u274c\ud83e\udd35 \u2705 \u274c \u274c"},{"location":"Docker%20Apps/02-docker-ratings/#ugid","title":"UGID","text":"<p>The Docker container/application or stack supports user ID and group ID mapping and respect the ID matching the host system. For example, Linuxserver.io and jlesage containers are gold standard.</p> \u2705 Natively Supported\u274e Supported\ud83d\udfe8 Usable\u274cNot Supported <ul> <li>All Linuxserver and jlesage containers and projects that build with their baseimages, uses environment variables <code>PUID/PGID</code> for mapping</li> <li>Fully respect UID and GID mappings on the host, will be able to all bind mounted files on the host with the respective permission without permission error and app issues</li> <li>All the files the app need to write to the bind mount are written with the ID set in environment variable and are accessible via anything such as VSCode and other containers</li> <li>For apps that don\u2019t have environment variables as above, but still following host user ID and permissions when modifying files will also have this rating <code>eg. Audiobookshelf, Navidrome</code></li> <li>If the app require multiple containers deployed as a stack and if the main app or the app that stores configuration/appdata fully support it but other part of the app do not, it will have <code>\u2705*</code> rating <code>eg. Bookstack</code></li> </ul> <ul> <li>The container do not have these environment variables and by default when it needs to create files on the host, it creates them with <code>root:root</code> permission but functions correctly </li> <li>The container permission can be fixed simply with <code>user: 1000:1001</code> in compose</li> <li>After this fix, these should not be any permission issues and the container functions without issues and create files that are accessible via anything <code>eg. Authelia, Jellystat</code></li> </ul> <ul> <li>The container do not support environment variables and by using <code>user:</code>, the functionality of the container is broken and have permission issues or still writes files as <code>root</code></li> <li>However, the container do not write configuration data or there is no need to have shared access of data</li> <li><code>eg. a database application, app that is entirely configured via environment/labels</code></li> </ul> <ul> <li>The container exhibit symptoms of <code>Usable</code> rating but <code>user:</code> either breaks the containers or still won\u2019t fix permission</li> <li>The container bind mounts to configuration or shared data that needs to be accessible by other tools, it would need constant <code>chown -R</code> to ensure access by others are possible</li> <li>By setting <code>user:</code> or <code>chown</code> to make files accessible to the host and other tools, the container cease to function</li> <li>Only named volumes can be used not bind mounts</li> </ul>"},{"location":"Docker%20Apps/02-docker-ratings/#tz","title":"TZ","text":"<p>The container support standard timezone variable. All logs generated by the container follows the timezone specified by <code>TZ</code> or other supported environment variables. This is either \u2705 or \u274c.</p>"},{"location":"Docker%20Apps/02-docker-ratings/#sso","title":"SSO","text":"<p>Users</p> <ul> <li>\ud83e\udd35: Only a single user/session is supported at a time</li> <li>\ud83d\udc6a: Multiple users are supported via SSO or internally</li> </ul> <p>Authelia  Authelia is the SSO provider that is used for the setup. Only support and compatibility for this will be documented. Only the main app via an exposed web interface need to support it, otherwise it\u2019s not applicable. If there are zero reasons to expose this app to the internet and have multiple local users, this is n/a.</p> \u2705 Natively Supported\u274e Supported\ud83d\udfe8 Usable\u274c Not Supported <ul> <li>App has OIDC support that works with third-party provider <code>eg. Audiobookshelf, Portainer</code></li> <li>App without advanced OIDC but have documented other ways to integrate SSO for users <code>eg. Filebrowser, Navidrome</code></li> <li>The user via SSO can be mapped to existing users with same name or creates the user if not exist</li> <li>App is able to fully integrate with ALL third party service or mobile/desktop apps flawlessly even after installing SSO/2FA</li> <li>Authelia whitelist rules can be easily created to restore full functionality of the app (<code>eg. API, public portion</code>) without compromising security where Authelia is needed </li> </ul> <ul> <li>App do not provide native integration for third party sign-in providers; but has an option to fully disable internal authentication in favor of Authelia <code>eg. Radarr, Nzbget</code></li> <li>App do not have internal authentication <code>eg. Memos, jlesage VNC</code></li> <li>By adding Authelia to add authentication or to replace internal authentication, the app is able to fully integrate with ALL third party service or mobile/desktop apps flawlessly even after installing SSO/2FA</li> <li>Authelia whitelist rules can be easily created to restore full functionality of the app (<code>eg. API, public portion</code>) without compromising security where Authelia is needed</li> <li>The above only apply with single-user apps, if a multi-user app do not natively support 3p SSO provider, Authelia is unable to passthrough the correct user</li> </ul> <ul> <li>Apps that have removable authentication or no authentication which Authelia can be added</li> <li>The only logical way to access the app is via a web browser where Authelia is fully supported</li> <li>Accessing the app via third-party services is restricted to LAN only or behind a VPN where Authelia is not relevant <code>eg. Nginx Proxy Manager, Teslamate</code></li> </ul> <ul> <li>The app has internal authentication that cannot be disabled or integrate with Authelia</li> <li>After installing Authelia, only way to use the app is via web browser; third party integration and mobile/desktop apps no longer function even with whitelisting rules <code>eg. Jellyfin, Home Assistant</code></li> <li>Using whitelist rules to restore functionality with third party apps would compromise security where Authelia is needed</li> <li>No workarounds are possible to have both SSO and 3p integrations</li> </ul>"},{"location":"Docker%20Apps/02-docker-ratings/#existing-fs","title":"Existing-FS","text":"<p>Existing filesystem structures, the app do not require a folder structure that only the app can use and is able to use it as is and allow user to not change workflow when switching to this app. (This section is incomplete, more updates needed)</p> <ul> <li>config: type of files that governs how an app behaves <code>eg. configuration.yaml, app.conf</code></li> <li>media: files includes videos, photos, documents or other files the user want the app to manage</li> </ul> \u2705 Yes\ud83d\udfe8 Partially\u274c No <ul> <li>App work with a bind mount to a host path where other process can also access it and the app do not have conflict with other processes</li> <li>App do not modify existing file structures and permissions</li> <li>User is able to import/export/edit data stored in the app (both configs and media) freely with or without the app <code>eg. Jellyfin, Filebrowser</code></li> <li>User is able to move relatively freely to a similar app</li> </ul> <ul> <li>(To be updated)</li> </ul> <ul> <li>App store its data (both config and media) in encrypted blob, proprietary format, specific database only the app can read</li> <li>App modify existing file structure for it to work and the permissions it need are incompatible with other workflows, refer to U/GID</li> <li>The only way to import/export/edit data is via the app, it\u2019s difficult to use another workflow</li> </ul>"},{"location":"Docker%20Apps/02-docker-ratings/#portable","title":"Portable","text":"<p>The portability of the app refers to how easy is it to migrate, backup/restore an app\u2019s config. If the frequency of backup/restore is irrelevant or no persistence data is needed such the app runs entirely via docker-compose, it\u2019d be n/a.</p> \u2705 Yes\ud83d\udfe8 Partially\u274c No <ul> <li>The app will work on another machine simply by copying the bind mount to the new machine</li> <li>If U/GID are not supported and a named volume is used, copying the volume with various tools will transfer the app to the new machine</li> <li>If an app uses a database, it will still work after either copying the bind path or volume to the new machine; if not, a repeatable and documented way to dump and import the database is provide so the app will transfer smoothly </li> <li>After the app is migrated, zero user intervention is needed and the app to function exactly the same</li> </ul> <ul> <li>App does not work by simply copying over the persistent data, but only a quick user intervention is needed <code>eg. backup/restore file in WebUI</code></li> <li>App data migration will work, but might require complex scripts or other dependencies that makes scripting harder</li> </ul> <ul> <li>App cannot be migrated or restored by simply copying the files, the app stop workings</li> <li>The backup process is difficult and often fails</li> <li>Even with a migration, heavy user intervention is needed for the app to function exactly the same if it\u2019s possible</li> </ul>"},{"location":"Docker%20Apps/02-docker-ratings/#mobile","title":"Mobile","text":"<p>The mobile refers to mobiles apps section, this rating determines the quality of mobile integration (only Android tested) since an app on mobiles offers more function than a website.</p> \u2705 Great\u2714 App Present/PWA\u274cNot Mobile Friendly <ul> <li>The app has a mobile app on app store or APK either from the developer itself or has viable well-maintained third-party apps</li> <li>The mobile app enhance the experience of the app and offers better usability compared to a web browser</li> <li>Mobile app offers deep integration with Android OS or other apps with widgets, controls, intents where nessecary (eg. Audiobookshelf, Home Assistant, Jellyfin, share icon to and from app)</li> </ul> <ul> <li>The app website has a mobile-friendly layout which a progressive-web app can be used and the webapp offers equivalent functionality to desktop counterpart</li> <li>The app in question is basic and all its functions are supported via a website without deep system integration (eg. Dashboard app for display only)</li> <li>App will be given <code>*</code> rating if the app does not have a mobile app or support PWA but it\u2019s mobile friendly when opened in a traditional mobile browser</li> </ul> <ul> <li>The app either do not have a mobile friendly website/app or it\u2019s mobile counterpart is not useable that a lot of desktop functionality is lost (eg. Grafana, webtop)</li> </ul>"},{"location":"Docker%20Apps/bookstack/","title":"Bookstack","text":""},{"location":"Docker%20Apps/bookstack/#installation","title":"Installation","text":"<p>Change port to 6975</p> <p>Add in docker-compose: restart: unless-stopped</p> <p>$docker directory = /home/docker .... etc</p> <p>Docker-Compose file reference</p> <p>https://github.com/solidnerd/docker-bookstack/blob/master/docker-compose.yml</p> <pre><code>version: '2'\nservices:\n  mysql:\n    image: mysql:8.0\n    environment:\n\n    - MYSQL_ROOT_PASSWORD=secret\n    - MYSQL_DATABASE=bookstack\n    - MYSQL_USER=bookstack\n    - MYSQL_PASSWORD=secret\n    volumes:\n    - mysql-data:/var/lib/mysql\n    restart: unless-stopped\n\n  bookstack:\n    image: solidnerd/bookstack:22.10.2\n    depends_on:\n\n    - mysql\n    environment:\n    - DB_HOST=mysql:3306\n    - DB_DATABASE=bookstack\n    - DB_USERNAME=bookstack\n    - DB_PASSWORD=secret\n    #set the APP_ to the URL of bookstack without without a trailing slash APP_URL=https://example.com\n    - APP_URL=http://xxx.xxxmydomainxxx.duckdns.org\n    volumes:\n    - $docker/public-uploads:/var/www/bookstack/public/uploads\n    - $docker/storage-uploads:/var/www/bookstack/storage/uploads\n    ports:\n    - \"6975:8080\"\n    restart: unless-stopped\n</code></pre> <p>Notice: The default password for bookstack is</p> <p>admin@admin.com</p> <p>password</p> <p>Permissions: remember the set write permission on public-uploads folder so users can upload photos.</p>"},{"location":"Docker%20Apps/bookstack/#backup-and-restore","title":"Backup and Restore","text":"<p>Files Backup:</p> <pre><code>tar -czvf bookstack-files-backup.tar.gz public-uploads storage-uploads\n</code></pre> <p>Restore:</p> <pre><code>tar -xvzf bookstack-files-backup.tar.gz\n</code></pre> <p>Database backup:</p> <pre><code>sudo docker exec bookstack_mysql_1 /usr/bin/mysqldump -u root --password=secret bookstack &gt; ./bookstack/bookstack_db.sql\n</code></pre> <p>Restore:</p> <pre><code>sudo docker exec -i bookstack_mysql_1 mysql -u root --password=secret bookstack &lt; /$docker/bookstack/bookstack_db.sql\n</code></pre> <ul> <li>bookstack_mysql1 is the container name</li> <li>password is secret or the database password</li> </ul>"},{"location":"Docker%20Apps/bookstack/#reverse-proxy","title":"Reverse Proxy","text":"<p>Use subdomain in proxy manager.</p> <p>Backing Up and Restoring with LinuxServer.io container</p> <p>Due to limits or Oracle Cloud free tier. The only arm image is from linuxserver io container, and it is different than solidnerd image.</p> <p>Docker-Compose file</p> <pre><code>version: \"2\"\nservices:\n  bookstack:\n    image: lscr.io/linuxserver/bookstack\n    container_name: bookstack\n    environment:\n\n      - PUID=1001\n      - PGID=1001\n      - APP_URL=https://wiki.xxx.duckdns.org\n      - DB_HOST=bookstack_db\n      - DB_USER=bookstack\n      - DB_PASS=secret\n      - DB_DATABASE=bookstackapp\n    volumes:\n      - /home/ubuntu/bookstack:/config\n    ports:\n      - 6975:80\n    restart: unless-stopped\n    depends_on:\n      - bookstack_db\n\n  bookstack_db:\n    image: lscr.io/linuxserver/mariadb\n    container_name: bookstack_db\n    environment:\n\n      - PUID=1001\n      - PGID=1001\n      - MYSQL_ROOT_PASSWORD=secret\n      - TZ=Europe/London\n      - MYSQL_DATABASE=bookstackapp\n      - MYSQL_USER=bookstack\n      - MYSQL_PASSWORD=secret\n    volumes:\n      - /home/ubuntu/bookstack:/config\n    restart: unless-stopped\n</code></pre> <p>Notice: In Oracle cloud free tier, the default ubuntu user is 1001, not 1000. For database name, it it bookstackapp, keep in mind when executing restore command. The folder structure is also different. In the solidnerd container, the images are stored at /public-uploads while in LSIO container it is stored at /www/uploads</p>"},{"location":"Docker%20Apps/bookstack/#backing-up-from-home-pc","title":"Backing Up (from home PC)","text":"<p>Images</p> <p>cd into /public-uploads and make a tar archive</p> <pre><code>tar -czvf images.tar.gz images\n</code></pre> <p>Backup the database</p> <pre><code>sudo docker exec bookstack_mysql_1 /usr/bin/mysqldump -u root --password=secret bookstack &gt; ./bookstack_db.sql\n</code></pre> <p>Transfer to Oracle Cloud Server</p> <pre><code>scp -i oracle-arm-2.key images.tar.gz bookstack_db.sql ubuntu@$IPADDR:/home/ubuntu/bookstack/www/uploads\n</code></pre> <p>Take in consideration the location where LSIO image stores the images.</p>"},{"location":"Docker%20Apps/bookstack/#restore-into-oracle-cloud","title":"Restore (into Oracle Cloud)","text":"<p>Images (/home/ubuntu/bookstack/www/uploads)</p> <pre><code>tar -xvzf images.tar.gz\n</code></pre> <p>Database</p> <p>The image url in the database still refers to old server url, it needs to be changed. The following command replace the subdomain in the sq1 dump.</p> <pre><code>sed -i 's/wiki.$home.duckdns.org/wiki.$oracle.duckdns.org/g' bookstack_db.sql\n</code></pre> <p>Restore the database.</p> <pre><code>sudo docker exec -i bookstack_db mysql -u root --password=secret bookstackapp &lt; /home/ubuntu/bookstack/www/uploads/bookstack_db.sql\n</code></pre>"},{"location":"Docker%20Apps/bookstack/#crontab","title":"Crontab","text":"<p>On Home PC</p> <pre><code>0 23 * * 2,5 /home/karis/bookstack.sh\n</code></pre> <pre><code>#!/bin/bash\n\ncd ~/docker/bookstack/public-uploads #location of bookstack public uploads\ntar -czvf images.tar.gz images\nsudo docker exec bookstack_mysql_1 /usr/bin/mysqldump -u root --password=secret bookstack &gt; ./bookstack_db.sql\nscp -i oracle-arm-2.key images.tar.gz bookstack_db.sql ubuntu@$ORACLEIP:/home/ubuntu/bookstack/www/uploads\n</code></pre> <p>Make sure to copy the oracle-arm-2.key to the appropriate location (~/docker/bookstack/public-uploads)</p> <p>Also make sure the permission of oracle-arm-2.key is in correct permission (600). Especially changing the permission of public-uploads folder to allow write access.</p> <p>Do a backup sequence in crontab at 11pm every Tuesday and Friday.</p> <p>Oracle Cloud Server</p> <pre><code>0 8 * * 3,6 /home/ubuntu/bookstack.sh\n</code></pre> <pre><code>#!/bin/bash\n\ncd ~/bookstack/www/uploads #directory where bookstack files scp from home are located\ntar -xvzf images.tar.gz\nsed -i 's/wiki.$homeip.duckdns.org/wiki.$oracle.duckdns.org/g' bookstack_db.sql\nsudo docker exec -i bookstack_db mysql -u root --password=secret bookstackapp &lt; /home/ubuntu/bookstack/www/uploads/bookstack_db.sql\n</code></pre> <p>Restore the sequence after backup, every Wednesday and Saturday at 8am (need to consider the TZ between Vancouver, Edmonton and Toronto, or any the time zone of the remote server)</p>"},{"location":"Docker%20Apps/code-server/","title":"VSCode Server","text":"Docker Apps Rating U/GID TZ SSO/Users Existing FS Portable Subfolder Mobile \u274e \u2705* \u274e\ud83e\udd35 \u2705 \u2705 \u2714 \u2714 <p> <pre><code>services:\n  code-server:\n    image: lscr.io/linuxserver/code-server:latest\n    container_name: code-server\n    environment:\n\n      - PUID=1000\n      - PGID=1001\n      - TZ=America/Vancouver\n      - DEFAULT_WORKSPACE=/projects #optional\n      - DOCKER_MODS=linuxserver/mods:code-server-python3\n    env_file:\n      - .env\n    volumes:\n      # Master configuration\n      - ~/docker/code-server:/config\n      # dotfiles\n      - ~/.bashrc:/config/.bashrc\n      - ~/.ssh:/config/.ssh\n      - ~/.gitconfig:/config/.gitconfig\n      - ~/Documents/ssh:/config/Documents/ssh # ssh keys\n      # Workspace folders (eg. Docker, other projects)\n      - ~/docker:/docker\n      - ~/projects:/projects\n    ports:\n      - 4443:8443\n    networks:\n      - public\n    restart: unless-stopped\n\nnetworks:\n  public:\n    name: public\n    external: true\n</code></pre></p>"},{"location":"Docker%20Apps/code-server/#setup","title":"Setup","text":"<p>The setup follows the same 01-docker-infra, since this is externally accessible, it has a network of <code>public</code></p>"},{"location":"Docker%20Apps/code-server/#environments","title":"Environments","text":"<p><code>DEFAULT_WORKSPACE</code> - the directory that VSCode will open to when accessing it, defaults to <code>/config</code> The container is Linuxserver so it follows their standards of PUGID and TZ The Docker Mods will add python3 into the environment for debugging python files.</p>"},{"location":"Docker%20Apps/code-server/#directory","title":"Directory","text":"<p>The base configuration is stored in <code>~/docker/code-server</code> as usual</p> <ul> <li>the bind mount <code>/config</code> is the container is also the <code>XDG_HOME</code> which is the default Linux home directory Given that the config is also the home directory, many dotfiles such as bash, git and SSH configuration need to be bind mounted from the hosts <code>~</code> directory into containers <code>/config</code> or home directory.</li> </ul> <p>The workspace folder contains <code>docker</code> (docker configuration and data) and <code>projects</code> (cloned from git repo) which are frequently edited files.</p>"},{"location":"Docker%20Apps/code-server/#usage","title":"Usage","text":"<p>The app functions similarly to VSCode and mostly follows the shortcut of the desktop version. Such as Ctrl+Shift+P to open command palette. The app has high idle usage, try to close workspace/sign out and restart after editing, or use solutions to use on-demand.</p>"},{"location":"Docker%20Apps/code-server/#problems","title":"Problems","text":"<p>Official account sync login doesn\u2019t work, third party extensions doesn\u2019t work either, so the settings has to be done manually.</p> <ul> <li>for basic configurations <code>keybindings.json</code> and <code>settings.json</code> contains all the theme and extension settings for a minimal viable VSCode</li> <li>the <code>json</code> files are periodically copied from main Desktop and synced to the server via Syncthing</li> </ul> <p>Remote SSH doesn\u2019t work, but can be solved by SSH extension. Github Copilot doesn\u2019t work. Python syntax highlighting doesn\u2019t work.</p>"},{"location":"Docker%20Apps/code-server/#extensions","title":"Extensions","text":""},{"location":"Docker%20Apps/code-server/#ssh","title":"SSH","text":"<p>Since the default Remote SSH doesn\u2019t work, the extension SSH FS can be used.  The configuration is done in <code>settings.json</code> and will show up in UI. <pre><code>\"sshfs.configs\": [\n\u00a0 \u00a0 {\n\u00a0 \u00a0 \u00a0 \u00a0 \"name\": \"mediaserver-docker\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"host\": \"10.10.120.16\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"username\": \"karis\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"privateKeyPath\": \"/config/Documents/ssh/openssh_keys/mediaserver.key\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"root\": \"~/docker\"\n\u00a0 \u00a0 },\n\u00a0 \u00a0 {\n\u00a0 \u00a0 \u00a0 \u00a0 \"name\": \"mediaserver-homeassistant\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"host\": \"10.10.120.16\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"username\": \"karis\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"privateKeyPath\": \"/config/Documents/ssh/openssh_keys/mediaserver.key\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"root\": \"/srv/homeassistant\"\n\u00a0 \u00a0 }\n\u00a0 \u00a0 ],\n</code></pre> The options from left to right are</p> <ul> <li>Open Folder - open the folder (configured as <code>root</code>) to workspace for editing, for SSH connections outside the network like VPS, the speed is slow</li> <li>Open Terminal - start a terminal session to the remote folder</li> <li>Settings</li> <li>Disconnect - after editing the remote folder, this will remote the remote folder from the workspace</li> </ul>"},{"location":"Docker%20Apps/code-server/#reverse-proxyauthentication","title":"Reverse Proxy/Authentication","text":""},{"location":"Docker%20Apps/code-server/#reverse-proxy","title":"Reverse Proxy","text":"<p>The app supports both subdomain and subpath for proxying in Nginx Proxy Manager.</p>"},{"location":"Docker%20Apps/code-server/#sso","title":"SSO","text":"<p>For Authelia SSO in Nginx Proxy Manager and custom location support. <pre><code>location /vscode/ {\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection $http_connection;\n    include /snippets/proxy.conf;\n    include /snippets/authelia-authrequest.conf;\n    proxy_pass http://10.10.120.12:4443/;\n}\n</code></pre> This configuration support all of websocket, subpath and authelia. No additional authelia whitelist is needed.</p>"},{"location":"Docker%20Apps/ddns-update/","title":"Dynamic DNS Updater Docker","text":"<p>Official Image: https://hub.docker.com/r/linuxserver/duckdns Custom Github Page: https://github.com/vttc08/docker-duckdns-dynu</p> <p>This is a docker container that automatically updates the public IPv4 address of the server every 5 minutes to dynamic DNS services Dynu and DuckDNS. It is the fork of Linuxserver DuckDNS container.</p>"},{"location":"Docker%20Apps/ddns-update/#docker-compose","title":"Docker Compose","text":"<pre><code>  services:\n      duckdns:\n        image: vttc08/docker-duckdns-dynu:latest\n        container_name: duckdns\n        env_file: ddns.env\n        environment:\n\n          - TZ=America/Vancouver\n          - PUID=1000\n          - PGID=1001\n        restart: unless-stopped\n</code></pre> <p>These need to be filled in the <code>ddns.env</code> <pre><code>DYNU_HOST= # full name of dynu domains\nDYNU_PASS= # md5 hashed dynu login pass\nSUBDOMAINS= # DuckDNS domains without the duckdns.org part\nTOKEN= # DuckDNS token \n</code></pre></p> <ul> <li>token will be visible in DuckDNS dashboard</li> <li>Dynu pass is the same as login; alternatively, it is possible to create a dedicated password  just for IP update  MD5 generator <pre><code>echo -n \"password\" | md5sum\n</code></pre></li> <li>when setting the IP to <code>10.0.0.0</code> in Dynu update API, dynu will automatically update the IP address to the IP address making that request</li> </ul>"},{"location":"Docker%20Apps/ddns-update/#other-usage","title":"Other Usage","text":"<p><code>docker restart duckdns</code> will manually run IP update <code>docker exec -it duckdns /app/debug.sh</code> or other scripts, debug script will print out IP address of subdomains resolved by Cloudflare</p>"},{"location":"Docker%20Apps/epic-games-free-games/","title":"Epic Games Free Games","text":"<p>Buy Free Games from Epic Games</p> <p>https://hub.docker.com/r/charlocharlie/epicgames-freegames</p> <p>Config</p> <p>NEED TO CHANGE</p> <p>Email: email address</p> <p>Password: password</p> <p>Webhook URL: make a discord channel and click settings. Go to integrations, then webhook, copy webhook URL.</p> <p>mentioned Users: right click your profile, and click Copy ID</p> <p>TOTP</p> <ol> <li>Go here to login. https://www.epicgames.com/account/password Login with Epic Games account.</li> <li>Click \u201cenable authenticator app.\u201d</li> <li>In the section labeled \u201cmanual entry key,\u201d copy the key.</li> <li>Use your authenticator app to add scan the QR code.</li> <li>Activate 2FA by completing the form and clicking activate.</li> <li>Once 2FA is enabled, use the key you copied as the value for the TOTP parameter.</li> </ol> <p>Docker</p> <pre><code>docker run -d -v /home/karis/docker/epicgames:/usr/app/config:rw -p 3000:3000 -m 2g --name epicgames --restart unless-stopped charlocharlie/epicgames-freegames:latest\n</code></pre> <p>Change the name of the container to a friendly name. Restart unless stopped so it restart automatically.</p> <p>Copy and Paste</p> <p>The default json configuration is located at /home/karis/docker/epicgames or $HOME/docker/epicgames.</p> <p>Fix Login Issue Using Cookies</p> <p>https://store.epicgames.com/en-US/</p> <ol> <li>Visit this site and make sure it\u2019s logged in.</li> <li>Install this extension EditThisCookie https://chrome.google.com/webstore/detail/editthiscookie/fngmhnnpilhplaeedifhccceomclgfbg/related</li> <li>Open the extension and change the url to epicgames.com/id as in screenshot below</li> <li>Export the cookie</li> </ol> <p></p> <ol> <li>Go to $HOME/docker/epicgames and create a new file email@gmail.com-cookies.json</li> <li>If the json file is already there, truncate it with \u2013size 0</li> <li>Paste the cookie value to the json file</li> <li>Restart container.</li> </ol> <p>Update</p> <pre><code>docker pull charlocharlie/epicgames-freegames:latest\ndocker rm -f epicgames\ndocker images | grep epicgames\n# use docker rmi to remote the corresponding image \n# re run the epicgames docker run command\n</code></pre>"},{"location":"Docker%20Apps/filebrowser/","title":"Filebrowser","text":"<p>Filebrowser app on a webbrowser, port 4455. free-games-claimer</p> <p>Docker-compose deployment</p> <pre><code>version: '3.9'\nservices:\n    filebrowser:\n        container_name: filebrowser\n        image: filebrowser/filebrowser\n        ports:\n\n            - '4455:80'\n        user: 1000:1000\n        restart: unless-stopped\n        volumes:\n            - '~/docker/filebrowser/.filebrowser.json:/.filebrowser.json'\n            - '~/docker/filebrowser/filebrowser.db:/database.db'\n            - '~/docker/filebrowser/branding:/branding'\n            - '~/docker:/srv/docker'\n            - '/mnt/data:/srv/data'\n            - '/mnt/nvme/share:/srv/nvme-share'\n</code></pre> <p>The first 3 bind mount are for configuration of filebrowser, eg. config, database and branding files. On first deployment, need to create an empty database.db file. The remaining bind mount are for the folders that need to be accessed, the folders should be bound under <code>/srv</code>. Filebrowser by default create a volume under <code>/srv</code>, in this setup where folders are bind mount to subfolders in <code>/srv</code> and nothing bind mount directly, it could create a specific volume under docker just for <code>/srv</code> which is unavoidable.</p> <p>This is the content of <code>.filebrowser.json</code></p> <pre><code>{\n    \"port\": 80,\n    \"baseURL\": \"\",\n    \"address\": \"\",\n    \"log\": \"stdout\",\n    \"database\": \"/database.db\",\n    \"root\": \"/srv\"\n  }\n</code></pre>"},{"location":"Docker%20Apps/filebrowser/#usershare","title":"User/Share","text":"<p>The user and share management in filebrowser is simple. The shares have a expiring time, and can optionally have a password. The recipient can view and download files in the share but cannot upload.</p> <p>To create a new user, it\u2019s under settings -&gt; User Management, and add a user and password accordingly, and give appropriate permission. The scope is where the root folder where the user have access to, since the docker data folder is bound at /srv/docker and /srv is defined as root folder in config, the folder name to put in scopes would be <code>/docker</code>. Only one scope is allowed.</p> <p></p> <p>It is also possible to add rules to prevent user access of files within a scope. Under rules, enter the path that is relative to the scope, for example /docker/minecraft/config would be <code>/config</code></p> <p></p>"},{"location":"Docker%20Apps/filebrowser/#personalization","title":"Personalization","text":"<p>Enable dark theme - Setting -&gt; Global Settings -&gt; Branding</p> <ul> <li>also change the branding directory path to /branding which is bind mount in docker</li> </ul> <p>Under the branding folder, create a file <code>custom.css</code>which is used for css customization. Then create a folder img and place logo.svg in it for custom icon. The icon is the same as egow entertainment and stored in OliveTin icon PSD file. Under the folder img, create a folder icons and use favicon generator site to create an icon archive and put all the content of that archive in the icons folder, the result should look like this.</p> <p></p> <p>Reverse Proxy/Homepage</p> <p>Reverse proxy is normal procedure using NPM. To add bookmark to a file location, use browser/homepages bookmark function.</p>"},{"location":"Docker%20Apps/fireshare/","title":"Fireshare","text":"Docker Apps Rating U/GID TZ SSO/Users Existing FS Portable Subfolder Mobile \u274e \u2705* \u274c\ud83e\udd35 \u2705 \u2705 \u274c \u2714"},{"location":"Docker%20Apps/fireshare/#configuration","title":"Configuration","text":"<pre><code>services:\n\u00a0 fireshare:\n\u00a0 \u00a0 image: shaneisrael/fireshare:develop\n\u00a0 \u00a0 container_name: fireshare\n\u00a0 \u00a0 environment:\n\u00a0 \u00a0 \u00a0 - MINUTES_BETWEEN_VIDEO_SCAN=30\n\u00a0 \u00a0 \u00a0 - PUID=1000\n\u00a0 \u00a0 \u00a0 - PGID=1001\n\u00a0 \u00a0 env_file:\n\u00a0 \u00a0 \u00a0 - .env # admin password\n\u00a0 \u00a0 volumes:\n\u00a0 \u00a0 \u00a0 - ~/docker/fireshare/data:/data:rw\n\u00a0 \u00a0 \u00a0 - ~/docker/fireshare/processed:/processed:rw\n\u00a0 \u00a0 \u00a0 - /mnt/nvme/share/gaming:/videos:rw\n\u00a0 \u00a0 networks:\n\u00a0 \u00a0 \u00a0 public:\n\u00a0 \u00a0 ports:\n\u00a0 \u00a0 \u00a0 - 8080:80\n\u00a0 \u00a0 restart: unless-stopped\n\nnetworks:\n\u00a0 public:\n\u00a0 \u00a0 name: public\n\u00a0 \u00a0 external: true\n</code></pre>"},{"location":"Docker%20Apps/fireshare/#environments","title":"Environments","text":"<p>Content of <code>.env</code> <pre><code>ADMIN_PASSWORD=\nDOMAIN=\n</code></pre> Setup user and group ID accordingly; more environment options are available https://github.com/ShaneIsrael/fireshare/wiki/Fireshare-Configurables</p>"},{"location":"Docker%20Apps/fireshare/#other","title":"Other","text":"<p>The software can also be configured via <code>config.json</code> located in <code>/data/config.json</code>. It\u2019s configuration is same as the WebUI.  <code>Default Video Privacy</code>: <code>false</code> set all the videos public viewable without sharing manually <code>Default Video Privacy</code>: <code>false</code> public user cannot upload videos <code>Sharable Link Domain</code>: link which fireshare append to when sharing files <code>Upload Folder</code>: folder that will be created in <code>/videos</code> directory when file is uploaded</p>"},{"location":"Docker%20Apps/fireshare/#usage","title":"Usage","text":"<p> By default, can view videos, admin and share links and the link will show preview and viewable in Discord. Admin can also upload directly in web interface. All the uploaded files are located in <code>/videos/uploads</code></p> <ul> <li>when uploading files through filesystem with a changed date via <code>touch</code> the changed date will also be reflected in the app</li> </ul>"},{"location":"Docker%20Apps/fireshare/#workflow","title":"Workflow","text":"<p>https://github.com/vttc08/fireshare-import Refer to this Github repo to setup. For personal documentation</p> <ul> <li>setup the project directory into <code>~/Documents/Projects</code></li> </ul>"},{"location":"Docker%20Apps/free-games-claimer/","title":"Free Games Claimer","text":"<p>https://github.com/vogler/free-games-claimer</p> <p>This is the Github repo for the new and advanced free games claimer. This is implemented after Epicgames FreeGames keeps failing.</p>"},{"location":"Docker%20Apps/free-games-claimer/#configuration","title":"Configuration","text":"<p>Using Docker-Compose</p> <p>In the folder structure</p> <pre><code>server: ~/docker/fgc$\ndocker-compose.yml\nfgc.env\n</code></pre> <p>fgc.env is the environment file for all the password/keys to login to different game services, fill it in manually or use a backup.</p> <pre><code>EG_OTPKEY=\nEG_EMAIL=\nEG_PASSWORD=\nNOTIFY=discord://123456/ABCD\nPG_EMAIL=\nPG_PASSWORD=\nGOG_EMAIL=\nGOG_PASSWORD=\nTIMEOUT=300\n</code></pre> <p><code>NOTIFY=discord://123456/ABCD</code> if the webhook looks like this <code>https://discord.com/api/webhooks/123456/ABCD</code></p> <p><code>TIMEOUT=300</code> sets the timeout to 300s before the container skip and error out due to EpicGames captcha problems. However, the impact on prime gaming and GOG are not tested.</p> <p>docker-compose.yml</p> <pre><code>services:\n  free-games-claimer:\n    container_name: FGC # is printed in front of every output line\n    image: ghcr.io/vogler/free-games-claimer # otherwise image name will be free-games-claimer-free-games-claimer\n    build: .\n    ports:\n\n      - \"5990:5900\" # VNC server\n      - \"5890:6080\" # noVNC (browser-based VNC client)\n    volumes:\n      - ~/docker/fgc:/fgc/data\n      - ~/docker/fgc/epic-games.js:/fgc/epic-games.js\n      - ~/docker/fgc/prime-gaming.js:/fgc/prime-gaming.js\n      - ~/docker/fgc/gog.js:/fgc/gog.js\n    command: bash -c \"node epic-games; node prime-gaming; node gog; echo sleeping; sleep 1d\"\n    env_file:\n      - fgc.env\n    restart: unless-stopped\n</code></pre> <p>This docker-compose file use the environment file fgc.env as indicated above and runs once every day. It also contains VNC server/web based client.</p>"},{"location":"Docker%20Apps/free-games-claimer/#missing-captcha-session","title":"Missing Captcha Session","text":"<p>This should no longer be needed. Edit the line to epicgames.js code and replace with the following message. When the captcha is missed, it will send a notification for manual claiming.</p> <pre><code>wait notify(`epic-games: got captcha challenge right before claim. Use VNC to solve it manually. Game link: \\n ${url}`)\n</code></pre> <p>EpicGames require a captcha to claim free games. If the 5 minute timeout window for EpicGames is missed, it is no longer possible to claim the games unless waiting for the next day, which due to the nature of discord notifications, there is a slim to none chance of catching the captcha at next day. To continuing claiming after acknowledging the missed session, use portainer, ConnectBot Android to temporarily restart the container to restore VNC session.</p> <p>In order to restore the default time of claiming the games. Eg. waking up on Thurs or Fri and a predictable time and claim games, use the linux at command. Need to install <code>at</code> using <code>apt</code>. <pre><code>at 9:20\n&gt; docker restart FGC\n&gt; &lt;EOT&gt;\n</code></pre></p> <p>This will run the command at 9:20 AM the next day. Ctrl-D to exit at prompt and verify the time is correct.</p>"},{"location":"Docker%20Apps/ghost-docker/","title":"Ghost CMS Docker","text":"<p>Ghost is a website/blog management system with a database. This page is specific to installation and management of Ghost Docker container.</p>"},{"location":"Docker%20Apps/ghost-docker/#installation","title":"Installation","text":""},{"location":"Docker%20Apps/ghost-docker/#basic-configuration","title":"Basic Configuration","text":""},{"location":"Docker%20Apps/ghost-docker/#ghost-configuration","title":"Ghost Configuration","text":"<p>Will be documented in ghost-cms in depth.</p>"},{"location":"Docker%20Apps/invidious/","title":"Invidious","text":""},{"location":"Docker%20Apps/jlesage-vnc-apps/","title":"jlesage VNC Apps","text":"<p>VNC apps consists of desktop applications that have the GUI in a web browser, mostly from the creator jlesage.</p>"},{"location":"Docker%20Apps/jlesage-vnc-apps/#environments","title":"Environments","text":"<p>At least for apps from jlesage, it supports an environment variable. Create an environment file called <code>vnc.env</code></p> <p>The environment file can be reference in many docker images from jlesage using docker-compose. The current environment variable specify U/GID, time zone and make every app dark mode. It is also possible to set VNC passwords. This is the full list of environment variables. For supported apps such as avidemux, there is an option <code>WEB_AUDIO=1</code> which allow audio to work.</p> <pre><code>USER_ID=1000\nGROUP_ID=1001\nTZ=America/Vancouver\nDARK_MODE=1\nKEEP_APP_RUNNING=1\n</code></pre> <p>The jlesage apps have 2 ports, port 5800 for viewing the VNC app on a web browser on desktop; port 5900 is for VNC protocol that can be used in dedicated VNC viewer or mobile viewing.</p>"},{"location":"Docker%20Apps/jlesage-vnc-apps/#general-bind-mounts","title":"General Bind Mounts","text":"<p>The appdata bind mount is located in the <code>~/docker/vnc</code>, as seen from the yml example, the vnc environment file <code>vnc.env</code> is placed in the appdata folder. For application requiring access to movie storage, the bind mount is on the corresponding hard drive or pool. As for applications requiring access to storage but not large media, it\u2019s best to put the files on a SSD.</p> <p>This is an example of VNC container of MKVToolNix. The <code>vnc.yml</code> file is backed up elsewhere.</p> <pre><code>    mkvtoolnix:\n        image: jlesage/mkvtoolnix\n        env_file:\n\n            - ./vnc/vnc.env\n        volumes:\n            - '/mnt/data/nzbget:/storage:rw'\n            - '~/docker/vnc/mkvtoolnix:/config:rw'\n        ports:\n            - '5820:5800'\n            - '5920:5900'\n        container_name: mkvtoolnix\n</code></pre>"},{"location":"Docker%20Apps/jlesage-vnc-apps/#ports","title":"Ports","text":"<p>The application port start from 5800/5900 for its corresponding access and add 10 for each application.</p> <ul> <li>for apps with high idle CPU or RAM, it\u2019s best to run the app on-demand and close it when not used</li> </ul> App Port Dialog Idle CPU RAM Additional Config JDownloader 5800 jdownloader Firefox 5810 MKVToolNix 5820 gtk MKVCleaver 5840 QT High MegaBasterd 5860 Github MCASelector 5870 High High Github Avidemux 5880 QT Med Med <code>WEB_AUDIO=1</code>"},{"location":"Docker%20Apps/jlesage-vnc-apps/#files","title":"Files","text":"<p><code>/config</code> is the directory which app configuration are stored and should have the correct permission, there are other additional bind mounts for <code>/storage</code> which is the default file choose location for some containers.</p> <ul> <li>any directory from host can be bind mount into anything in container; however if a directory is not created on host and the container has to create it, it\u2019s possible it will be owned by <code>root</code></li> </ul> <p>QT Based Apps that use QT based file explorer (eg. Avidemux) has the configuration stored in <code>${APP_CONFIG}/xdg/config/QtProject.ini</code>, this is used to setup file explorer shortcuts. <pre><code>[FileDialog]\nshortcuts=file:, file:///config, file:///storage, file:///mnt/data/nzbget, file:///mnt/data, file:///mnt/data2\n</code></pre></p> <p>GTK Based Apps that use GTK based file explorer (eg. MCASelector) has the configuration stored in <code>${APP_CONFIG}/xdg/config/gtk-3.0/bookmarks</code>, this is used to setup file explorer shortcuts. <pre><code>file:///world, file:///storage\n</code></pre></p> <p>There are also some application specific setup. For applications accessing hard drive or intensive apps, it is best to stop when not used. Lazytainer and ContainerNursery and possibly using DNS server can help automate this process.</p>"},{"location":"Docker%20Apps/tesla-homepage/","title":"Tesla Homepage","text":"<p>This is a homepage that allows Tesla browser to enter full screen mode.</p> <p>Docker-compose</p> <pre><code>services:\n  homepage-for-tesla:\n    image: jessewebdotcom/homepage-for-tesla:latest\n    container_name: homepage-for-tesla\n    environment:\n\n      - DEFAULT_THEME=13\n    volumes:\n      - ~/docker/tesla/public/bookmarks.json:/app/public/bookmarks.json\n      - ~/docker/tesla/public/images:/app/public/images\n    ports:\n      - \"3000:3000\"\n</code></pre>"},{"location":"Docker%20Apps/uptime-kuma/","title":"Uptime Kuma","text":"Docker Apps Rating U/GID TZ SSO/Users Existing FS Portable Subfolder Mobile \u274e \u2705* \u274c\ud83e\udd35 \u2705 \u2705 \u274c \u2714"},{"location":"Docker%20Apps/uptime-kuma/#install","title":"Install","text":"<p>Docker Compose <pre><code>services:\n  uptime-kuma:\n    container_name: uptime-kuma\n    image: louislam/uptime-kuma\n    ports:\n\n      - 3001:3001\n    environment:\n      - PUID=1001\n      - PGID=1001\n    volumes:\n      - ~/docker/uptime-kuma:/app/data\n    restart: unless-stopped\n</code></pre></p> <ul> <li>Container support non-root users  via <code>PUID/PGID</code></li> <li>default port 3001</li> </ul>"},{"location":"Docker%20Apps/uptime-kuma/#monitoring","title":"Monitoring","text":"<p>To add a monitor, follow the GUI</p> <ul> <li>Friendly name is what is displayed on the dashboard</li> <li>There is an option to define how often to check, recheck and how many times to recheck</li> <li>Setup [notification]</li> </ul>"},{"location":"Docker%20Apps/uptime-kuma/#http","title":"HTTP","text":"<p> For HTTP monitoring, it will monitor a HTTP site and give out metrics as such up/down, and the response time. - accepted response code: eg. 200-299 anything that is not accepted will be considered as down - option to check HTTPS certificate expiration</p>"},{"location":"Docker%20Apps/uptime-kuma/#docker","title":"Docker","text":"Docker Health <p>Uptime Kuma does not notify if a Docker container is unhealthy, it will show as pending. No notification will be sent. Github Issue</p> <p>Go to <code>Settings</code> -&gt; <code>Docker Hosts</code> to create a Docker host. Under <code>Add a new monitor</code>, select <code>Docker container</code> and choose the corresponding Docker host</p>"},{"location":"Docker%20Apps/uptime-kuma/#remote-hosts","title":"Remote Hosts","text":"<p>By default, it requires mounted Docker sockets. It also supported socket over tcp or a socket proxy. For remote hosts it\u2019s best to use tailscale and expose the appropriate docker socket to tailscale only.</p>"},{"location":"Docker%20Apps/uptime-kuma/#notification","title":"Notification","text":"<p>Configured under <code>Settings</code> -&gt; <code>Notifications</code></p> <ul> <li>it\u2019s possible to apply a newly added notification to all existing monitors</li> <li>when it\u2019s set as default, all new monitors will have this notification</li> </ul>"},{"location":"Docker%20Apps/uptime-kuma/#tags","title":"Tags","text":"<p>Tags can be added in <code>Settings</code> -&gt; <code>Tags</code>, it can be applied to monitors. In the main page, tags can be filtered. - tags cannot be used as a filter for status page or maintenance </p>"},{"location":"Docker%20Apps/uptime-kuma/#status-page","title":"Status Page","text":"<p>Status page Maintenance Tags SSO Monitor services behind Authelia Remote Docker Hosts Autokuma</p>"},{"location":"Docker%20Apps/webtop/","title":"Webtop (openbox-ubuntu)","text":"<pre><code>version: \"2.1\"\nservices:\n  webtop:\n    image: lscr.io/linuxserver/webtop:amd64-ubuntu-openbox\n    container_name: webtop-openbox\n    security_opt:\n\n      - seccomp:unconfined #optional\n    environment:\n      - PUID=1000\n      - PGID=1001\n      - TZ=America/Vancouver\n      - SUBFOLDER=/ # For reverse proxy\n      - TITLE=WebtopMate # The title as it shown in browser\n    volumes:\n      - ~/docker/webtop/config:/config # default home folder\n      - /mnt/data:/mnt/data\n      - /var/run/docker.sock:/var/run/docker.sock # Run docker inside docker\n    ports:\n      - 3050:3000\n    shm_size: \"1gb\" #optional\n    restart: unless-stopped\n</code></pre> <p>The default installation with config folder copied is not usable. Packages to be installed <pre><code>apt update\napt install wget terminator rsync ntp spacefm compton tint2 nitrogen nano lxappearance mousepad unrar unzip xarchiver mono-complete libhunspell-dev p7zip libmpv-dev tesseract-ocr vlc ffmpeg fonts-wqy-zenhei language-pack-zh-hans mediainfo mediainfo-gui p7zip\n</code></pre></p> <p>Packages that has to be installed manually <code>lxappearance, spacefm, tint2, nitrogen</code></p> <p>Desktop (tint2, nitrogen)</p> <ul> <li>nitrogen cannot keep <code>scaled</code> option after restarting and needs to change it manually</li> <li>nitrogen wallpaper are found in <code>/config/Pictures/wallpaper.jpg</code></li> </ul>"},{"location":"Docker%20Apps/webtop/#customization","title":"Customization","text":"<p>lxappearance</p> <ul> <li>theme: <code>Quixotic-blue</code>; location <code>.themes</code></li> <li>icon: <code>Desert-Dark-icons</code>; location <code>.icons</code> tint2</li> <li>tint2 with copied config, located in <code>.config/tint2</code></li> </ul>"},{"location":"Docker%20Apps/webtop/#firefox-browser","title":"Firefox Browser","text":"<p>policies.json <pre><code>// force install ublock, disable annoyances, add bookmarks\n{\n  \"policies\": {\n    \"ExtensionSettings\": {\n      \"uBlock0@raymondhill.net\": {\n        \"installation_mode\": \"force_installed\",\n        \"install_url\": \"https://addons.mozilla.org/firefox/downloads/latest/ublock-origin/latest.xpi\"\n      }\n    },\n    \"NoDefaultBookmarks\": true,\n    \"DisableTelemetry\": true,\n    \"Bookmarks\": [\n      {\n        \"Title\": \"zmk\",\n        \"URL\": \"https://zmk.pw\",\n        \"Placement\": \"toolbar\"\n      },\n      {\n        \"Title\": \"SubHD\",\n        \"URL\": \"https://subhd.tv\",\n        \"Placement\": \"toolbar\"\n      } // Add more bookmarks like this\n    ],\n    \"FirefoxHome\": {\n      \"Search\": true,\n      \"TopSites\": true,\n      \"SponsoredTopSites\": false,\n      \"Pocket\": false,\n      \"SponsoredPocket\": false,\n      \"Locked\": false\n    }\n  }\n}\n</code></pre></p> <ul> <li>it is not possible to backup bookmarks on the pinned menu via policies (only way is to restore from home folder)</li> <li>it\u2019s not possible to remove <code>import bookmarks</code> and <code>getting started</code> bookmarks with <code>policies.json</code> as documented here, it has to be removed manually Manual Configs</li> <li>ublock add Chinese filter</li> <li>pin bookmarks</li> <li>remove default bookmarks and getting started from toolbar</li> </ul>"},{"location":"Docker%20Apps/webtop/#files","title":"Files","text":"<p>SpaceFM</p> <ul> <li>upon installing, with config copied over, everything works fine</li> <li>configuration is stored in <code>~/.config/spacefm</code></li> </ul> <p>Movie-Renamer Script</p> <ul> <li>works after copying</li> </ul>"},{"location":"Docker%20Apps/webtop/#subtitles","title":"Subtitles","text":""},{"location":"Docker%20Apps/webtop/#subtitle-edit","title":"Subtitle Edit","text":"<p>Install dependencies Download subtitle-edit <pre><code>curl -s https://api.github.com/repos/SubtitleEdit/subtitleedit/releases/latest | grep -E \"browser_download_url.*SE[0-9]*\\.zip\" | cut -d : -f 2,3 | tr -d \\\" | wget -qi - -O SE.zip\nunzip SE.zip -d /config/subtitle-edit\n</code></pre> Subtitle-Edit Dark theme has to be changed manually</p> <ul> <li><code>Options</code> -&gt; <code>Settings</code> -&gt; <code>Appearance</code> -&gt; <code>Use Dark Theme</code></li> <li><code>Options</code> -&gt; <code>Settings</code> -&gt; <code>Syntax Coloring</code> -&gt; <code>Error color</code> and change to <code>27111D</code></li> <li><code>Options</code> -&gt; <code>Settings</code> -&gt; <code>Appearance</code> -&gt; <code>UI Font</code> -&gt; <code>General</code> and change to <code>WenQuanYi Zen Hei</code></li> </ul>"},{"location":"Docker%20Apps/webtop/#obsidian-webtop","title":"Obsidian Webtop","text":"<p>Make sure to close everything in Obsidian to reduce CPU usage.</p> <pre><code>services:\n  obsidian:\n    image: lscr.io/linuxserver/obsidian:latest\n    container_name: obsidian\n    security_opt:\n\n      - seccomp:unconfined #optional\n    environment:\n      - PUID=1000\n      - PGID=1001\n      - TZ=America/Vancouver\n      - SUBFOLDER=/obsidian/\n      - TITLE=Obsidian\n    volumes:\n      - ~/docker/obsidian-webtop:/config\n      - ~/Documents/notes:/notes\n    networks:\n      - public\n    ports:\n      - 3010:3000\n    devices:\n      - /dev/dri:/dev/dri\n    shm_size: \"1gb\"\n    restart: unless-stopped\n\nnetworks:\n  public:\n    name: public\n    external: true\n</code></pre> <ul> <li>standard procedure for PUGID, TZ and docker networks</li> <li>optional environment variable <code>PASSWORD</code> for HTTP basic auth</li> <li><code>SUBFOLDER</code> can be used for reverse proxy with custom location</li> </ul>"},{"location":"Docker%20Apps/webtop/#authentication","title":"Authentication","text":"<p>Setup of webtop with Authelia require more configurations. Needs to manually configure the custom location in Nginx Proxy Manager just like bluemap. <pre><code>location /obsidian/ {\n  proxy_set_header Upgrade $http_upgrade;\n  proxy_set_header Connection $http_connection;\n  include /snippets/proxy.conf;\n  include /snippets/authelia-authrequest.conf;\n  proxy_pass http://10.10.120.12:3010/obsidian/;\n}\n</code></pre></p> <ul> <li>the <code>proxy_set_header</code> lines are required because of websocket</li> </ul> <p>Authelia configuration (need whitelist VNC assets) <pre><code>    - domain: \"basedomainforsubfolder.mywire.org\"\n      resources:\n        - \"socket.io/*\"\n        - \"public/*\"\n        - \"vnc/*\"\n      policy: bypass\n    - domain: \"basedomainforsubfolder.mywire.org\"\n      policy: one_factor\n</code></pre></p>"},{"location":"Docker%20Apps/Downloading/rutorrent/","title":"RuTorrent","text":"<p><code>/watched</code> folder allow dropping torrents files and autodownload, the watched folder is located in the base <code>/download</code> folder</p>"},{"location":"Docker%20Apps/Media%20Apps/audiobookshelf/","title":"Audiobookshelf","text":"<p>Audiobooks and podcasts. </p> UID/GID <p>With the newer version of ABS. The environment variables <code>AUDIOBOOKSHELF_UID</code> and <code>GID</code> are removed, the container now runs as root with no ways to change it; if using the <code>user</code> flag in docker, there would be permission error on startup.</p> <p>Docker-compose, place it in the media apps compose media.yml</p> <pre><code>version: \"3.7\"\nservices:\n  audiobookshelf:\n    image: ghcr.io/advplyr/audiobookshelf:latest\n    ports:\n\n      - 13378:80\n    volumes:\n      - /mnt/m/Audios/audiobooks:/audiobooks # hard drive mount\n      - /mnt/m/Audios/podcasts:/podcasts # hard drive mount\n      - $HOME/audiobookshelf/config:/config\n      - $HOME/audiobookshelf/metadata:/metadata\n    restart: unless-stopped\n\n\u00a0 audiobookshelf-permfix:\n\u00a0 \u00a0 container_name: abs-permfix\n\u00a0 \u00a0 image: ubuntu\n\u00a0 \u00a0 networks:\n\u00a0 \u00a0 \u00a0 - public\n\u00a0 \u00a0 command: bash -c \"chown -R $${PUID}:$${PGID} /mnt; echo sleeping; sleep $${TIME}\"\n\u00a0 \u00a0 volumes:\n\u00a0 \u00a0 \u00a0 - /mnt/data/Audios/audiobooks:/mnt/audiobooks # hard drive mount\n\u00a0 \u00a0 \u00a0 - /mnt/data/Audios/podcasts:/mnt/podcasts # hard drive mount\n\u00a0 \u00a0 \u00a0 - ~/docker/audiobookshelf/config:/mnt/config\n\u00a0 \u00a0 \u00a0 - ~/docker/audiobookshelf/metadata:/mnt/metadata\n\u00a0 \u00a0 environment:\n\u00a0 \u00a0 \u00a0 - PUID=1000\n\u00a0 \u00a0 \u00a0 - PGID=1001\n\u00a0 \u00a0 \u00a0 - TIME=1h\n\u00a0 \u00a0 restart: unless-stopped\n</code></pre> <ul> <li>The change made to the docker-compose include a <code>permfix</code> that automatically <code>chown</code> everything in audiobookshelf bind mounts<ul> <li>mount everything into <code>/mnt</code></li> <li>change the user and group ID accordingly</li> </ul> </li> </ul>"},{"location":"Docker%20Apps/Media%20Apps/audiobookshelf/#usage","title":"Usage","text":"<p>To add a library, go to settings, libraries and add the path as mounted in docker.</p> <p>Go to Users, change the root password and create a new user. Note, the user cannot scan library, only the root can do that.</p> <p></p>"},{"location":"Docker%20Apps/Media%20Apps/audiobookshelf/#adding-media","title":"Adding Media","text":"<p>Make sure the contents are in a separate folder. Follow naming like this. A cover image can also be created. The best bitrate should be under 128 kbps for smooth playback.</p> <pre><code>/audiobooks\n--- ./Author - Book\n---  --- ./Cover.jpg\n---  --- ./book - 001 or book - chapter 1\n---  --- ./book - 002\n---  --- ./book - 003\n</code></pre> <p>In the WebUI, make sure logged in as root. Go to settings, library and scan. It will scan the newly added media. Also useful for dealing with unplayable file errors.</p> <p>It is also possible to upload via the WebUI. When files are uploaded this way, it is also be placed in the audiobooks folder. However, it is not possible to add more files via the web upload once it\u2019s scanned.</p> <p>Additional Metadata <code>Cover.jpg</code> - cover image <code>desc.txt</code> - descriptions <code>*.opf</code> - XML library file that contains additional metadata such as title, author etc.. Vocabulary <code>abridged/unabridged</code> - shortened listening version <code>primary/supplementary ebooks</code> - primary ebooks are</p> <p>If the media does not match or not have an image, go click the edit icon, go to <code>Match</code>, the best result is usually <code>Audible.com</code>.</p> <p></p> <p>If the chapter does not match, chapters can be edited manually. Go to Chapter and Lookup.</p>"},{"location":"Docker%20Apps/Media%20Apps/audiobookshelf/#mobile-app","title":"Mobile App","text":"<p>https://play.google.com/store/apps/details?id=com.audiobookshelf.app</p> <p>Mobile app also has download functionality, however, the directory cannot be changed, the default for download is <code>/Internal Storage/Download/{Podcast or Audiobook}</code></p> <p>The statistic of minutes listened is the actual minutes listened, not the minutes of audiobook progress listened (eg. playing at faster speed).</p>"},{"location":"Docker%20Apps/Media%20Apps/audiobookshelf/#backuprestore","title":"Backup/Restore","text":"<p>In the WebUI, go to <code>Settings</code> &gt; <code>Backups</code> and there will be option for backup/restore. Alternatively, copy the entire appdata folder to another computer.</p>"},{"location":"Docker%20Apps/Media%20Apps/audiobookshelf/#scripting-windows","title":"Scripting (Windows)","text":"<p>ffmpeg detect audio silence (for splitting a large audio file into multiple chapters)</p> <pre><code>ffmpeg -i input.mp3 -af silencedetect=n=-50dB:d=1.5 -f null -\n</code></pre> <pre><code>ffmpeg -i input.mp3 -af silencedetect=n=-50dB:d=1.5 -f null -loglevel debug 2&gt;&amp;1 - | findstr \"silence_duration\" | find /c /v \"\"\n</code></pre> <p>This will find silence parts below -50dB and duration threshold of 1.5s.</p> <p>The second code (windows cmd only) for linux use grep -c, finds how many silence parts can be detected, this should correlate to number of chapters.</p> <p>Once the optimal duration is set, use split.py.</p> <p>ffmpeg that remove silence from audio</p> <pre><code>ffmpeg -i input.mp4 -af silenceremove=stop_periods=-1:stop_duration=4:stop_threshold=-50dB -b:a 96k output.mp3\n</code></pre> <ul> <li>stop_duration (threshold duration for removing silence part)</li> <li>stop_periods = -1 (search for the entire audio track)</li> </ul> <p>Use edge_reader.py to utilize Edge AI reader to read the audiobook if only the pdf book is provided.</p> <p>After reading, put all the recorded files and pdf in the project folder and run processing.py twice.</p>"},{"location":"Docker%20Apps/Media%20Apps/jellystat/","title":"Jellystat","text":"Docker Apps Rating U/GID TZ SSO/Users Portable Subfolder \u274e \u2705* \u274c\ud83e\udd35 \u2705 \u274c <p>https://github.com/CyferShepard/Jellystat</p>"},{"location":"Docker%20Apps/Media%20Apps/jellystat/#install","title":"Install","text":"<p>Docker Compose (minimum viable setup) <pre><code>services:\n\u00a0 jellystat-db:\n\u00a0 \u00a0 container_name: jellystat-db\n\u00a0 \u00a0 image: postgres:15\n\u00a0 \u00a0 user: 1000:1001\n\u00a0 \u00a0 env_file:\n\u00a0 \u00a0 \u00a0 - jellystat.env\n\u00a0 \u00a0 environment:\n\u00a0 \u00a0 \u00a0 POSTGRES_DB: 'jellystat'\n\u00a0 \u00a0 \u00a0 TZ: 'America/Vancouver'\n\u00a0 \u00a0 \u00a0 PGTZ: 'America/Vancouver'\n\u00a0 \u00a0 volumes:\n\u00a0 \u00a0 - ~/docker/jellystat/db:/var/lib/postgresql/data # Mounting the volume\n\u00a0 \u00a0 restart: unless-stopped\n\n\u00a0 jellystat:\n\u00a0 \u00a0 image: cyfershepard/jellystat:latest\n\u00a0 \u00a0 container_name: jellystat\n\u00a0 \u00a0 user: 1000:1001\n\u00a0 \u00a0 env_file:\n\u00a0 \u00a0 \u00a0 - jellystat.env\n\u00a0 \u00a0 environment:\n\u00a0 \u00a0 \u00a0 POSTGRES_IP: jellystat-db\n\u00a0 \u00a0 \u00a0 POSTGRES_PORT: 5432\n\u00a0 \u00a0 ports:\n\u00a0 \u00a0 \u00a0 - \"5050:3000\" #Server Port\n\u00a0 \u00a0 volumes:\n\u00a0 \u00a0 \u00a0 - ~/docker/jellystat/app:/app/backend/backup-data # Mounting the volume\n\u00a0 \u00a0 depends_on:\n\u00a0 \u00a0 \u00a0 - jellystat-db\n\u00a0 \u00a0 restart: unless-stopped\n</code></pre></p> <p>The content of <code>jellystat.env</code> <pre><code>POSTGRES_USER=jellystat\nPOSTGRES_PASSWORD=\nJWT_SECRET=\n</code></pre></p> <ul> <li>Use both <code>PGTZ</code> and <code>TZ</code> to set timezone logging</li> <li>The environment <code>POSTGRES_DB</code> may not work, the default database is <code>jfstat</code> The secret can be generated with <pre><code>openssl rand -base64 64 | tr -d '\\ n'\n</code></pre></li> </ul>"},{"location":"Docker%20Apps/Media%20Apps/jellystat/#usage","title":"Usage","text":"<p>Jellyfin API key is needed to configure it. The app will show login/configuration screen. No other configurations are nessecary.</p>"},{"location":"Docker%20Apps/Media%20Apps/jellystat/#backuprestore","title":"Backup/Restore","text":"<p>If using bind mount, simply copy the files in the bind mount and everything will work on the new machine without issues. No database dumps, other steps are necessary.</p> <ul> <li>ensure the username/password/secret in the environments are matching</li> </ul>"},{"location":"Docker%20Apps/Media%20Apps/jellystat/#reverse-proxysso","title":"Reverse Proxy/SSO","text":"<p>App do not have SSO support. The internal login cannot be disabled, github issue. App do not support subfolders, only subpath supported. No special requirements needed when using Nginx Proxy Manager. If the frontend is in the same network as proxy, simply <code>jellystat:3000</code> is enough.</p> <p></p>"},{"location":"Docker%20Apps/Media%20Apps/rich-media/","title":"Rich Media","text":"<p>Hello Everyone</p> <p>This is a demo consisting of medias.</p> <p></p> <p>Some Code</p> <pre><code>docker-compose up -d\n</code></pre> <pre><code>import os\nimport time\n\nprint(\"hello world\")\nif a=b:\n  print(a)\nelif b=c:\n  try:\n    print(c)\n  except:\n    print(c+a)\nelse:\n  print(\"what is the meaning of life\")\n</code></pre> <p>More sample media</p> <p></p> <p>Portainer is a software for managing docker containers.</p>"},{"location":"Docker%20Apps/Minecraft/bluemap/","title":"Bluemap","text":"Docker Apps Rating U/GID TZ SSO/Users Portable Subfolder Mobile n/a n/a \u274e\ud83e\udd35 n/a \u2705 \u2714 <p>https://bluemap.bluecolored.de/wiki/</p>"},{"location":"Docker%20Apps/Minecraft/bluemap/#installation","title":"Installation","text":"<p>Download bluemap and place it in minecraft plugin folder, Docker version also available.</p>"},{"location":"Docker%20Apps/Minecraft/bluemap/#configuration","title":"Configuration","text":"<p>Config files are located in <code>plugins/Bluemap</code> Change the line in <code>core.conf</code> so the app functions <pre><code>accept-download: true\n</code></pre></p> <ul> <li><code>data: \"bluemap\"</code> the data location is not in <code>plugins</code> base folder but relative to base folder of the minecraft docker container<ul> <li>the default is located in <code>&lt;docker_mc_folder&gt;/bluemap</code></li> </ul> </li> <li>Default port is 8100, change in <code>webserver.conf</code></li> </ul>"},{"location":"Docker%20Apps/Minecraft/bluemap/#resource-pack","title":"Resource pack","text":"<p>Add a <code>.zip</code> into <code>plugin/Bluemap/packs</code> The <code>.zip</code> folder should have on the files in its root folder</p> <ul> <li><code>.zip</code> -&gt; <code>resource_pack\\</code> -&gt; <code>[pack.mcmeta, assets ...]</code> not OK</li> <li><code>.zip</code> -&gt; <code>[pack.mcmeta, assets ...]</code> OK</li> </ul>"},{"location":"Docker%20Apps/Minecraft/bluemap/#markers","title":"Markers","text":"<p>To see the changes <code>docker attach mcserver</code> then execute <code>bluemap reload</code></p>"},{"location":"Docker%20Apps/Minecraft/bluemap/#marker-set","title":"Marker Set","text":"<p>https://bluemap.bluecolored.de/wiki/customization/Markers.html <pre><code>debug-set: {\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 label: \"Debug Set\"\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 toggleable: true\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 default-hidden: false\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 sorting: 1\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 markers: {\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n\u00a0 \u00a0 }\n</code></pre></p> <ul> <li>multiple sets can be added in this format </li> <li><code>label</code> the name that is will appear (the <code>debug-set</code> is just an identifier)</li> <li><code>sorting</code> the order which it will appear</li> </ul>"},{"location":"Docker%20Apps/Minecraft/bluemap/#html","title":"HTML","text":"<p>Marker that shows an HTML element, for example a text label. <pre><code>\u00a0marker-html: {\n\u00a0 \u00a0 \u00a0type: \"html\"\n\u00a0 \u00a0 \u00a0position: { x: -132, y: 72, z: -202 }\n\u00a0 \u00a0 \u00a0label: \"Karis\"\n\u00a0 \u00a0 \u00a0html: \"&lt;html code&gt;\"\n\u00a0 \u00a0 \u00a0anchor: { x: 0, y: 0 }\n\u00a0 \u00a0 \u00a0sorting: 0\n\u00a0 \u00a0 \u00a0listed: true\n\u00a0 \u00a0 \u00a0min-distance: 50\n\u00a0 \u00a0 \u00a0max-distance: 750\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n</code></pre></p> <ul> <li><code>type</code> set to <code>html</code></li> </ul> <p>HTML Code <pre><code>&lt;div style='line-height: 1em; font-size: 1.2em; color: black; font-weight: bold; background-color: white; transform: translate(-50%, -50%);'&gt;Karis&lt;/div&gt;\n</code></pre> This HTML code have black text with white background, bolded  To have a multiline text, just copy the <code>&lt;div&gt;</code> part again</p>"},{"location":"Docker%20Apps/Minecraft/bluemap/#line","title":"Line","text":"<p>Marker is a 3D line that can be clicked to show <code>label</code> or <code>detail</code>, color can be customized. <pre><code>line-marker: {\n\u00a0 \u00a0 \u00a0 type: \"line\"\n\u00a0 \u00a0 \u00a0 position: { x: -42, y: 70, z: -340 }\n\u00a0 \u00a0 \u00a0 label: \"Text to Display\"\n\u00a0 \u00a0 \u00a0 line: [\n\u00a0 \u00a0 \u00a0 \u00a0 { x: -42, y: 70, z: -340 },\n\u00a0 \u00a0 \u00a0 \u00a0 { x: 37, y: 90, z: -325 },\n\u00a0 \u00a0 \u00a0 \u00a0 { x: 102, y: 115, z: -312 }\n\u00a0 \u00a0 \u00a0 ]\n\u00a0 \u00a0 \u00a0 line-color: {r: 255, g: 0, b: 0, a: 1}\n\u00a0 \u00a0 \u00a0 line-width: 3\n\u00a0 \u00a0 \u00a0 detail: \"HTML code\"\n\u00a0 \u00a0 \u00a0 max-distance: 1500\n\u00a0 \u00a0 }\n</code></pre> </p> <ul> <li><code>position</code> - the starting position</li> <li><code>line</code> - array of xyz coordinates (can include starting position)</li> <li><code>line-color</code> - RGBA value</li> <li><code>label</code> and <code>detail</code> will both display the name of the line marker<ul> <li>setting anything in detail will override label It good idea to set the y above the value that is appears on map, if a line is covered by a block, that part of the line will not show.</li> </ul> </li> </ul>"},{"location":"Docker%20Apps/Minecraft/bluemap/#poi","title":"POI","text":"<p>Marker that can be clicked and shows the <code>label</code> text, with option to add custom icons. <pre><code>\u00a0 \u00a0 \u00a0 \u00a0 poi-marker-1: {\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type: \"poi\"\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 position: { x: 273, y: 62, z: 640 }\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 label: \"Village Marker 1\"\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 icon: \"assets/poi.svg\"\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 max-distance: 400\n\u00a0 \u00a0 \u00a0 \u00a0 } \n</code></pre> </p> <p><code>icon</code> - can be any HTML image type</p> <ul> <li>the default icon size is <code>50px</code> as shown in preview</li> <li>icons must be stored in <code>/blue/web/assets</code> to be used </li> <li><code>svg</code> vector type is preferred over <code>png</code> due to small size constraint<ul> <li><code>svg</code> created in illustrator need <code>width=\"50px\" height=\"50px\"</code> for it to work properly</li> </ul> </li> </ul> Weird behavior with dark mode/different browsers <p>On Brave browser mobile dark mode, icons do not show. On Chrome Windows, while markers works, the text style such as <code>bold</code> do not work</p>"},{"location":"Docker%20Apps/Minecraft/bluemap/#shape","title":"Shape","text":"<p>Flat, 2D only box that covers an area. <pre><code>\u00a0 \u00a0 \u00a0 \u00a0 terrain-park: {\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type: \"shape\"\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 label: \"Example Shape Marker\"\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 position: { x: 186, z: -321 }\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 shape: [\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 { x: 186, z: -321 }\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 { x: 184, z: -374 }\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 { x: 168, z: -368 }\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 { x: 169, z: -316 }\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 { x: 186, z: -308 }\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 line-width: 2\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 line-color: { r: 255, g: 0, b: 0, a: 1.0 }\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fill-color: { r: 200, g: 0, b: 0, a: 0.3 }\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 shape-y: 86\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 max-distance: 1400\n\u00a0 \u00a0 \u00a0 \u00a0 }\n</code></pre></p> <ul> <li><code>shape</code>, only the x and z values are needed, no height</li> <li><code>shape-y</code> the height which the shape appears<ul> <li>if there are blocks above the plane of <code>shape-y</code>: part of that shape will be covered</li> <li>if there are no blocks below the plane of <code>shape-y</code>: the shape will appear floating (refer the image above)</li> </ul> </li> <li><code>color</code>, has a line and fill component, a fill with <code>a:</code> less than 1 decrease the opacity</li> </ul>"},{"location":"Docker%20Apps/Minecraft/bluemap/#render-distance","title":"Render Distance","text":"<ul> <li>for flat view, any view distance below 400 would not show</li> <li>as the view distance increase, the icon/html/line will gradually fade out</li> </ul>"},{"location":"Docker%20Apps/Minecraft/bluemap/#reverse-proxysso","title":"Reverse Proxy/SSO","text":"<p>The reverse proxy and authentication setup for subdomain is as usual in Nginx Proxy Manager. App has no built-in authentication so Authelia SSO is supported.</p>"},{"location":"Docker%20Apps/Minecraft/bluemap/#subpath-with-sso","title":"Subpath with SSO","text":"Nginx Proxy ManagerCaddy <p>The custom locations tab do not work, need to add it manually. Go to <code>Advanced</code> and edit these in the custom Nginx configuration. <pre><code>location /map/ {\n    include /snippets/proxy.conf;\n    include /snippets/authelia-authrequest.conf;\n    proxy_pass http://10.10.120.16:8100/;\n  }\n</code></pre></p> <ul> <li>Not tested yet </li> </ul>"},{"location":"Docker%20Apps/Minecraft/bluemap/#internal-use-only","title":"Internal Use Only","text":"<p>For public viewer, these parts are not relevant for setup. This is for setup of my specific server and guidelines.</p> <p>Ski Slopes Red - default color Black - default color Green -  <code>line-color: {r: 40, g: 255, b: 40, a: 1}</code> Blue - <code>line-color: {r: 0, g: 100, b: 200, a: 1}</code></p> <p>Roads Roads- <code>line-color: {r: 240, g: 220, b: 150, a: 1}</code></p>"},{"location":"Docker%20Apps/Minecraft/minecraft-prep-and-install/","title":"Minecraft Prep and Install","text":""},{"location":"Docker%20Apps/Minecraft/minecraft-prep-and-install/#client-setup-java-online","title":"Client Setup (Java + Online)","text":"<ol> <li>Download Java</li> <li>Download OptiFine the latest version.</li> <li>On the official Minecraft client, go add a new installation and match the version with OptiFine.</li> <li>Download and try the official version, then install OptiFine with Java.</li> <li>Under Settings -&gt; Keep the Launcher open while games are running</li> </ol>"},{"location":"Docker%20Apps/Minecraft/minecraft-prep-and-install/#client-setup-java-offline","title":"Client Setup (Java + Offline)","text":"<ol> <li>Use the client PolyMC to enable offline play.</li> <li>Go to the right corner, manage accounts and create an offline account.</li> <li>Click on add an instance and follow the guide.</li> <li>To install OptiFine, need the official launcher first, then download OptiFine</li> <li>Extract OptiFine, the extracted file should be ending in _MOD.jar</li> <li>Open the jar file in WinRAR, then move the files from notch folder into the base folder. Save the jar archive.</li> <li>Go to PolyMC, right click on the instance, click Edit -&gt; Versions -&gt; Add to minecraft.jar and select the modified OptiFine.</li> </ol>"},{"location":"Docker%20Apps/Minecraft/minecraft-prep-and-install/#docker-server-setup","title":"Docker Server Setup","text":"<p>Docker-compose for minecraft server</p> <pre><code>version: \"3.9\"\nservices:\n  minecraft:\n    image: marctv/minecraft-papermc-server:latest\n    restart: unless-stopped\n    container_name: mcserver\n    environment:\n\n      - MEMORYSIZE=4G\n      - PAPERMC_FLAGS=\"\"\n      - PUID=1000\n      - PGID=1000\n    volumes:\n      - ~/docker/minecraft:/data:rw\n    ports:\n      - 25565:25565\n      - 19132:19132\n      - 19132:19132/udp # geyser\n\u00a0 \u00a0 \u00a0 - 8100:8100 # bluemap\n    stdin_open: true\n    tty: true\n</code></pre> <p>This downloads the latest version of Minecraft, to use another PaperMC version, need to build the image from scratch.</p> <p>Warning: PaperMC cannot be downgraded, only newer version of PaperMC can be installed after first run.</p> <pre><code>git clone https://github.com/mtoensing/Docker-Minecraft-PaperMC-Server\n# go edit the \"ARG version=1.xx.x\" to the correct version\ndocker build -t marctv/mcserver:1.xx.x\n</code></pre>"},{"location":"Docker%20Apps/Minecraft/minecraft-prep-and-install/#folders-and-plugins","title":"Folders and Plugins","text":"<p>Plugins are located in folder <code>./plugins</code> some plugins have .yml files. To update or download plugins, use scp, wget on the server or VSCode.</p> <p>The <code>world</code> folder consists of the save data. It is separated into world, nether, the_end.</p> <p>Before starting the server, the <code>eula.txt</code> must have eula=true.</p> <p><code>bukkit</code> and <code>spigot.yml</code> in the root folder are configuration files for PaperMC.</p>"},{"location":"Docker%20Apps/Minecraft/minecraft-prep-and-install/#rcon-commands","title":"Rcon Commands","text":"<p>To access the rcon-cli, use <code>docker attach mcserver</code>, to exit, use Ctrl-P and Q, if using VSCode may need to edit keyboard shortcut.</p> <p>Editing VSCode Shortcut Press <code>Ctrl-Shift-P</code> and search for keyboard shortcut json.</p> <pre><code>[\n    {\n        \"key\": \"ctrl+p\",\n        \"command\": \"ctrl+p\",\n        \"when\": \"terminalFocus\"\n    },\n\n    {\n        \"key\": \"ctrl+q\",\n        \"command\": \"ctrl+q\",\n        \"when\": \"terminalFocus\"\n    },\n\n    {\n        \"key\": \"ctrl+e\",\n        \"command\": \"ctrl+e\",\n        \"when\": \"terminalFocus\"\n    }\n\n]\n</code></pre>"},{"location":"Docker%20Apps/Minecraft/useful-plugins/","title":"Useful Plugins","text":"<p>WorldEdit</p> <p>EssentialX</p> <p>CoreProtect</p> <p>ViaVersions - allow other similar version to join the server without conflict</p> <p>bluemap</p> <p>Geyser</p> <p>WorldGuard</p>"},{"location":"Docker%20Apps/Minecraft/useful-plugins/#offline-modemobile-bedrock","title":"Offline Mode/Mobile Bedrock","text":"<p>To allow offline play for PC version. Change <code>server.properties</code> and edit these lines <pre><code>enforce-whitelist=false\nonline-mode=false\n</code></pre> Refer to  Minecraft Prep and Install to install offline client.</p> <p>For bedrock compatibility, need the geyser plugin.</p> <p>To allows offline play for bedrock mobile version. Go to <code>./plugins/Geyser-Spigot/config.yml</code> and change these lines. Do not install the plugin floodgate, if it\u2019s installed, removed the plugin. ViaVersions is also needed for mobile play.</p> <pre><code>auth-type: offline\nenable-proxy-connections: true\n</code></pre> <p>Now client can play without login to Xbox or Java.</p>"},{"location":"Docker%20Apps/Web/caddy/","title":"Custom Caddy Lego","text":"<p>https://github.com/vttc08/caddy-lego Customized caddy docker container that has Dynu support for wildcard certificates.</p>"},{"location":"Docker%20Apps/Web/caddy/#install","title":"Install","text":"<p>Create a Docker network specific to publicly accessible container. <pre><code>docker network create public --subnet 172.80.0.0/16\n</code></pre></p> <ul> <li> <p>the Caddy container will have IP address of <code>172.80.44.3</code> <pre><code>services:\n  caddy:\n    image: vttc08/caddy\n    container_name: caddy\n    ports:\n      - 80:80\n      - 443:443\n    volumes:\n      - ~/docker/caddy/Caddyfile:/etc/caddy/Caddyfile\n      - ~/docker/caddy/www:/www\n    env_file:\n      - .env\n    environment:\n      - WHITELIST=${WHITELIST}\n    networks:\n      public:\n        ipv4_address: 172.80.44.3\n    restart: unless-stopped\n\nnetworks:\n  public:\n    external: true\n    name: public\n</code></pre></p> </li> <li> <p>the volume of caddy follows all other docker apps which is at <code>~/docker</code></p> </li> <li><code>.env</code> file for <code>DYNU_API_KEY</code> which will be used for SSL</li> <li>create a network <code>public</code> with the IP address</li> <li>it is not the best idea to use <code>user:</code> since it may break container function; however, it all the files are present when mounted Caddy should not change the permissions</li> <li><code>WHITELIST</code> is an environment variable that contains the IP address that can be only allowed on certain services<ul> <li>this can be created in <code>~/.bashrc</code> and sourced <pre><code>export WHITELIST=123.456.789.0\n</code></pre></li> </ul> </li> </ul> <p>The content of <code>.env</code> <pre><code>DYNU_API_KEY=\nWEBSITE=\nHTTPS=\nEMAIL=\n</code></pre></p> <ul> <li><code>HTTPS</code> list of domains so Caddy doesn\u2019t error when parsing comma; <code>\"*.website.dynu.com, website.dynu.com\"</code></li> <li><code>WEBSITE</code> just the website name <code>website.dynu.com</code></li> </ul>"},{"location":"Docker%20Apps/Web/caddy/#dockerfile","title":"Dockerfile","text":"<p>If the provided image doesn\u2019t work, need to build a image on the server itself. <pre><code>FROM caddy:2.7.5-builder-alpine AS builder\n\nRUN xcaddy build \\\n    --with github.com/caddy-dns/lego-deprecated\n\nFROM caddy:2.7.5\n\nCOPY --from=builder /usr/bin/caddy /usr/bin/caddy\n</code></pre> Then modify the <code>image</code> part of <code>compose.yml</code> <pre><code>    build:\n      context: .\n      dockerfile: Dockerfile\n</code></pre></p>"},{"location":"Docker%20Apps/Web/caddy/#caddyfile","title":"Caddyfile","text":"<pre><code>{\n    email {$EMAIL}\n}\n</code></pre>"},{"location":"Docker%20Apps/Web/caddy/#basic-website","title":"Basic Website","text":"<pre><code>:80 {\n        root * /usr/share/caddy\n        file_server\n}\n</code></pre>"},{"location":"Docker%20Apps/Web/caddy/#https","title":"HTTPS","text":"<pre><code>{$HTTPS} {\n        tls {\n                dns lego_deprecated dynu\n        }\n\n        # Standard reverse proxy\n        @web host web.{$WEBSITE$}\n        handle @web {\n                reverse_proxy mynginx:80\n        }\n}\n</code></pre> <ul> <li>start with <code>*.website</code> to indicate wildcard</li> <li>the tls block uses dynu</li> <li>declare <code>@web host</code> with the subdomain name <ul> <li>this is later used in <code>handle @web</code></li> <li>use <code>reverse_proxy</code> block to define the port to be reverse proxied In this method, only Docker containers that is in the same Docker network of <code>public</code> can be reverse proxied. By the internal port and via container names. Tailscale IP entries should also work.</li> </ul> </li> </ul>"},{"location":"Docker%20Apps/Web/caddy/#html-file-server","title":"HTML File Server","text":"<p>If caddy uses bind mount and access to the root of HTML files, it can be file server. First need to create the bind mount in <code>/www</code> of the container. Then edit the Caddyfile <pre><code>        @fs host fs.{$WEBSITE}\n        handle @fs {\n                root * /www\n                file_server\n                encode gzip\n        }\n</code></pre></p>"},{"location":"Docker%20Apps/Web/caddy/#environment-variables","title":"Environment Variables","text":"<p>The previous codeblock already utilize environment variables. The syntax is <code>{$NAME}</code>.</p>"},{"location":"Docker%20Apps/Web/caddy/#whitelisting","title":"Whitelisting","text":"<p><pre><code>                @blocked not remote_ip {$WHITELIST}\n                respond @blocked \"Unauthorized\" 403\n</code></pre> This respond 403 unauthorized on any IP addresses not in whitelist.</p>"},{"location":"Docker%20Apps/Web/caddy/#usage","title":"Usage","text":""},{"location":"Docker%20Apps/Web/caddy/#reloading","title":"Reloading","text":"<pre><code>docker exec -w /etc/caddy caddy caddy reload\n</code></pre>"},{"location":"Docker%20Apps/Web/ddns-update/","title":"Dynamic DNS Updater Docker","text":"<p>Official Image: https://hub.docker.com/r/linuxserver/duckdns Custom Github Page: https://github.com/vttc08/docker-duckdns-dynu</p> <p>This is a docker container that automatically updates the public IPv4 address of the server every 5 minutes to dynamic DNS services Dynu and DuckDNS. It is the fork of Linuxserver DuckDNS container.</p>"},{"location":"Docker%20Apps/Web/ddns-update/#docker-compose","title":"Docker Compose","text":"<pre><code>  services:\n      duckdns:\n        image: vttc08/docker-duckdns-dynu:latest\n        container_name: duckdns\n        env_file: ddns.env\n        environment:\n\n          - TZ=America/Vancouver\n          - PUID=1000\n          - PGID=1001\n        restart: unless-stopped\n</code></pre> <p>These need to be filled in the <code>ddns.env</code> <pre><code>DYNU_HOST= # full name of dynu domains\nDYNU_PASS= # md5 hashed dynu login pass\nSUBDOMAINS= # DuckDNS domains without the duckdns.org part\nTOKEN= # DuckDNS token \n</code></pre></p> <ul> <li>token will be visible in DuckDNS dashboard</li> <li>Dynu pass is the same as login; alternatively, it is possible to create a dedicated password  just for IP update  MD5 generator <pre><code>echo -n \"password\" | md5sum\n</code></pre></li> <li>when setting the IP to <code>10.0.0.0</code> in Dynu update API, dynu will automatically update the IP address to the IP address making that request</li> </ul>"},{"location":"Docker%20Apps/Web/ddns-update/#other-usage","title":"Other Usage","text":"<p><code>docker restart duckdns</code> will manually run IP update <code>docker exec -it duckdns /app/debug.sh</code> or other scripts, debug script will print out IP address of subdomains resolved by Cloudflare</p>"},{"location":"Docker%20Apps/Web%20Archive/youtube-archiving/","title":"YouTube Archive","text":""},{"location":"Docker%20Apps/Web%20Archive/youtube-archiving/#pinchflat","title":"Pinchflat","text":"Docker Apps Rating <p>| U/GID | TZ  | SSO/Users | ExistingFS | Portable | Mobile | | ----- | \u2014 | --------- | -------- | -------- | ------- | -------- | | \u274e     | \u2705*  | n/a      | \u274c        | \u2705 | \u2714 |</p> <p>YouTube archiving solution. Default port <code>8945</code>. Default credential <code>none</code>.</p>"},{"location":"Docker%20Apps/Web%20Archive/youtube-archiving/#install","title":"Install","text":"<pre><code>services:\n  pinchflat:\n    container_name: pinchflat\n    image: ghcr.io/kieraneglin/pinchflat:latest\n    user: 1000:1001\n    environment:\n\n      - TZ=America/Vancouver\n    ports:\n      - '8945:8945'\n    networks:\n      - archive\n    volumes:\n      - ~/docker/pinchflat:/config\n      - /mnt/nvme/share/youtube:/downloads\n    restart: unless-stopped\n\nnetworks:\n  archive:\n    name: archive\n</code></pre> <ul> <li><code>user</code> definition to fix permission issues, container will run fine</li> <li>app uses <code>sqlite</code> database for volumes in <code>/config</code></li> <li>create custom network <code>archive</code> to easy container access with other apps</li> </ul>"},{"location":"Docker%20Apps/Web%20Archive/youtube-archiving/#usage","title":"Usage","text":""},{"location":"Docker%20Apps/Web%20Archive/youtube-archiving/#media-profile","title":"Media Profile","text":"<p>The profile eg. resolution sponsorblock settings that is used to download videos also consist of renaming. The syntax are listed like such <code>/{{ source_custom_name }}/{{ channel }}/{{ upload_yyyy_mm_dd }} - {{ title }}.{{ ext }}</code>. More templates are available for customization. The example above shows a good naming for Jellyfin.</p>"},{"location":"Docker%20Apps/Web%20Archive/youtube-archiving/#sources","title":"Sources","text":"<p>The sources are YouTube playlist or channels. To download a Media Profile must be applied for the source. </p> <ul> <li>each source can have a custom name that can be applied as <code>{{ source_custom_name }}</code> The preferred method for indexing is <code>fast indexing</code> The <code>Download Cutoff Date</code> can be set and only videos uploaded after that day will be downloaded.</li> </ul> <p>Cutoff Date != Index</p> <p>The cutoff date set there does not prevent indexing. When a source is added, everything will be indexed even before the cutoff date. This will take a very long time on a big channel.</p>"},{"location":"Docker%20Apps/Web%20Archive/youtube-archiving/#cookies","title":"Cookies","text":"<p>The app support downloading private playlists via YouTube cookies. Cookies appears to be short-lived, more observations needed. (maybe use oauth2 plugin)</p>"},{"location":"Docker%20Apps/Web%20Archive/youtube-archiving/#api-key","title":"API Key","text":"<p>https://github.com/kieraneglin/pinchflat/wiki/Generating-a-YouTube-API-key API key can be used to for fast indexing.</p>"},{"location":"Docker%20Apps/Web%20Archive/youtube-archiving/#behavior","title":"Behavior","text":"<p>Pinchflat is not a media server, it only manage downloads not the files. Hence previous media cannot be imported. Everything is stored in its internal database.</p> <p>Deleting or managing the file in other applications will not get reflected by the app.</p> <ul> <li>if the file is deleted in the filesystem, it will still exist in app but no video will exists and the video needs to be redownloaded</li> <li>the only way to delete files is to delete via the app</li> </ul> <p>Media profile for each sources only have 1 chance of settings it right</p> <ul> <li>when changing media profile or editing profiles after a source is added and downloaded, even refreshing the metadata does not work</li> </ul> <p>New changes to sources are not reflected immediately</p> <ul> <li>eg. when changing the cutoff date or when a new video is added to playlist or channel</li> <li>to have it download new videos immediately, need to manually <code>force index</code></li> </ul>"},{"location":"Linux%20Server/debian-based-server-setup/","title":"Debian-Based Server Setup","text":"<p>Run update and upgrade distro first. Install NTP package is there are errors with that. Reboot</p> <p>Setup powertop and powersaving features</p> <pre><code>sudo apt install powertop\npowertop --auto-tune\n</code></pre> <p>Powersave governor and at reboot. Remember to run the command again</p> <pre><code>@reboot echo \"powersave\" | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor &gt;/dev/null 2&gt;&amp;1\n</code></pre> <p>Ensure these packages are installedi</p> <pre><code>powertop htop iotop fio curl gnupg wget ntfs-3g neofetch ca-certificates lsb-release hdparm hd-idle openssh-server at autojump screen bash-completion\n</code></pre> <ul> <li>after installing <code>bash-completion</code>, need to source <code>.bashrc</code> for Docker autocomplete to work</li> </ul>"},{"location":"Linux%20Server/debian-based-server-setup/#hdd","title":"HDD","text":"<p><code>lsblk</code> and <code>blkid</code> to get the ntfs hard drive /dev name and the /dev/by-uuid/\u2026</p> <p>Edit the fstab to mount the drive, same entry for nvme drive</p> <pre><code>UUID=CC34294F34293E38 /mnt/data ntfs-3g 0 0\n</code></pre> <p>If the mounted device is HDD array, need to spindown disk with hdparm</p> <pre><code>hdparm -B 120 /dev/sdb # set the APM level\nhdparm -S 241 /dev/sdb\n</code></pre> <p>For the -S spindown, 0-240 is multiple of 5s, 241-255 is multiple of 30 min. The above command set spindown every 30min.</p> <p>If hdparm does not work, hd-idle can be used. Edit the file in <code>/etc/defaults/hd-idle</code></p> <pre><code>-i 60 -a disk/by-uuid/xxx -l /var/log/hd-idle.log\n</code></pre> <p>Sudo without password, go to visudo and add the lines to the bottom, replace $USER with the actual username.</p> <pre><code>$USER ALL=(ALL) NOPASSWD: ALL\n</code></pre> <p>Edit shortcuts in bashrc</p> <pre><code>source .bashrc\n</code></pre>"},{"location":"Linux%20Server/debian-based-server-setup/#openssh-with-keys","title":"OpenSSH with Keys","text":""},{"location":"Linux%20Server/debian-based-server-setup/#generate-the-key-using-the-terminal","title":"Generate the key using the terminal","text":"<pre><code>ssh-keygen\n</code></pre> <ul> <li>give a location to put the key pair</li> <li>this generate a public (.pub) and private key pair</li> </ul> <pre><code>ssh-copy-id -i key.pub username@server\n</code></pre> <ul> <li><code>key.pub</code> is the public key that was generated</li> </ul> <p>The key is ready to use for authorization.</p>"},{"location":"Linux%20Server/debian-based-server-setup/#generate-keys-using-putty-software","title":"Generate keys using PuTTY software","text":"<ol> <li>Copy the red part and use nano to add it in the server <code>~/.ssh/authorized_keys</code></li> <li>Make sure permissions are correct <pre><code>mkdir -p ~/.ssh\nchmod 700 ~/.ssh\nchmod 600 ~/.ssh/authorized_keys\nnano ~/.ssh/authorized_keys\n</code></pre></li> <li>Save private key as ppk file on the root ssh folder.</li> <li> <p>If the client with private key is Linux machine, need to change the permission of the private key.</p> <pre><code>chmod 600 private.key\n</code></pre> </li> <li> <p>Convert the private key Conversion &gt; Export OpenSSH Keys and save the file to a folder OpenSSH Keys</p> </li> </ol>"},{"location":"Linux%20Server/debian-based-server-setup/#ssh-config","title":"SSH Config","text":"<p>Configuration file for easy SSH access. The permission for that file is 644. <pre><code>Host server\n  HostName 10.10.120.1\n  User ubuntu\n  IdentityFile ~/keys/server.key\n</code></pre></p> <p>Use with OliveTin</p> <p>To have seamless ssh experience with OliveTin, make sure to copy the <code>ssh config</code> file and all the keys to <code>/root</code>, since in OliveTin <code>~</code> means <code>/root</code> not your user home directory.</p>"},{"location":"Linux%20Server/debian-based-server-setup/#setting-up-smb","title":"Setting Up SMB","text":"<p>Refer to Samba(SMB) Setup to setup SMB server.</p>"},{"location":"Linux%20Server/debian-based-server-setup/#desktop-environment-setup","title":"Desktop Environment Setup","text":""},{"location":"Linux%20Server/debian-based-server-setup/#firefox","title":"Firefox","text":"<p>The location of firefox profile is at /home/$USER/.mozilla/firefox/xxxxx.default</p> <p>Make a tarball and copy it and extract it in destination.</p> <p>In the profile folder, look for compatibility.ini, go to a random profile in the dest machine and copy the compatibility.ini settings to the one that is copied over. This ensure compatibility so that the new profile works without warning.</p> <p>Check the profile.ini with the name and the location of the new profile folder, firefox should be the same as before.</p> <pre><code>[Profile0]\nName=karis\nIsRelative=1\nPath=ims58kbd.default-esr-1\n</code></pre> <p>Themes</p> <p>To backup/restore settings of cinnamon</p> <p>Icons</p> <p>The icons are located at these locations.</p> <pre><code>/usr/share/icons\n~/.icons\n</code></pre> <p>Scripts</p> <p>Copy the scripts and put it into ~/script for organization and copy the old crontab for executing these scripts.</p>"},{"location":"Linux%20Server/olivetin/","title":"OliveTin","text":"<p>OliveTin exposes a webpage with buttons that execute shell command (eg. docker, scripts) on the server and allow others for easy access. It should be used internally only.</p> <p>Main Interface  Log Interface </p>"},{"location":"Linux%20Server/olivetin/#installation","title":"Installation","text":"<p>Download the correct file from this site. https://github.com/OliveTin/OliveTin/releases OliveTin_linux_amd64.deb</p> <p>Go to the directory and install the package.</p> <ul> <li>if a previous <code>config.yaml</code> is already present, installer will ask what to do, the default is to keep the previous config <pre><code>sudo dpkg -i OliveTin\u2026\u200bdeb\nsudo systemctl enable --now OliveTin\n</code></pre></li> </ul> <p>Uninstall <pre><code>sudo dpkg -r OliveTin # the installed app name, not the deb file\n</code></pre></p>"},{"location":"Linux%20Server/olivetin/#configuration","title":"Configuration","text":"<p>The configuration file is located at <code>/etc/OliveTin/config.yaml</code></p> Script Execution User <p>By default, OliveTin always execute script as root!! This have complications. With an example script that echo some location,  create a file in<code>/opt</code> dir owned by user 1000 and cd into <code>~/Downloads</code> user 1000\u2019s download dir.</p> default <p><code>/root/Downloads/</code> <code>line 7: cd: /root/Downloads: No such file or directory</code> The file created by the script is owned by root and not editable in VSCode or other editor unless using <code>sudo</code></p> as user 1000 <p><code>/home/test/Downloads/</code> The file created by the script is owned by user and can be freely edited.</p> <p>Run command as user user <code>sudo -u user /path/to/script</code>. </p> <ul> <li><code>~</code> path works as intended</li> <li>all files created and modified will be owned by user not root</li> <li><code>bashrc</code> variables do not work, to use environment variables, it must be sourced elsewhere</li> <li>by default, the script has a <code>$PWD</code> at <code>/root</code>, so relative path do not work regarding files</li> </ul> <p>Example Configuration <pre><code>listenAddressSingleHTTPFrontend: 0.0.0.0:1378 # set the port to 1378\n\n# Choose from INFO (default), WARN and DEBUG\nlogLevel: \"INFO\"\n\nactions:\n\n- title: Update Music\n  shell: /home/karis/scripts/script\n  icon: '&amp;#127925'\n  timeout: 2\n  hidden: true\n</code></pre> Configuration consists of list of actions, each action consist of <code>title</code>, <code>shell</code>, icon</p> <ul> <li><code>timeout</code> is also optional, the task will be killed if it takes longer (in seconds) to complete</li> <li><code>hidden</code> will hide it from dashboard<ul> <li>to unhide, a service restart is needed</li> </ul> </li> <li><code>maxConcurrent</code> optional, only allow x runs for the duration of the execution, any more will be blocked </li> <li>rateLimit more advance limiting<ul> <li>to clear a rate limit, OliveTin has to be restarted <pre><code>    maxRate:\n      - limit: 3\n        duration: 5m\n</code></pre></li> </ul> </li> </ul>"},{"location":"Linux%20Server/olivetin/#arguments","title":"Arguments","text":""},{"location":"Linux%20Server/olivetin/#textbox-input","title":"Textbox Input","text":"<pre><code>- title: Restart a Docker CT\n  icon: '&lt;img src = \"icons/restart.png\" width=\"48px\" /&gt;'\n  shell: docker restart {{ container }}\n  arguments:\n    - name: container\n      type: ascii\n</code></pre> <ul> <li>use <code>{{ }}</code> and give a variable</li> <li>under arguments type, assign a type for it, <code>ascii</code> only allows letters and numbers</li> </ul>"},{"location":"Linux%20Server/olivetin/#dropdown-choices","title":"Dropdown Choices","text":"<p><pre><code>- title: Manage Docker Stack Services\n  icon: \"&amp;#128736;\"\n  shell: docker-compose -f /home/karis/docker/bookstack/docker-compose.yml {{ action }}\n  arguments:\n    - name: action\n      choices:\n        - title: Start Stack\n          value: up -d\n        - title: Stop Stack\n          value: down\n</code></pre> This example give choices to start or stop a docker stack of a docker-compose file. If a argument is given the parameter choices, it will be in dropdown mode.</p>"},{"location":"Linux%20Server/olivetin/#suggestion","title":"Suggestion","text":"<p>Suggestion is a hybrid between dropdown and textbox. It will suggest the list of possible items in browser but do not restrict choices. <pre><code>  arguments:\n    - name: action\n      title: Action Name\n      suggestions:\n        - value: Information\n</code></pre></p> <ul> <li><code>value</code> is what is passed onto the shell and <code>Information</code> is a text display for clarification  After modifying configuration, it require a restart to clear out previous suggestions for browsers.</li> </ul>"},{"location":"Linux%20Server/olivetin/#execute-on-files-created-in-a-directory","title":"Execute on files created in a directory","text":"<p><pre><code>- title: Update Songs\n  icon: &lt;iconify-icon icon=\"mdi:music\"&gt;&lt;/iconify-icon&gt;\n  shell: /home/test/scripts/file.sh {{ filepath }}\n  arguments:\n    - name: filepath\n      type: unicode_identifier\n  execOnFileCreatedInDir: \n    - /home/test/Downloads/\n    - /another/folder\n</code></pre> Whenever a new file is created the action will execute.</p> <ul> <li><code>execOnFileCreatedInDir</code><ul> <li>it is possible to add multiple path to monitor; however, adding a path require a restart of OliveTin service</li> </ul> </li> <li>same principle as <code>Arguments</code>, whereas OliveTin provides predefined arguments for files. <code>filepath</code> is the full absolute path of the file that is created</li> </ul>"},{"location":"Linux%20Server/olivetin/#execution-feedback","title":"Execution Feedback","text":"<pre><code>- title: some action\n  popupOnstart: default, execution-dialog-stdout-only, execution-dialog, execution-button\n</code></pre> default stdout-only dialog button <ul> <li>popup dialog have an option to only show <code>stdout</code> or show full log output with exit code</li> <li>button will show how long the process take</li> <li>the design of popup box may not be easy to close, use the keyboard ++Esc++ key to close</li> </ul>"},{"location":"Linux%20Server/olivetin/#confirmation","title":"Confirmation","text":"<p>It is possible to have a confirmation before completing action. <pre><code>  arguments:\n\n    - type: confirmation\n      title: Click start to begin.\n</code></pre></p> <ul> <li>user must click a checkbox and then start before the action will execute</li> <li>API do not have such restrictions</li> </ul>"},{"location":"Linux%20Server/olivetin/#ssh-to-another-server","title":"SSH to Another Server","text":"<p>Since OliveTin by default runs command as root, it is necessary to copy the SSH <code>config</code> file and all the keys from a user\u2019s folder into <code>/root/.ssh</code></p> <ul> <li>if the permission is setup correctly for a user, the permissions will copy over</li> </ul> <p>On the first try, need to have this option when using SSH command <code>-o StrictHostChecking=no</code> and on the subsequent logins, ssh via ssh configs will work as normal.</p>"},{"location":"Linux%20Server/olivetin/#icons","title":"Icons","text":"<p>The icons need to be placed in a folder in /var/www/[icon-folder]/icon.png. To use the icons, offline image or web address, it should be in HTML format. The size of 48px is the default size of OliveTin icons. Other CSS options such as <code>style=\"background-color: white;\"</code> also works. <pre><code>icon: '&lt;img src = \"icons/minecraft.png\" size=\"48px\" /&gt;'\n</code></pre> Icon with emoji, to use emoji, need to use the html code. https://symbl.cc/en/emoji/ For example, <code>&amp;#9786;</code> \ud83d\ude0a. <pre><code>icon: \"&amp;#9786;\"\n</code></pre></p>"},{"location":"Linux%20Server/olivetin/#third-party","title":"Third-Party","text":"<p>Olivetin only support iconify icons. To use it, search for an icon, under <code>components</code> select <code>Iconify Icon</code>  Add the pasted line into the configuration. <pre><code>  - title: Title\n    icon: &lt;iconify-icon icon=\"openmoji:jellyfin\"&gt;&lt;/iconify-icon&gt;\n</code></pre></p>"},{"location":"Linux%20Server/olivetin/#icon-management","title":"Icon Management","text":"<p>The default icon folder is <code>/var/www/olivetin/icons</code> The icon folder of all homelab icons is in <code>~/icons/homelab</code></p>"},{"location":"Linux%20Server/olivetin/#api","title":"API","text":"<p>Simple action button. <pre><code>curl -X POST \"http://mediaserver:1378/api/StartAction\" -d '{\"actionId\": \"Update Music\"}'\n</code></pre> Action with Arguments. <pre><code>curl -X POST 'http://mediaserver:1378/api/StartAction' -d '{\"actionId\": \"Rename Movies\", \"arguments\": [{\"name\": \"location\", \"value\": \"value\"}]}'\n</code></pre></p> Arguments variable cannot be \u201cpath\u201d <p>If <code>path</code> is used as argument, when executing commands with arguments, it will replace the system <code>$PATH</code> variable, this will render most commands useless even basic ones like <code>sleep</code>, <code>date</code> etc. Use another variable such as <code>directory</code> or <code>location</code></p> Newest Olivetin Version Break Old API Method <p>The <code>actionName</code> key is deprecated and no longer works, newest Olivetin API only allow <code>actionId</code> for <code>StartAction</code> API endpoint. The scripts above are adjusted accordingly. To migrate, the easiest way it to create a ID in configuration that has the same value as action name. <pre><code>- title: action name\n- id: action name\n</code></pre></p>"},{"location":"Linux%20Server/olivetin/#dashboard","title":"Dashboard","text":"<p>Dashboard are a separate page from the default OliveTin page, Fieldsets and Folders are allowed to group actions only in dashboard.</p> <ul> <li>when an action is in dashboards, it does not appear in main view.</li> <li>when refreshing the page, it will always go back to main view even if the page is currently at a dashboard <pre><code>dashboards:\n  - title: My Dashboard\n    contents:\n      - title: Title Desc\n        type: fieldset\n        contents:\n          - title: Fix Epic Games\n          - title: Restart Minecraft\n      - title: Update Metadata\n        type: fieldset\n        contents:\n          - title: Stuff\n            icon: '&lt;img src = \"icons/mcrestart.png\" width=\"64px\" /&gt;'\n            contents:\n               - title: Update Songs\n</code></pre></li> </ul> Preview <p></p>"},{"location":"Linux%20Server/olivetin/#fieldsets","title":"Fieldsets","text":"<p>Fieldsets are group of actions under a title. Any <code>title</code> that has <code>type: fieldset</code> defined is a fieldset, any actions are grouped under <code>contents</code> key and need to have matching title.</p>"},{"location":"Linux%20Server/olivetin/#folders","title":"Folders","text":"<p>Folders also group actions together in a dashboard and user need to click into the folder to see the actions.</p> <ul> <li>it is possible to use custom icons or title for folders as long as <code>type:</code> is not set and it has <code>contents:</code></li> </ul>"},{"location":"Linux%20Server/olivetin/#entities","title":"Entities","text":"<p>To use entities, an action, a dashboard entry, entities json/yaml file and entity update method is needed (when the action interact with the entity).</p> Preview of Entities Flowchart <p></p>"},{"location":"Linux%20Server/olivetin/#entities-file","title":"entities-file","text":"<p>It\u2019s  possible to use json or  YAML <pre><code>entities:\n  - file: /etc/OliveTin/entities/containers.json\n    name: container\n</code></pre></p> <ul> <li>entities file are stored in <code>/etc/OliveTin/entities</code></li> <li>the name of the entity will be reference as <code>container.attributes</code> in configuration</li> </ul>"},{"location":"Linux%20Server/olivetin/#entity-update","title":"entity update","text":"<pre><code>- title: Update container entity file\n  shell: 'docker ps -a --format \"{{ json . }}\" &gt; /etc/OliveTin/entities/entity.json\n  hidden: true\n  execOnStartup: true\n  execOnCron: '*/5 * * * *'\n</code></pre> <ul> <li>this is an action that is trigger by other actions that need to modify the entity, the purpose is to update the entity file</li> </ul>"},{"location":"Linux%20Server/olivetin/#entity-actions","title":"entity-actions","text":"<pre><code>- title: Check {{ container.Names }} Status\n  shell: echo {{ container.Status }}\n  entity: container\n  trigger: Update container entity file\n</code></pre> <p>The entity action is defined the same way as other actions.</p> <ul> <li><code>entity</code> need to be defined</li> <li><code>trigger</code> automatically update entity attributes (since executing this actions could change some attribute of an entity like starting a container)</li> <li>both title and shell can use <code>entity.attributes</code></li> </ul>"},{"location":"Linux%20Server/olivetin/#dashboard-entry","title":"dashboard-entry","text":"<pre><code> - title: CPanel\n    contents:\n      - title: 'Container {{ container.Names }} ({{ container.Image }})'\n        entity: container\n        type: fieldset\n        contents:\n          - type: display\n            title: |\n              {{ container.Status }} &lt;br /&gt;&lt;br /&gt;&lt;strong&gt;{{ container.State }}&lt;&gt;\n          - title: 'Check {{ container.Names }} Status'\n</code></pre> Preview <ul> <li>dashboard is the same configuration as in previous but now is able to utilize entities. </li> </ul>"},{"location":"Linux%20Server/sambasmb-setup/","title":"Samba(SMB) Setup","text":""},{"location":"Linux%20Server/sambasmb-setup/#setting-up-smb-server-on-linux","title":"Setting up SMB Server on Linux","text":"<p>Install the samba tool on Linux.</p> <pre><code>sudo apt update\nsudo apt install samba -y\n</code></pre> <p>Edit the <code>/etc/samba/smb.conf</code></p> <pre><code>[nvme_share]\n   comment = NVMe Share\n   path = /mnt/nvme/share\n   browseable = yes\n   read only = no\n</code></pre> <p><code>nvme_share</code> is the name of the Samba path which will appear in SMB clients and its path is accessed by <code>\\\\192.168.0.1\\nvme_share</code></p> <p></p> <p><code>path</code> is the location where the files are stored</p> <p><code>browseable</code> and <code>read only</code> are flags that are needed to make sure read/write access on the SMB share</p> <p>Lastly, add the user and password for the SMB share</p> <pre><code>sudo smbpasswd -a $USER # enter the password twice\n</code></pre> <p>In the case when Windows fail to write files in the samba share for odd reason. Go to <code>Manage Credentials</code> -&gt; <code>Windows Credentials</code> -&gt; <code>Add a Windows Credential</code> and fill the necessary address, username and password.</p>"},{"location":"Website/ghost-cms/","title":"Ghost CMS","text":""}]}