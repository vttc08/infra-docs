{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#recent-updates","title":"Recent Updates","text":"<ul> <li>Debian-Based Server Setup</li> <li>OliveTin</li> <li>jlesage VNC Apps</li> <li>Webtop (openbox-ubuntu)</li> <li>Mkdocs</li> <li>01 Docker Infrastructure</li> <li>JDownloader</li> <li>Samba(SMB) Setup</li> <li>Dynamic DNS Updater Docker</li> <li>Filebrowser</li> </ul>"},{"location":"mkdocs/","title":"Mkdocs","text":""},{"location":"mkdocs/#mkdocs-gotchas","title":"Mkdocs Gotchas","text":"<ul> <li><code>yaml</code> highlighting is broken with <code>mdx-breakless-lists</code></li> <li>when using heading <code>#</code>, if there are no line breaks between headings, any lists that is after content of the second heading will not be rendered properly, even with <code>mdx-breakless-lists</code></li> <li>furthermore, if using lists right after a <code>yaml</code> code block, the list will also not be rendered correctly</li> <li></li> <li>when referencing a subheading in another file, mkdocs uses <code>[](file.md#heading-with-space)</code> while obsidian uses <code>[](file.md#heading%20with%20space)</code></li> <li>Before switching from lists to normal content, a line break is needed, otherwise the text below will be rendered with a indent</li> <li>mkdocs subheadings <code>[](#subheadings)</code> must be in lower case</li> </ul>"},{"location":"mkdocs/#admonitioncallouts","title":"Admonition/Callouts","text":"Mkdocs native callout <p>callout content mkdocs</p> <p>Nested</p> <p>Nesting</p> <ul> <li><code>???</code> is also valid syntax for mkdocs</li> <li><code>???+</code> makes the callout collapsible and opens by default, while <code>???-</code> makes it closed by default <pre><code>!!! notes \"Title\"\n    content\n</code></pre> Obsidian callouts requires the plugin <code>mkdocs-callouts</code></li> </ul> Obsidian Native Callout <p>Callout content mkdocs</p> <p>Nested callout</p> <p>callout</p> <pre><code>&gt; [!notes]+/- Callout title\n&gt; Callout content\n</code></pre> <ul> <li>obsidian callout syntax also follows the same <code>+</code>,<code>-</code> for collapsing, it is to be inserted after the brackets</li> </ul> <p>Available callouts include <code>notes</code>, <code>info</code>, <code>warning</code>, <code>danger</code>, <code>success</code>, <code>failure</code>, <code>example</code>, <code>abstract</code>, <code>tip</code>, <code>question</code>, <code>bug</code>.  </p>"},{"location":"mkdocs/#keys-caret-mark-tilde","title":"Keys, Caret, Mark, Tilde","text":"<p>Keys <code>++ctrl+alt+plus++</code> Ctrl+Alt++ mark highlighting tilde strikethrough</p>"},{"location":"mkdocs/#tabbed-content","title":"Tabbed Content","text":"Tab 1Tab 2 <p>Tab 1 content mkdocs Second line here.</p> <p>Tab 2 content</p> <p><pre><code>=== \"Tab Name\"\n    Tab content\n</code></pre> </p> <ul> <li>not supported in obsidian</li> </ul>"},{"location":"mkdocs/#attr_list","title":"attr_list","text":"<p>Fancy Buttons mkdocs <code>[button text](link.md){ .md-button }</code> Tooltip I\u2019m a tooltip that you can hover or click. <code>[tooltip](https://link \"hover text\")</code> Annotation I\u2019m an annotation, but you need to click the plus icon (1) to show. (2) </p> <ol> <li>annotation 1</li> <li>annotation 2 <pre><code>Annotation location 1 (1), location (2)\n{ .annotate }\n1. annotation text to be shown\n</code></pre> </li> </ol> <p>Footnote Insert footnote like <code>[^1]</code> <sup>1</sup></p> <ul> <li>for inserting footnote <code>[^1]</code></li> <li><code>[^1]:</code> at the end to explain the footnote; not supported in obsidian</li> </ul>"},{"location":"mkdocs/#code-highlighting","title":"Code Highlighting","text":"<pre><code>from python import python\npython.run(arg1=123, arg2=\"mystr\")[2]\n</code></pre> <pre><code>#!/bin/bash\nvar=\"myvar\"\necho $var+3\n</code></pre> <pre><code># yaml highlighting has to be `yaml` not `yml` and it's broken\n---\nversion: \"2.1\"\nservices:\n  clarkson:\n    image: lscr.io/linuxserver/clarkson\n    container_name: clarkson\n    environment:\n\n      - PUID=1000\n      - PGID=1000\n    ports:\n      - 3000:3000\n    restart: unless-stopped\n</code></pre> <ol> <li> <p>explaining the footnote.\u00a0\u21a9</p> </li> </ol>"},{"location":"Cloud%20VPS/basic-server-setup-caddy-docker-jdownloader/","title":"Basic Server Setup, Caddy, Docker, JDownloader","text":"<p>Creating the VM in oracle cloud. </p> <ol> <li>Go to instances, new instance.</li> <li>Select the Always Free image, ARM or x86. 1 core only, recommended 4GB RAM, should be exceed 6 GB.</li> <li>Choose Ubuntu image.</li> <li>Download the SSH key and name it accordingly.</li> </ol> <p>Key Pair</p> <p>Using PuttyGen.</p> <ul> <li>Place the key in <code>./ssh/openssh_keys</code></li> <li>Open PuttyGen, conversion -&gt; import keys</li> <li>Save the key files as ppk file in root folder of <code>./ssh</code></li> </ul> <p>Putty</p> <ul> <li>Grab the IP address in the cloud console</li> <li>Give a name in saved sessions</li> <li>Go to behavior, choose these options</li> <li>Under Data, make sure Terminal-type string is xterm-256color</li> <li>Under Terminal -&gt; Features, check \u201cdisable application keypad mode\u201d to fix issues with nano</li> <li>The private key needs to be load in Connection -&gt; SSH -&gt; Auth -&gt; Credentials</li> </ul> <p></p> <p></p> <p>To get the IP address of the VPS at any time</p> <pre><code>curl ifconfig.me\n</code></pre> <p>Basic Setup + Docker</p> <ol> <li>Installing Caddy web server (simple to use reverse proxy), lightweight, easy and no need for docker. (Nginx is also a good candidate for reverse proxy as the command is easy to memorize and does not require consulting documentation sites. However, the syntax for nginx is extremely complex compared to caddy and might not be easily memorized.</li> </ol> <p>https://caddyserver.com/docs/install#debian-ubuntu-raspbian</p> <pre><code>sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy net-tools\n# net-tools is good utility, optionally can install firewall-cmd or nginx\n# sudo apt install firewalld nginx\n</code></pre> <p>2. Install Docker</p> <p>https://docs.docker.com/engine/install/ubuntu/</p> <pre><code>sudo apt-get update\nsudo apt-get install \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n\nsudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin docker-compose\n# code modified to install docker-compose, each space in paragraph indicates a separate step in their official blog\n</code></pre> <pre><code>sudo groupadd docker \\\nsudo usermod -aG docker ubuntu\nnewgrp docker # activate docker group immediately\n</code></pre> <p>The machine needs to be rebooted from Oracle Cloud console to finish installation.</p> <p>JDownloader</p> <p>https://hub.docker.com/r/jlesage/jdownloader-2</p> <pre><code>docker run -d \\\n    --name=jdownloader-2 \\\n    -p 5800:5800 \\\n    -v $HOME/appdata/jdownloader-2:/config:rw \\\n    -v $HOME/Downloads:/output:rw \\\n    --restart unless-stopped \\\n    jlesage/jdownloader-2\n</code></pre> <p>If port forwarding configured properly, entering ipaddress:5800 should work. If not open ports manually.</p> <pre><code>sudo iptables -I INPUT 6 -m state --state NEW -p tcp --dport 5800 -j ACCEPT\nsudo netfilter-persistent save\n</code></pre> <p>Other Useful Ports</p> <pre><code>sudo iptables -I INPUT 6 -m state --state NEW -p tcp --dport 443 -j ACCEPT\nsudo iptables -I INPUT 6 -m state --state NEW -p tcp --dport 80 -j ACCEPT\nsudo iptables -I INPUT 6 -m state --state NEW -p tcp --dport 25565 -j ACCEPT\nsudo iptables -I INPUT 6 -m state --state NEW -p tcp --dport 19132 -j ACCEPT\nsudo iptables -I INPUT 6 -m state --state NEW -p udp --dport 25565 -j ACCEPT\nsudo iptables -I INPUT 6 -m state --state NEW -p udp --dport 19132 -j ACCEPT\nsudo iptables -I INPUT 6 -m state --state NEW -p udp --dport 51820 -j ACCEPT\nsudo netfilter-persistent save\n</code></pre> <p>Alternative (firewall-cmd)</p> <pre><code>sudo apt install firewalld\n</code></pre> <p>Firewalld is a CentOS package, it may be unstable and crash, but command easy to memorize.</p> <pre><code>sudo firewall-cmd --zone=public --add-port 19132/tcp --permanent\nsudo firewall-cmd --zone=public --add-port 19132/udp --permanent\nsudo firewall-cmd --zone=public --add-port 25565/tcp --permanent\nsudo firewall-cmd --zone=public --add-port 25565/udp --permanent\nsudo firewall-cmd --zone=public --add-port 80/tcp --permanent\nsudo firewall-cmd --zone=public --add-port 443/tcp --permanent\nsudo firewall-cmd --zone=public --add-port 5800/tcp --permanent\nsudo firewall-cmd --reload\n</code></pre> <p>Troubleshooting network</p> <p>For firewall-cmd, use this command to check all open ports.</p> <pre><code>sudo firewall-cmd --list-all\n</code></pre> <p>Using netstat, or pipe it to grep</p> <pre><code>netstat -tln\n# | grep 8080 etc...\n</code></pre> <p>Configuring JDownloader</p> <ul> <li>Go to the JDownloader WebUI</li> <li>Go to Settings</li> <li>Under general, change the max number of downloads (2) and DL per hoster (1) to minimize issues</li> </ul> <p></p> <ul> <li>Go to MyJDownloader and configure MyJDownloader account</li> </ul> <p></p> <ul> <li>Go to extension modules, install and enable \u201cfolderwatch\u201d</li> </ul> <p></p> <p>The configuration for JDownloader is complete and should appear and be functional in WebUI. Advanced JDownloader documentation will be covered in detailed in another section. It is recommended to close port 5800 after configuring to prevent others accessing.</p> <p>Basic Caddy Syntax (if applicable)</p> <p>If the server that is being setup or restored needs functional service like bookstack or uptime-kuma, reverse proxy is needed.</p> <pre><code>sudo nano /etc/caddy/Caddyfile\n</code></pre> <pre><code>{\n    email weebly2x10@gmail.com\n}\n\nyour-uptime-kuma.yoursubdomain.duckdns.org {\n        reverse_proxy http://127.0.0.1:3001\n}\n\nwiki.yoursubdomain.duckdns.org {\n        reverse_proxy http://127.0.0.1:6975\n}\n</code></pre> <p>Advanced</p> <p>Tunneling Jellyfin and other web services with tailscale and caddy</p> <p>Minecraft Server tunneling via Nginx (tcp only)</p> <p>Minecraft Tunneling</p>"},{"location":"Cloud%20VPS/jdownloader/","title":"JDownloader","text":"<p>After setting up JDownloader and it appears well in WebUI.</p> <p>The section is useless now as UHDMV has shutdown and it\u2019s pointless to setup multiple automated JDownloader server on VPS.</p>"},{"location":"Cloud%20VPS/jdownloader/#settings-for-jdownloader","title":"Settings for JDownloader","text":"<p>Debloat settings  https://rentry.org/jdownloader2 Advanced Settings <code>GraphicalUserInterfaceSettings: Banner</code> -&gt; disable <code>GraphicalUserlnterfaceSettings: Premium Alert Task Column</code> - &gt; disable <code>GraphicalUserInterfaceSeftings: Premium Alert Speed Column</code> -&gt; disable <code>GraphicalUserInterfaceSettings: Premium Alert ETA Column</code> -&gt; disable <code>GraphicalUsserInterfaceSeftings: Special Deal Oboom Dialog Visible On Startup</code> -&gt; disable <code>GraphicalUsserInterfaceSeftings: Special Deals</code>\u00a0-&gt; disable <code>GraphicalUsserInterfaceSeftings: Donate Button State</code>\u00a0-&gt; <code>Hidden (automode)</code></p>"},{"location":"Cloud%20VPS/jdownloader/#theming","title":"Theming","text":"<p><code>GraphicalUserInterfaceSettings: Look And Feel Theme</code> - &gt; <code>BLACK_EYE</code> For Colors <code>LAFSettings: Color For</code></p> <ul> <li>Panel background and header background and alternate row background- <code>#ff222222</code></li> <li>Selected Rows Background - <code>#ff666666</code></li> <li>Package Row Background - <code>#ff333333</code></li> <li>Mouse Over Row Background - <code>#ff666666</code></li> <li>Panel Header Foreground, Tooltip Foreground, Selected Rows Foreground, Package Row Foreground, Mouse Over Row Foreground, Alternate Row Foreground,  Account Temp Error Row Foreground, Account Error Row Foreground- <code>#ffffffff</code><ul> <li>basically, change all the black values to white when searching for <code>color fore</code>, change everything except blue colors and error color</li> </ul> </li> <li>Enabled Text Color, Speed Meter Text, Speed Meter Average Text, Config Panel Description Text, Config Header Text Color - <code>#ffffffff</code></li> <li>Disabled Text Color - <code>#ff666666</code><ul> <li>basically, when searching for <code>color text</code>, change all to white except for disabled text</li> </ul> </li> </ul>"},{"location":"Cloud%20VPS/tunneling-basic-services-jellyfin-web-with-caddy-and-tailscale/","title":"Tunneling Basic Services (Jellyfin, Web) with Caddy and Tailscale","text":"<p>This procedure is not reproducible yet. Rigorous testing is still required before being documented. Here are the known procedures.</p> <p>The purpose is to tunnel normal web or network intensive traffic such as Jellyfin when faced with CG-NAT or similar situations (in this case locked down dorm internet), also configure hardware transcoding (in this case NVENC, but Intel QSV for future) to mitigate limitations with Canadian ISP(s).</p> <p>Jellyfin Install</p> <p>https://jellyfin.org/downloads/server</p> <p>Download and run the server installer.</p> <p>Jellyfin Server Configuration</p> <p>Tailscale (Windows Client)</p> <p>https://tailscale.com/download/windows</p> <p>Download, install and login.</p> <p>Tailscale (Linux Server)</p> <pre><code>curl -fsSL https://tailscale.com/install.sh | sh\n</code></pre> <pre><code>sudo tailscale up\n</code></pre> <p>All the tailscale management is done in the WebUI.</p> <p></p> <p>The Windows client is given a tailscale network IP address in 100 range. Check if Windows client is pingable on server.</p> <pre><code>ping 100.x.y.z\n</code></pre> <p>Check if Jellyfin is running and tunneled properly on Oracle cloud. It should get a webpage html rather than unable to resolve host etc.</p> <pre><code>curl http://100.x.y.z:8096\n</code></pre> <p>Reverse Proxy basic-server-setup-caddy-docker-jdownloader</p> <p>Caddy installation and syntax is can be found on this page. Replace 127.0.0.1 with the tailscale IP address.</p> <pre><code>{\n    email weebly2x10@gmail.com\n}\n\nmovies.yoursubdomain.duckdns.org {\n        reverse_proxy http://100.x.y.z\n}\n</code></pre> <p>It is possible to set use the root domain (yoursub.duckdns.org) or a subfolder domain (movies.yousub.duckdns.org) for Jellyfin. After configuring the Caddyfile.</p> <pre><code>sudo systemctl reload caddy\n</code></pre> <p>Use netstat to check port 80, 443 is being listened. Make sure to port forward Oracle VPS.</p> <p>Other Services</p> <p>Follow the same syntax as the caddy file provided, if the root domain is used, then a subdomain must be used for other services.</p> <p>Results</p> <p>Inconclusive yet, more testing required.</p>"},{"location":"Cloud%20VPS/tunneling-minecraft-server-tcp-only-with-nginx/","title":"Tunneling Minecraft Server (tcp only) with Nginx","text":"<p>Procedure not reproducible yet, will be documented later.</p>"},{"location":"Computer%20Stuff/demucs-nvidia/","title":"Demucs Nvidia","text":"<p>Demucs is an music separation tool that has potential for a karaoke setup.</p> <p>https://github.com/facebookresearch/demucs</p> <p>https://www.youtube.com/watch?v=9QnFMKWEFcI&amp;t=585s</p> <p>https://docs.google.com/document/d/1XMmLrz-Tct1Hdb_PatcwEeBrV9Wrt15wHB1xhkB2oiY/edit</p> <p>Installation on PC with Nvidia</p> <ol> <li>Firstly install Anaconda. Download Anaconda for Windows https://www.anaconda.com/products/distribution</li> <li>Install PyTorch. https://pytorch.org/get-started/locally/. Select the correct version of pytorch.</li> <li>Install ffmpeg. [https://www.gyan.dev/ffmpeg/builds/]](assets/gallery/2022-12/TwJimage.png)</li> </ol> <p>Demucs</p> <p>After installing the prerequesties.</p> <p>Open \u201cAnaconda terminal\u201d and type</p> <pre><code>python.exe -m pip install -U demucs\n</code></pre> <pre><code>pip install PySoundFile \n</code></pre> <p>Running Demucs</p> <pre><code>demucs \"C:\\path\\to\\music\\file.mp3\"\n</code></pre> <p>This will run demucs with CUDA GPU acceleration, make sure to put the path in double quote. The extracted file will be found in the directory where you run the command eg. the default Anaconda prompt starts in ~/separated</p>"},{"location":"Docker%20Apps/01%20docker-infra/","title":"01 Docker Infrastructure","text":""},{"location":"Docker%20Apps/01%20docker-infra/#filesystem","title":"Filesystem","text":""},{"location":"Docker%20Apps/01%20docker-infra/#compose","title":"Compose","text":"<p>All <code>docker-compose.yml</code> files are stored in <code>~/docker</code> folder, which then by default is under the network <code>docker_default</code>.</p> <ul> <li>by default for newly created apps, a new folder is created and <code>docker-compose.yml</code> is created for that app for testing<ul> <li>once app testing is complete, the compose file can be moved docker root folder if appropriate or remain</li> </ul> </li> <li>some apps can be grouped together and these compose files are in the root docker folder such as <code>media.yml</code>, <code>network.yml</code>, the grouping allows multiple services to be managed by a single compose. For grouping, some of the property can include<ul> <li>the apps share common properties such as <code>arrs</code> apps</li> <li>it is preferable for apps to live in same network, eg. <code>teslamate</code></li> <li>a large app requiring multiple containers eg. <code>frontend</code>, <code>mysql</code> etc..</li> <li>apps share similar/same category, such as <code>qBittorrent</code> and <code>nzbget</code> can be put together in <code>downloader.yml</code> even though they do not have common properties or require same networking</li> </ul> </li> </ul>"},{"location":"Docker%20Apps/01%20docker-infra/#storage","title":"Storage","text":"<p>The storage used for all containers are bind mount.</p> <ul> <li>application configs are stored in <code>~/docker/[app]</code><ul> <li>if an app has multiple components needing persistence (eg. app with database, helpers), a folder will be created as such <code>~/docker/[app]/postgres</code> etc.</li> </ul> </li> <li>apps that also store non-config data (such as music, documents etc.) and not using a lot of space can bind mount <code>/mnt/nvme/share</code> (a directory on local or another SSD) for fast data access and without spinning up HDD</li> <li>exceptions are home assistant or its related home automation containers and these are stored at <code>/srv/homeassistant</code></li> </ul>"},{"location":"Docker%20Apps/01%20docker-infra/#backup","title":"Backup","text":"<p>The entire docker root folder is copied to a NFS share on another computer. With exception of minecraft and home assistant which a specialized method is used.</p>"},{"location":"Docker%20Apps/01%20docker-infra/#network","title":"Network","text":"<p>With <code>docker-compose</code>, a new network is created with the name of folder the compose is located, while it\u2019s possible to change network, it is not straightforward, therefore, there is no points in manually defining networks unless required.</p> <p>Public <code>172.80.0.0/16</code> - bridge network for public facing applications with reverse proxy, this way when configuring Nginx Proxy Manager, all it need is to enter <code>container_name:80</code> rather than IP address.</p> <ul> <li>Nginx Proxy Manager - <code>172.80.44.3</code></li> <li>Other containers will use docker DHCP to get address</li> <li>Containers that need to public facing can attach to this network Media <code>172.96.0.0/16</code> - bridge network for arrs, downloader and management applications for easy interconnection when configuring Minecraft <code>172.255.255.0/24</code> - bridge network for Minecraft related networks</li> <li>Minecraft server (mcserver) - <code>172.255.255.65</code></li> </ul>"},{"location":"Docker%20Apps/01%20docker-infra/#categories","title":"Categories","text":"<p>Media Apps - apps related to media acquisition, curation and other functions services for Jellyfin Networking - reverse proxy, DNS, VPN and related services Home Automation - home assistant and its associated functions VNC - containers based on jlesage-vnc-apps or Linuxserver Kasm images, usually desktop apps run in a browser via noVNC Management - tools for managing docker containers or entire server Games - game servers and associated tools Filesharing - apps that share files to other clients Documentation - notes and operation procedures for server infrastructure Authentication - services that handle single sign-on (SSO) with users</p>"},{"location":"Docker%20Apps/bookstack/","title":"Bookstack","text":""},{"location":"Docker%20Apps/bookstack/#installation","title":"Installation","text":"<p>Change port to 6975</p> <p>Add in docker-compose: restart: unless-stopped</p> <p>$docker directory = /home/docker .... etc</p> <p>Docker-Compose file reference</p> <p>https://github.com/solidnerd/docker-bookstack/blob/master/docker-compose.yml</p> <pre><code>version: '2'\nservices:\n  mysql:\n    image: mysql:8.0\n    environment:\n\n    - MYSQL_ROOT_PASSWORD=secret\n    - MYSQL_DATABASE=bookstack\n    - MYSQL_USER=bookstack\n    - MYSQL_PASSWORD=secret\n    volumes:\n    - mysql-data:/var/lib/mysql\n    restart: unless-stopped\n\n  bookstack:\n    image: solidnerd/bookstack:22.10.2\n    depends_on:\n\n    - mysql\n    environment:\n    - DB_HOST=mysql:3306\n    - DB_DATABASE=bookstack\n    - DB_USERNAME=bookstack\n    - DB_PASSWORD=secret\n    #set the APP_ to the URL of bookstack without without a trailing slash APP_URL=https://example.com\n    - APP_URL=http://xxx.xxxmydomainxxx.duckdns.org\n    volumes:\n    - $docker/public-uploads:/var/www/bookstack/public/uploads\n    - $docker/storage-uploads:/var/www/bookstack/storage/uploads\n    ports:\n    - \"6975:8080\"\n    restart: unless-stopped\n</code></pre> <p>Notice: The default password for bookstack is</p> <p>admin@admin.com</p> <p>password</p> <p>Permissions: remember the set write permission on public-uploads folder so users can upload photos.</p>"},{"location":"Docker%20Apps/bookstack/#backup-and-restore","title":"Backup and Restore","text":"<p>Files Backup:</p> <pre><code>tar -czvf bookstack-files-backup.tar.gz public-uploads storage-uploads\n</code></pre> <p>Restore:</p> <pre><code>tar -xvzf bookstack-files-backup.tar.gz\n</code></pre> <p>Database backup:</p> <pre><code>sudo docker exec bookstack_mysql_1 /usr/bin/mysqldump -u root --password=secret bookstack &gt; ./bookstack/bookstack_db.sql\n</code></pre> <p>Restore:</p> <pre><code>sudo docker exec -i bookstack_mysql_1 mysql -u root --password=secret bookstack &lt; /$docker/bookstack/bookstack_db.sql\n</code></pre> <ul> <li>bookstack_mysql1 is the container name</li> <li>password is secret or the database password</li> </ul>"},{"location":"Docker%20Apps/bookstack/#reverse-proxy","title":"Reverse Proxy","text":"<p>Use subdomain in proxy manager.</p> <p>Backing Up and Restoring with LinuxServer.io container</p> <p>Due to limits or Oracle Cloud free tier. The only arm image is from linuxserver io container, and it is different than solidnerd image.</p> <p>Docker-Compose file</p> <pre><code>version: \"2\"\nservices:\n  bookstack:\n    image: lscr.io/linuxserver/bookstack\n    container_name: bookstack\n    environment:\n\n      - PUID=1001\n      - PGID=1001\n      - APP_URL=https://wiki.xxx.duckdns.org\n      - DB_HOST=bookstack_db\n      - DB_USER=bookstack\n      - DB_PASS=secret\n      - DB_DATABASE=bookstackapp\n    volumes:\n      - /home/ubuntu/bookstack:/config\n    ports:\n      - 6975:80\n    restart: unless-stopped\n    depends_on:\n      - bookstack_db\n\n  bookstack_db:\n    image: lscr.io/linuxserver/mariadb\n    container_name: bookstack_db\n    environment:\n\n      - PUID=1001\n      - PGID=1001\n      - MYSQL_ROOT_PASSWORD=secret\n      - TZ=Europe/London\n      - MYSQL_DATABASE=bookstackapp\n      - MYSQL_USER=bookstack\n      - MYSQL_PASSWORD=secret\n    volumes:\n      - /home/ubuntu/bookstack:/config\n    restart: unless-stopped\n</code></pre> <p>Notice: In Oracle cloud free tier, the default ubuntu user is 1001, not 1000. For database name, it it bookstackapp, keep in mind when executing restore command. The folder structure is also different. In the solidnerd container, the images are stored at /public-uploads while in LSIO container it is stored at /www/uploads</p>"},{"location":"Docker%20Apps/bookstack/#backing-up-from-home-pc","title":"Backing Up (from home PC)","text":"<p>Images</p> <p>cd into /public-uploads and make a tar archive</p> <pre><code>tar -czvf images.tar.gz images\n</code></pre> <p>Backup the database</p> <pre><code>sudo docker exec bookstack_mysql_1 /usr/bin/mysqldump -u root --password=secret bookstack &gt; ./bookstack_db.sql\n</code></pre> <p>Transfer to Oracle Cloud Server</p> <pre><code>scp -i oracle-arm-2.key images.tar.gz bookstack_db.sql ubuntu@$IPADDR:/home/ubuntu/bookstack/www/uploads\n</code></pre> <p>Take in consideration the location where LSIO image stores the images.</p>"},{"location":"Docker%20Apps/bookstack/#restore-into-oracle-cloud","title":"Restore (into Oracle Cloud)","text":"<p>Images (/home/ubuntu/bookstack/www/uploads)</p> <pre><code>tar -xvzf images.tar.gz\n</code></pre> <p>Database</p> <p>The image url in the database still refers to old server url, it needs to be changed. The following command replace the subdomain in the sq1 dump.</p> <pre><code>sed -i 's/wiki.$home.duckdns.org/wiki.$oracle.duckdns.org/g' bookstack_db.sql\n</code></pre> <p>Restore the database.</p> <pre><code>sudo docker exec -i bookstack_db mysql -u root --password=secret bookstackapp &lt; /home/ubuntu/bookstack/www/uploads/bookstack_db.sql\n</code></pre>"},{"location":"Docker%20Apps/bookstack/#crontab","title":"Crontab","text":"<p>On Home PC</p> <pre><code>0 23 * * 2,5 /home/karis/bookstack.sh\n</code></pre> <pre><code>#!/bin/bash\n\ncd ~/docker/bookstack/public-uploads #location of bookstack public uploads\ntar -czvf images.tar.gz images\nsudo docker exec bookstack_mysql_1 /usr/bin/mysqldump -u root --password=secret bookstack &gt; ./bookstack_db.sql\nscp -i oracle-arm-2.key images.tar.gz bookstack_db.sql ubuntu@$ORACLEIP:/home/ubuntu/bookstack/www/uploads\n</code></pre> <p>Make sure to copy the oracle-arm-2.key to the appropriate location (~/docker/bookstack/public-uploads)</p> <p>Also make sure the permission of oracle-arm-2.key is in correct permission (600). Especially changing the permission of public-uploads folder to allow write access.</p> <p>Do a backup sequence in crontab at 11pm every Tuesday and Friday.</p> <p>Oracle Cloud Server</p> <pre><code>0 8 * * 3,6 /home/ubuntu/bookstack.sh\n</code></pre> <pre><code>#!/bin/bash\n\ncd ~/bookstack/www/uploads #directory where bookstack files scp from home are located\ntar -xvzf images.tar.gz\nsed -i 's/wiki.$homeip.duckdns.org/wiki.$oracle.duckdns.org/g' bookstack_db.sql\nsudo docker exec -i bookstack_db mysql -u root --password=secret bookstackapp &lt; /home/ubuntu/bookstack/www/uploads/bookstack_db.sql\n</code></pre> <p>Restore the sequence after backup, every Wednesday and Saturday at 8am (need to consider the TZ between Vancouver, Edmonton and Toronto, or any the time zone of the remote server)</p>"},{"location":"Docker%20Apps/ddns-update/","title":"Dynamic DNS Updater Docker","text":"<p>Official Image: https://hub.docker.com/r/linuxserver/duckdns Custom Github Page: https://github.com/vttc08/docker-duckdns-dynu</p> <p>This is a docker container that automatically updates the public IPv4 address of the server every 5 minutes to dynamic DNS services Dynu and DuckDNS. It is the fork of Linuxserver DuckDNS container.</p>"},{"location":"Docker%20Apps/ddns-update/#docker-compose","title":"Docker Compose","text":"<pre><code>  services:\n      duckdns:\n        image: vttc08/docker-duckdns-dynu:latest\n        container_name: duckdns\n        env_file: ddns.env\n        environment:\n\n          - TZ=America/Vancouver\n          - PUID=1000\n          - PGID=1001\n        restart: unless-stopped\n</code></pre> <p>These need to be filled in the <code>ddns.env</code> <pre><code>DYNU_HOST= # full name of dynu domains\nDYNU_PASS= # md5 hashed dynu login pass\nSUBDOMAINS= # DuckDNS domains without the duckdns.org part\nTOKEN= # DuckDNS token \n</code></pre></p> <ul> <li>token will be visible in DuckDNS dashboard</li> <li>Dynu pass is the same as login; alternatively, it is possible to create a dedicated password  just for IP update  MD5 generator <pre><code>echo -n \"password\" | md5sum\n</code></pre></li> <li>when setting the IP to <code>10.0.0.0</code> in Dynu update API, dynu will automatically update the IP address to the IP address making that request</li> </ul>"},{"location":"Docker%20Apps/ddns-update/#other-usage","title":"Other Usage","text":"<p><code>docker restart duckdns</code> will manually run IP update <code>docker exec -it duckdns /app/debug.sh</code> or other scripts, debug script will print out IP address of subdomains resolved by Cloudflare</p>"},{"location":"Docker%20Apps/epic-games-free-games/","title":"Epic Games Free Games","text":"<p>Buy Free Games from Epic Games</p> <p>https://hub.docker.com/r/charlocharlie/epicgames-freegames</p> <p>Config</p> <p>NEED TO CHANGE</p> <p>Email: email address</p> <p>Password: password</p> <p>Webhook URL: make a discord channel and click settings. Go to integrations, then webhook, copy webhook URL.</p> <p>mentioned Users: right click your profile, and click Copy ID</p> <p>TOTP</p> <ol> <li>Go here to login. https://www.epicgames.com/account/password Login with Epic Games account.</li> <li>Click \u201cenable authenticator app.\u201d</li> <li>In the section labeled \u201cmanual entry key,\u201d copy the key.</li> <li>Use your authenticator app to add scan the QR code.</li> <li>Activate 2FA by completing the form and clicking activate.</li> <li>Once 2FA is enabled, use the key you copied as the value for the TOTP parameter.</li> </ol> <p>Docker</p> <pre><code>docker run -d -v /home/karis/docker/epicgames:/usr/app/config:rw -p 3000:3000 -m 2g --name epicgames --restart unless-stopped charlocharlie/epicgames-freegames:latest\n</code></pre> <p>Change the name of the container to a friendly name. Restart unless stopped so it restart automatically.</p> <p>Copy and Paste</p> <p>The default json configuration is located at /home/karis/docker/epicgames or $HOME/docker/epicgames.</p> <p>Fix Login Issue Using Cookies</p> <p>https://store.epicgames.com/en-US/</p> <ol> <li>Visit this site and make sure it\u2019s logged in.</li> <li>Install this extension EditThisCookie https://chrome.google.com/webstore/detail/editthiscookie/fngmhnnpilhplaeedifhccceomclgfbg/related</li> <li>Open the extension and change the url to epicgames.com/id as in screenshot below</li> <li>Export the cookie</li> </ol> <p></p> <ol> <li>Go to $HOME/docker/epicgames and create a new file email@gmail.com-cookies.json</li> <li>If the json file is already there, truncate it with \u2013size 0</li> <li>Paste the cookie value to the json file</li> <li>Restart container.</li> </ol> <p>Update</p> <pre><code>docker pull charlocharlie/epicgames-freegames:latest\ndocker rm -f epicgames\ndocker images | grep epicgames\n# use docker rmi to remote the corresponding image \n# re run the epicgames docker run command\n</code></pre>"},{"location":"Docker%20Apps/filebrowser/","title":"Filebrowser","text":"<p>Filebrowser app on a webbrowser, port 4455. free-games-claimer</p> <p>Docker-compose deployment</p> <pre><code>version: '3.9'\nservices:\n    filebrowser:\n        container_name: filebrowser\n        image: filebrowser/filebrowser\n        ports:\n\n            - '4455:80'\n        user: 1000:1000\n        restart: unless-stopped\n        volumes:\n            - '~/docker/filebrowser/.filebrowser.json:/.filebrowser.json'\n            - '~/docker/filebrowser/filebrowser.db:/database.db'\n            - '~/docker/filebrowser/branding:/branding'\n            - '~/docker:/srv/docker'\n            - '/mnt/data:/srv/data'\n            - '/mnt/nvme/share:/srv/nvme-share'\n</code></pre> <p>The first 3 bind mount are for configuration of filebrowser, eg. config, database and branding files. On first deployment, need to create an empty database.db file. The remaining bind mount are for the folders that need to be accessed, the folders should be bound under /srv.</p> <p>This is the content of <code>.filebrowser.json</code></p> <pre><code>{\n    \"port\": 80,\n    \"baseURL\": \"\",\n    \"address\": \"\",\n    \"log\": \"stdout\",\n    \"database\": \"/database.db\",\n    \"root\": \"/srv\"\n  }\n</code></pre>"},{"location":"Docker%20Apps/filebrowser/#usershare","title":"User/Share","text":"<p>The user and share management in filebrowser is simple. The shares have a expiring time, and can optionally have a password. The recipient can view and download files in the share but cannot upload.</p> <p>To create a new user, it\u2019s under settings -&gt; User Management, and add a user and password accordingly, and give appropriate permission. The scope is where the root folder where the user have access to, since the docker data folder is bound at /srv/docker and /srv is defined as root folder in config, the folder name to put in scopes would be <code>/docker</code>. Only one scope is allowed.</p> <p></p> <p>It is also possible to add rules to prevent user access of files within a scope. Under rules, enter the path that is relative to the scope, for example /docker/minecraft/config would be <code>/config</code></p> <p></p>"},{"location":"Docker%20Apps/filebrowser/#personalization","title":"Personalization","text":"<p>Enable dark theme - Setting -&gt; Global Settings -&gt; Branding</p> <ul> <li>also change the branding directory path to /branding which is bind mount in docker</li> </ul> <p>Under the branding folder, create a file <code>custom.css</code>which is used for css customization. Then create a folder img and place logo.svg in it for custom icon. The icon is the same as egow entertainment and stored in OliveTin icon PSD file. Under the folder img, create a folder icons and use favicon generator site to create an icon archive and put all the content of that archive in the icons folder, the result should look like this.</p> <p></p> <p>Reverse Proxy/Homepage</p> <p>Reverse proxy is normal procedure using NPM. To add bookmark to a file location, use browser/homepages bookmark function.</p>"},{"location":"Docker%20Apps/free-games-claimer/","title":"Free Games Claimer","text":"<p>https://github.com/vogler/free-games-claimer</p> <p>This is the Github repo for the new and advanced free games claimer. This is implemented after Epicgames FreeGames keeps failing.</p>"},{"location":"Docker%20Apps/free-games-claimer/#configuration","title":"Configuration","text":"<p>Using Docker-Compose</p> <p>In the folder structure</p> <pre><code>server: ~/docker/fgc$\ndocker-compose.yml\nfgc.env\n</code></pre> <p>fgc.env is the environment file for all the password/keys to login to different game services, fill it in manually or use a backup.</p> <pre><code>EG_OTPKEY=\nEG_EMAIL=\nEG_PASSWORD=\nNOTIFY=discord://123456/ABCD\nPG_EMAIL=\nPG_PASSWORD=\nGOG_EMAIL=\nGOG_PASSWORD=\nTIMEOUT=300\n</code></pre> <p><code>NOTIFY=discord://123456/ABCD</code> if the webhook looks like this <code>https://discord.com/api/webhooks/123456/ABCD</code></p> <p><code>TIMEOUT=300</code> sets the timeout to 300s before the container skip and error out due to EpicGames captcha problems. However, the impact on prime gaming and GOG are not tested.</p> <p>docker-compose.yml</p> <pre><code>services:\n  free-games-claimer:\n    container_name: FGC # is printed in front of every output line\n    image: ghcr.io/vogler/free-games-claimer # otherwise image name will be free-games-claimer-free-games-claimer\n    build: .\n    ports:\n\n      - \"5990:5900\" # VNC server\n      - \"5890:6080\" # noVNC (browser-based VNC client)\n    volumes:\n      - ~/docker/fgc:/fgc/data\n      - ~/docker/fgc/epic-games.js:/fgc/epic-games.js\n      - ~/docker/fgc/prime-gaming.js:/fgc/prime-gaming.js\n      - ~/docker/fgc/gog.js:/fgc/gog.js\n    command: bash -c \"node epic-games; node prime-gaming; node gog; echo sleeping; sleep 1d\"\n    env_file:\n      - fgc.env\n    restart: unless-stopped\n</code></pre> <p>This docker-compose file use the environment file fgc.env as indicated above and runs once every day. It also contains VNC server/web based client.</p>"},{"location":"Docker%20Apps/free-games-claimer/#missing-captcha-session","title":"Missing Captcha Session","text":"<p>This should no longer be needed. Edit the line to epicgames.js code and replace with the following message. When the captcha is missed, it will send a notification for manual claiming.</p> <pre><code>wait notify(`epic-games: got captcha challenge right before claim. Use VNC to solve it manually. Game link: \\n ${url}`)\n</code></pre> <p>EpicGames require a captcha to claim free games. If the 5 minute timeout window for EpicGames is missed, it is no longer possible to claim the games unless waiting for the next day, which due to the nature of discord notifications, there is a slim to none chance of catching the captcha at next day. To continuing claiming after acknowledging the missed session, use portainer, ConnectBot Android to temporarily restart the container to restore VNC session.</p> <p>In order to restore the default time of claiming the games. Eg. waking up on Thurs or Fri and a predictable time and claim games, use the linux at command. Need to install <code>at</code> using <code>apt</code>. <pre><code>at 9:20\n&gt; docker restart FGC\n&gt; &lt;EOT&gt;\n</code></pre></p> <p>This will run the command at 9:20 AM the next day. Ctrl-D to exit at prompt and verify the time is correct.</p>"},{"location":"Docker%20Apps/jlesage-vnc-apps/","title":"jlesage VNC Apps","text":"<p>VNC apps consists of desktop applications that have the GUI in a web browser, mostly from the creator jlesage.</p>"},{"location":"Docker%20Apps/jlesage-vnc-apps/#environments","title":"Environments","text":"<p>At least for apps from jlesage, it supports an environment variable. Create an environment file called <code>vnc.env</code></p> <p>The environment file can be reference in many docker images from jlesage using docker-compose. The current environment variable specify U/GID, time zone and make every app dark mode. It is also possible to set VNC passwords. This is the full list of environment variables.</p> <pre><code>USER_ID=1000\nGROUP_ID=1001\nTZ=America/Vancouver\nDARK_MODE=1\n</code></pre> <p>The jlesage apps have 2 ports, port 5800 for viewing the VNC app on a web browser on desktop; port 5900 is for VNC protocol that can be used in dedicated VNC viewer or mobile viewing.</p>"},{"location":"Docker%20Apps/jlesage-vnc-apps/#general-bind-mounts","title":"General Bind Mounts","text":"<p>The appdata bind mount is located in the <code>~/docker/vnc</code>, as seen from the yml example, the vnc environment file <code>vnc.env</code> is placed in the appdata folder. For application requiring access to movie storage, the bind mount is on the corresponding hard drive or pool. As for applications requiring access to storage but not large media, it\u2019s best to put the files on a SSD.</p> <p>This is an example of VNC container of MKVToolNix. The vnc.yml file is backed up elsewhere.</p> <pre><code>    mkvtoolnix:\n        image: jlesage/mkvtoolnix\n        env_file:\n\n            - ./vnc/vnc.env\n        volumes:\n            - '/mnt/data/nzbget:/storage:rw'\n            - '~/docker/vnc/mkvtoolnix:/config:rw'\n        ports:\n            - '5820:5800'\n            - '5920:5900'\n        container_name: mkvtoolnix\n</code></pre>"},{"location":"Docker%20Apps/jlesage-vnc-apps/#ports","title":"Ports","text":"<p>The application port start from 5800/5900 for its corresponding access and add 10 for each application.</p> <p>JDownloader: 5800</p> <p>Firefox: 5810</p> <p>MKVToolNix: 5820</p> <p>MKVCleaver: 5840</p> <ul> <li>it\u2019s best to use this app on-demand due to phantom CPU usage</li> </ul> <p>MegaBasterd: 5860 (no VNC viewer 59xx port)</p> <ul> <li>this app require special configuration that is documented here</li> <li>use the <code>VERSION</code> to download the correct binary</li> </ul> <p>MCASelector: 5870</p> <ul> <li>this app require special configuration that is documented here</li> <li>it\u2019s best to use the app on-demand due to phantom CPU usage and high RAM usage</li> </ul> <p>There are also some application specific setup. For applications accessing hard drive or intensive apps, it is best to stop when not used. Lazytainer and ContainerNursery and possibly using DNS server can help automate this process.</p> <p>JDownloader JDownloader Setup</p>"},{"location":"Docker%20Apps/tesla-homepage/","title":"Tesla Homepage","text":"<p>This is a homepage that allows Tesla browser to enter full screen mode.</p> <p>Docker-compose</p> <pre><code>services:\n  homepage-for-tesla:\n    image: jessewebdotcom/homepage-for-tesla:latest\n    container_name: homepage-for-tesla\n    environment:\n\n      - DEFAULT_THEME=13\n    volumes:\n      - ~/docker/tesla/public/bookmarks.json:/app/public/bookmarks.json\n      - ~/docker/tesla/public/images:/app/public/images\n    ports:\n      - \"3000:3000\"\n</code></pre>"},{"location":"Docker%20Apps/webtop/","title":"Webtop (openbox-ubuntu)","text":"<pre><code>version: \"2.1\"\nservices:\n  webtop:\n    image: lscr.io/linuxserver/webtop:amd64-ubuntu-openbox\n    container_name: webtop-openbox\n    security_opt:\n\n      - seccomp:unconfined #optional\n    environment:\n      - PUID=1000\n      - PGID=1001\n      - TZ=America/Vancouver\n      - SUBFOLDER=/ # For reverse proxy\n      - TITLE=WebtopMate # The title as it shown in browser\n    volumes:\n      - ~/docker/webtop/config:/config # default home folder\n      - /mnt/data:/mnt/data\n      - /var/run/docker.sock:/var/run/docker.sock # Run docker inside docker\n    ports:\n      - 3050:3000\n    shm_size: \"1gb\" #optional\n    restart: unless-stopped\n</code></pre> <p>The default installation with config folder copied is not usable. Packages to be installed <pre><code>apt update\napt install wget terminator rsync ntp spacefm compton tint2 nitrogen nano lxappearance mousepad unrar unzip xarchiver mono-complete libhunspell-dev p7zip libmpv-dev tesseract-ocr vlc ffmpeg fonts-wqy-zenhei language-pack-zh-hans mediainfo mediainfo-gui p7zip\n</code></pre></p> <p>Packages that has to be installed manually <code>lxappearance, spacefm, tint2, nitrogen</code></p> <p>Desktop (tint2, nitrogen)</p> <ul> <li>nitrogen cannot keep <code>scaled</code> option after restarting and needs to change it manually</li> <li>nitrogen wallpaper are found in <code>/config/Pictures/wallpaper.jpg</code></li> </ul>"},{"location":"Docker%20Apps/webtop/#customization","title":"Customization","text":"<p>lxappearance</p> <ul> <li>theme: <code>Quixotic-blue</code>; location <code>.themes</code></li> <li>icon: <code>Desert-Dark-icons</code>; location <code>.icons</code> tint2</li> <li>tint2 with copied config, located in <code>.config/tint2</code></li> </ul>"},{"location":"Docker%20Apps/webtop/#firefox-browser","title":"Firefox Browser","text":"<p>policies.json <pre><code>// force install ublock, disable annoyances, add bookmarks\n{\n  \"policies\": {\n    \"ExtensionSettings\": {\n      \"uBlock0@raymondhill.net\": {\n        \"installation_mode\": \"force_installed\",\n        \"install_url\": \"https://addons.mozilla.org/firefox/downloads/latest/ublock-origin/latest.xpi\"\n      }\n    },\n    \"NoDefaultBookmarks\": true,\n    \"DisableTelemetry\": true,\n    \"Bookmarks\": [\n      {\n        \"Title\": \"zmk\",\n        \"URL\": \"https://zmk.pw\",\n        \"Placement\": \"toolbar\"\n      },\n      {\n        \"Title\": \"SubHD\",\n        \"URL\": \"https://subhd.tv\",\n        \"Placement\": \"toolbar\"\n      } // Add more bookmarks like this\n    ],\n    \"FirefoxHome\": {\n      \"Search\": true,\n      \"TopSites\": true,\n      \"SponsoredTopSites\": false,\n      \"Pocket\": false,\n      \"SponsoredPocket\": false,\n      \"Locked\": false\n    }\n  }\n}\n</code></pre></p> <ul> <li>it is not possible to backup bookmarks on the pinned menu via policies (only way is to restore from home folder)</li> <li>it\u2019s not possible to remove <code>import bookmarks</code> and <code>getting started</code> bookmarks with <code>policies.json</code> as documented here, it has to be removed manually Manual Configs</li> <li>ublock add Chinese filter</li> <li>pin bookmarks</li> <li>remove default bookmarks and getting started from toolbar</li> </ul>"},{"location":"Docker%20Apps/webtop/#files","title":"Files","text":"<p>SpaceFM</p> <ul> <li>upon installing, with config copied over, everything works fine</li> <li>configuration is stored in <code>~/.config/spacefm</code></li> </ul> <p>Movie-Renamer Script</p> <ul> <li>works after copying</li> </ul>"},{"location":"Docker%20Apps/webtop/#subtitles","title":"Subtitles","text":""},{"location":"Docker%20Apps/webtop/#subtitle-edit","title":"Subtitle Edit","text":"<p>Install dependencies Download subtitle-edit <pre><code>curl -s https://api.github.com/repos/SubtitleEdit/subtitleedit/releases/latest | grep -E \"browser_download_url.*SE[0-9]*\\.zip\" | cut -d : -f 2,3 | tr -d \\\" | wget -qi - -O SE.zip\nunzip SE.zip -d /config/subtitle-edit\n</code></pre> Subtitle-Edit Dark theme has to be changed manually</p> <ul> <li><code>Options</code> -&gt; <code>Settings</code> -&gt; <code>Appearance</code> -&gt; <code>Use Dark Theme</code></li> <li><code>Options</code> -&gt; <code>Settings</code> -&gt; <code>Syntax Coloring</code> -&gt; <code>Error color</code> and change to <code>27111D</code></li> <li><code>Options</code> -&gt; <code>Settings</code> -&gt; <code>Appearance</code> -&gt; <code>UI Font</code> -&gt; <code>General</code> and change to <code>WenQuanYi Zen Hei</code></li> </ul>"},{"location":"Docker%20Apps/Media%20Apps/audiobookshelf/","title":"Audiobookshelf","text":"<p>Audiobooks and podcasts. </p> <p>Docker-compose, place it in the media apps compose media.yml</p> <pre><code>version: \"3.7\"\nservices:\n  audiobookshelf:\n    image: ghcr.io/advplyr/audiobookshelf:latest\n    environment:\n\n      - AUDIOBOOKSHELF_UID=99\n      - AUDIOBOOKSHELF_GID=100\n    ports:\n      - 13378:80\n    volumes:\n      - /mnt/m/Audios/audiobooks:/audiobooks # hard drive mount\n      - /mnt/m/Audios/podcasts:/podcasts # hard drive mount\n      - $HOME/audiobookshelf/config:/config\n      - $HOME/audiobookshelf/metadata:/metadata\n    restart: unless-stopped\n</code></pre>"},{"location":"Docker%20Apps/Media%20Apps/audiobookshelf/#usage","title":"Usage","text":"<p>To add a library, go to settings, libraries and add the path as mounted in docker.</p> <p>Go to Users, change the root password and create a new user. Note, the user cannot scan library, only the root can do that.</p> <p></p>"},{"location":"Docker%20Apps/Media%20Apps/audiobookshelf/#adding-media","title":"Adding Media","text":"<p>Make sure the contents are in a separate folder. Follow naming like this. A cover image can also be created. The best bitrate should be under 128 kbps for smooth playback.</p> <pre><code>/audiobooks\n--- ./Author - Book\n---  --- ./cover.jpg\n---  --- ./book - 001 or book - chapter 1\n---  --- ./book - 002\n---  --- ./book - 003\n</code></pre> <p>In the WebUI, make sure logged in as root. Go to settings, library and scan. It will scan the newly added media.</p> <p>If the media does not match or not have an image, go click the edit icon, go to Match, the best result is usually Audible.ca.</p> <p></p> <p>If the chapter does not match, chapters can be edited manually. Go to Chapter and Lookup.</p>"},{"location":"Docker%20Apps/Media%20Apps/audiobookshelf/#mobile-app","title":"Mobile App","text":"<p>https://play.google.com/store/apps/details?id=com.audiobookshelf.app</p> <p>Mobile app also has download functionality, however, the directory cannot be changed, the default for download is /Internal Storage/Download/{Podcast or Audiobook}</p> <p>The statistic of minutes listened is the actual minutes listened, not the minutes of audiobook progress listened (eg. playing at faster speed).</p>"},{"location":"Docker%20Apps/Media%20Apps/audiobookshelf/#scripting-windows","title":"Scripting (Windows)","text":"<p>ffmpeg detect audio silence (for splitting a large audio file into multiple chapters)</p> <pre><code>ffmpeg -i input.mp3 -af silencedetect=n=-50dB:d=1.5 -f null -\n</code></pre> <pre><code>ffmpeg -i input.mp3 -af silencedetect=n=-50dB:d=1.5 -f null -loglevel debug 2&gt;&amp;1 - | findstr \"silence_duration\" | find /c /v \"\"\n</code></pre> <p>This will find silence parts below -50dB and duration threshold of 1.5s.</p> <p>The second code (windows cmd only) for linux use grep -c, finds how many silence parts can be detected, this should correlate to number of chapters.</p> <p>Once the optimal duration is set, use split.py.</p> <p>ffmpeg that remove silence from audio</p> <pre><code>ffmpeg -i input.mp4 -af silenceremove=stop_periods=-1:stop_duration=4:stop_threshold=-50dB -b:a 96k output.mp3\n</code></pre> <ul> <li>stop_duration (threshold duration for removing silence part)</li> <li>stop_periods = -1 (search for the entire audio track)</li> </ul> <p>Use edge_reader.py to utilize Edge AI reader to read the audiobook if only the pdf book is provided.</p> <p>After reading, put all the recorded files and pdf in the project folder and run processing.py twice.</p>"},{"location":"Docker%20Apps/Media%20Apps/rich-media/","title":"Rich Media","text":"<p>Hello Everyone</p> <p>This is a demo consisting of medias.</p> <p></p> <p>Some Code</p> <pre><code>docker-compose up -d\n</code></pre> <pre><code>import os\nimport time\n\nprint(\"hello world\")\nif a=b:\n  print(a)\nelif b=c:\n  try:\n    print(c)\n  except:\n    print(c+a)\nelse:\n  print(\"what is the meaning of life\")\n</code></pre> <p>More sample media</p> <p></p> <p>Portainer is a software for managing docker containers.</p>"},{"location":"Docker%20Apps/Minecraft/minecraft-prep-and-install/","title":"Minecraft Prep and Install","text":"<p>Client Setup (Java + Online)</p> <ol> <li>Download Java</li> <li>Download OptiFine the latest version.</li> <li>On the official Minecraft client, go add a new installation and match the version with OptiFine.</li> <li>Download and try the official version, then install OptiFine with Java.</li> <li>Under Settings -&gt; Keep the Launcher open while games are running</li> </ol> <p>Client Setup (Java + Offline)</p> <ol> <li>Use the client PolyMC to enable offline play.</li> <li>Go to the right corner, manage accounts and create an offline account.</li> <li>Click on add an instance and follow the guide.</li> <li>To install OptiFine, need the official launcher first, then download OptiFine</li> <li>Extract OptiFine, the extracted file should be ending in _MOD.jar</li> <li>Open the jar file in WinRAR, then move the files from notch folder into the base folder. Save the jar archive.</li> <li>Go to PolyMC, right click on the instance, click Edit -&gt; Versions -&gt; Add to minecraft.jar and select the modified OptiFine.</li> </ol> <p>Docker Server Setup</p> <p>Docker-compose for minecraft server</p> <pre><code>version: \"3.9\"\nservices:\n  minecraft:\n    image: marctv/minecraft-papermc-server:latest\n    restart: unless-stopped\n    container_name: mcserver\n    environment:\n\n      - MEMORYSIZE=4G\n      - PAPERMC_FLAGS=\"\"\n      - PUID=1000\n      - PGID=1000\n    volumes:\n      - ~/docker/minecraft:/data:rw\n    ports:\n      - 25565:25565\n      - 19132:19132\n    stdin_open: true\n    tty: true\n</code></pre> <p>This downloads the latest version of Minecraft, to use another PaperMC version, need to build the image from scratch.</p> <p>Warning: PaperMC cannot be downgraded, only newer version of PaperMC can be installed after first run.</p> <pre><code>git clone https://github.com/mtoensing/Docker-Minecraft-PaperMC-Server\n# go edit the \"ARG version=1.xx.x\" to the correct version\ndocker build -t marctv/mcserver:1.xx.x\n</code></pre> <p>Folders and Plugins</p> <p>Plugins are located in folder <code>./plugins</code> some plugins have .yml files. To update or download plugins, use scp, wget on the server or VSCode.</p> <p>The <code>world</code> folder consists of the save data. It is separated into world, nether, the_end.</p> <p>Before starting the server, the <code>eula.txt</code> must have eula=true.</p> <p><code>bukkit</code> and <code>spigot.yml</code> in the root folder are configuration files for PaperMC.</p> <p>Rcon Commands</p> <p>To access the rcon-cli, use <code>docker attach mcserver</code>, to exit, use Ctrl-P and Q, if using VSCode may need to edit keyboard shortcut.</p> <p>Editing VSCode Shortcut</p> <p>Press <code>Ctrl-Shift-P</code> and search for keyboard shortcut json.</p> <pre><code>[\n    {\n        \"key\": \"ctrl+p\",\n        \"command\": \"ctrl+p\",\n        \"when\": \"terminalFocus\"\n    },\n\n    {\n        \"key\": \"ctrl+q\",\n        \"command\": \"ctrl+q\",\n        \"when\": \"terminalFocus\"\n    },\n\n    {\n        \"key\": \"ctrl+e\",\n        \"command\": \"ctrl+e\",\n        \"when\": \"terminalFocus\"\n    }\n\n]\n</code></pre>"},{"location":"Docker%20Apps/Minecraft/useful-plugins/","title":"Useful Plugins","text":"<p>WorldEdit</p> <p>EssentialX</p> <p>CoreProtect</p> <p>ViaVersions - allow other similar version to join the server without conflict</p> <p>Offline Mode/Mobile Bedrock</p> <p>To allow offline play for PC version. Change <code>server.properties</code> and edit these lines</p> <pre><code>enforce-whitelist=false\nonline-mode=false\n</code></pre> <p>Refer to  Minecraft Prep and Install to install offline client.</p> <p>For bedrock compatibility, need the geyser plugin.</p> <p>Geyser</p> <p>To allows offline play for bedrock mobile version. Go to <code>./plugins/Geyser-Spigot/config.yml</code> and change these lines. Do not install the plugin floodgate, if it\u2019s installed, removed the plugin. ViaVersions is also needed for mobile play.</p> <pre><code>auth-type: offline\nenable-proxy-connections: true\n</code></pre> <p>Now client can play without login to Xbox or Java.</p> <p>WorldGuard</p>"},{"location":"Linux%20Server/debian-based-server-setup/","title":"Debian-Based Server Setup","text":"<p>Run update and upgrade distro first. Install NTP package is there are errors with that. Reboot</p> <p>Setup powertop and powersaving features</p> <pre><code>sudo apt install powertop\npowertop --auto-tune\n</code></pre> <p>Powersave governor and at reboot. Remember to run the command again</p> <pre><code>@reboot echo \"powersave\" | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor &gt;/dev/null 2&gt;&amp;1\n</code></pre> <p>Ensure these packages are installedi</p> <pre><code>powertop htop iotop fio curl gnupg wget ntfs-3g neofetch ca-certificates lsb-release hdparm hd-idle openssh-server at\n</code></pre>"},{"location":"Linux%20Server/debian-based-server-setup/#hdd","title":"HDD","text":"<p><code>lsblk</code> and <code>blkid</code> to get the ntfs hard drive /dev name and the /dev/by-uuid/\u2026</p> <p>Edit the fstab to mount the drive, same entry for nvme drive</p> <pre><code>UUID=CC34294F34293E38 /mnt/data ntfs-3g 0 0\n</code></pre> <p>If the mounted device is HDD array, need to spindown disk with hdparm</p> <pre><code>hdparm -B 120 /dev/sdb # set the APM level\nhdparm -S 241 /dev/sdb\n</code></pre> <p>For the -S spindown, 0-240 is multiple of 5s, 241-255 is multiple of 30 min. The above command set spindown every 30min.</p> <p>If hdparm does not work, hd-idle can be used. Edit the file in <code>/etc/defaults/hd-idle</code></p> <pre><code>-i 60 -a disk/by-uuid/xxx -l /var/log/hd-idle.log\n</code></pre> <p>Sudo without password, go to visudo and add the lines to the bottom, replace $USER with the actual username.</p> <pre><code>$USER ALL=(ALL) NOPASSWD: ALL\n</code></pre> <p>Edit shortcuts in bashrc</p> <pre><code>source .bashrc\n</code></pre>"},{"location":"Linux%20Server/debian-based-server-setup/#openssh-with-keys","title":"OpenSSH with Keys","text":""},{"location":"Linux%20Server/debian-based-server-setup/#generate-the-key-using-the-terminal","title":"Generate the key using the terminal","text":"<pre><code>ssh-keygen\n</code></pre> <ul> <li>give a location to put the key pair</li> <li>this generate a public (.pub) and private key pair</li> </ul> <pre><code>ssh-copy-id -i key.pub username@server\n</code></pre> <ul> <li><code>key.pub</code> is the public key that was generated</li> </ul> <p>The key is ready to use for authorization.</p>"},{"location":"Linux%20Server/debian-based-server-setup/#generate-keys-using-putty-software","title":"Generate keys using PuTTY software","text":"<ol> <li>Copy the red part and use nano to add it in the server <code>~/.ssh/authorized_keys</code></li> <li>Make sure permissions are correct <pre><code>mkdir -p ~/.ssh\nchmod 700 ~/.ssh\nchmod 600 ~/.ssh/authorized_keys\nnano ~/.ssh/authorized_keys\n</code></pre></li> <li>Save private key as ppk file on the root ssh folder.</li> <li> <p>If the client with private key is Linux machine, need to change the permission of the private key.</p> <pre><code>chmod 600 private.key\n</code></pre> </li> <li> <p>Convert the private key Conversion &gt; Export OpenSSH Keys and save the file to a folder OpenSSH Keys</p> </li> </ol>"},{"location":"Linux%20Server/debian-based-server-setup/#ssh-config","title":"SSH Config","text":"<p>Configuration file for easy SSH access. The permission for that file is 644. <pre><code>Host server\n  HostName 10.10.120.1\n  User ubuntu\n  IdentityFile ~/keys/server.key\n</code></pre></p> <p>Use with OliveTin</p> <p>To have seamless ssh experience with OliveTin, make sure to copy the <code>ssh config</code> file and all the keys to <code>/root</code>, since in OliveTin <code>~</code> means <code>/root</code> not your user home directory.</p>"},{"location":"Linux%20Server/debian-based-server-setup/#setting-up-smb","title":"Setting Up SMB","text":"<p>Refer to Samba(SMB) Setup to setup SMB server.</p>"},{"location":"Linux%20Server/debian-based-server-setup/#desktop-environment-setup","title":"Desktop Environment Setup","text":""},{"location":"Linux%20Server/debian-based-server-setup/#firefox","title":"Firefox","text":"<p>The location of firefox profile is at /home/$USER/.mozilla/firefox/xxxxx.default</p> <p>Make a tarball and copy it and extract it in destination.</p> <p>In the profile folder, look for compatibility.ini, go to a random profile in the dest machine and copy the compatibility.ini settings to the one that is copied over. This ensure compatibility so that the new profile works without warning.</p> <p>Check the profile.ini with the name and the location of the new profile folder, firefox should be the same as before.</p> <pre><code>[Profile0]\nName=karis\nIsRelative=1\nPath=ims58kbd.default-esr-1\n</code></pre> <p>Themes</p> <p>To backup/restore settings of cinnamon</p> <p>Icons</p> <p>The icons are located at these locations.</p> <pre><code>/usr/share/icons\n~/.icons\n</code></pre> <p>Scripts</p> <p>Copy the scripts and put it into ~/script for organization and copy the old crontab for executing these scripts.</p>"},{"location":"Linux%20Server/olivetin/","title":"OliveTin","text":"<p>OliveTin exposes a webpage with buttons that execute shell command (eg. docker, scripts) on the server and allow others for easy access. It should be used internally only.</p> <p>Main Interface  Log Interface </p>"},{"location":"Linux%20Server/olivetin/#installation","title":"Installation","text":"<p>Download the correct file from this site. https://github.com/OliveTin/OliveTin/releases OliveTin_linux_amd64.deb</p> <p>Go to the directory and install the package.</p> <ul> <li>if a previous <code>config.yaml</code> is already present, installer will ask what to do, the default is to keep the previous config <pre><code>sudo dpkg -i OliveTin\u2026\u200bdeb\nsudo systemctl enable --now OliveTin\n</code></pre></li> </ul> <p>Uninstall <pre><code>sudo dpkg -r OliveTin # the installed app name, not the deb file\n</code></pre></p>"},{"location":"Linux%20Server/olivetin/#configuration","title":"Configuration","text":"<p>The configuration file is located at <code>/etc/OliveTin/config.yaml</code></p> Script Execution User <p>By default, OliveTin always execute script as root!! This have complications. With an example script that echo some location,  create a file in<code>/opt</code> dir owned by user 1000 and cd into <code>~/Downloads</code> user 1000\u2019s download dir.</p> default <p><code>/root/Downloads/</code> <code>line 7: cd: /root/Downloads: No such file or directory</code> The file created by the script is owned by root and not editable in VSCode or other editor unless using <code>sudo</code></p> as user 1000 <p><code>/home/test/Downloads/</code> The file created by the script is owned by user and can be freely edited.</p> <p>Run command as user user <code>sudo -u user /path/to/script</code>. </p> <ul> <li><code>~</code> path works as intended</li> <li>all files created and modified will be owned by user not root</li> <li><code>bashrc</code> variables do not work, to use environment variables, it must be sourced elsewhere</li> <li>by default, the script has a <code>$PWD</code> at <code>/root</code>, so relative path do not work regarding files</li> </ul> <p>Example Configuration <pre><code>listenAddressSingleHTTPFrontend: 0.0.0.0:1378 # set the port to 1378\n\n# Choose from INFO (default), WARN and DEBUG\nlogLevel: \"INFO\"\n\nactions:\n\n- title: Update Music\n  shell: /home/karis/scripts/script\n  icon: '&amp;#127925'\n  timeout: 2\n  hidden: true\n</code></pre> Configuration consists of list of actions, each action consist of <code>title</code>, <code>shell</code>, icon</p> <ul> <li><code>timeout</code> is also optional, the task will be killed if it takes longer (in seconds) to complete</li> <li><code>hidden</code> will hide it from dashboard<ul> <li>to unhide, a service restart is needed</li> </ul> </li> <li><code>maxConcurrent</code> optional, only allow x runs for the duration of the execution, any more will be blocked </li> <li>rateLimit more advance limiting<ul> <li>to clear a rate limit, OliveTin has to be restarted <pre><code>    maxRate:\n      - limit: 3\n        duration: 5m\n</code></pre></li> </ul> </li> </ul>"},{"location":"Linux%20Server/olivetin/#arguments","title":"Arguments","text":""},{"location":"Linux%20Server/olivetin/#textbox-input","title":"Textbox Input","text":"<pre><code>- title: Restart a Docker CT\n  icon: '&lt;img src = \"icons/restart.png\" width=\"48px\" /&gt;'\n  shell: docker restart {{ container }}\n  arguments:\n    - name: container\n      type: ascii\n</code></pre> <ul> <li>use <code>{{ }}</code> and give a variable</li> <li>under arguments type, assign a type for it, <code>ascii</code> only allows letters and numbers</li> </ul>"},{"location":"Linux%20Server/olivetin/#dropdown-choices","title":"Dropdown Choices","text":"<p><pre><code>- title: Manage Docker Stack Services\n  icon: \"&amp;#128736;\"\n  shell: docker-compose -f /home/karis/docker/bookstack/docker-compose.yml {{ action }}\n  arguments:\n    - name: action\n      choices:\n        - title: Start Stack\n          value: up -d\n        - title: Stop Stack\n          value: down\n</code></pre> This example give choices to start or stop a docker stack of a docker-compose file. If a argument is given the parameter choices, it will be in dropdown mode.</p>"},{"location":"Linux%20Server/olivetin/#suggestion","title":"Suggestion","text":"<p>Suggestion is a hybrid between dropdown and textbox. It will suggest the list of possible items in browser but do not restrict choices. <pre><code>  arguments:\n    - name: action\n      title: Action Name\n      suggestions:\n        - value: Information\n</code></pre></p> <ul> <li><code>value</code> is what is passed onto the shell and <code>Information</code> is a text display for clarification  After modifying configuration, it require a restart to clear out previous suggestions for browsers.</li> </ul>"},{"location":"Linux%20Server/olivetin/#execute-on-files-created-in-a-directory","title":"Execute on files created in a directory","text":"<p><pre><code>- title: Update Songs\n  icon: &lt;iconify-icon icon=\"mdi:music\"&gt;&lt;/iconify-icon&gt;\n  shell: /home/test/scripts/file.sh {{ filepath }}\n  arguments:\n    - name: filepath\n      type: unicode_identifier\n  execOnFileCreatedInDir: \n    - /home/test/Downloads/\n    - /another/folder\n</code></pre> Whenever a new file is created the action will execute.</p> <ul> <li><code>execOnFileCreatedInDir</code><ul> <li>it is possible to add multiple path to monitor; however, adding a path require a restart of OliveTin service</li> </ul> </li> <li>same principle as <code>Arguments</code>, whereas OliveTin provides predefined arguments for files. <code>filepath</code> is the full absolute path of the file that is created</li> </ul>"},{"location":"Linux%20Server/olivetin/#execution-feedback","title":"Execution Feedback","text":"<pre><code>- title: some action\n  popupOnstart: default, execution-dialog-stdout-only, execution-dialog, execution-button\n</code></pre> default stdout-only dialog button <ul> <li>popup dialog have an option to only show <code>stdout</code> or show full log output with exit code</li> <li>button will show how long the process take</li> <li>the design of popup box may not be easy to close, use the keyboard ++Esc++ key to close</li> </ul>"},{"location":"Linux%20Server/olivetin/#confirmation","title":"Confirmation","text":"<p>It is possible to have a confirmation before completing action. <pre><code>  arguments:\n\n    - type: confirmation\n      title: Click start to begin.\n</code></pre></p> <ul> <li>user must click a checkbox and then start before the action will execute</li> <li>API do not have such restrictions</li> </ul>"},{"location":"Linux%20Server/olivetin/#ssh-to-another-server","title":"SSH to Another Server","text":"<p>Since OliveTin by default runs command as root, it is necessary to copy the SSH <code>config</code> file and all the keys from a user\u2019s folder into <code>/root/.ssh</code></p> <ul> <li>if the permission is setup correctly for a user, the permissions will copy over</li> </ul> <p>On the first try, need to have this option when using SSH command <code>-o StrictHostChecking=no</code> and on the subsequent logins, ssh via ssh configs will work as normal.</p>"},{"location":"Linux%20Server/olivetin/#icons","title":"Icons","text":"<p>The icons need to be placed in a folder in /var/www/[icon-folder]/icon.png. To use the icons, offline image or web address, it should be in HTML format. The size of 48px is the default size of OliveTin icons. Other CSS options such as <code>style=\"background-color: white;\"</code> also works. <pre><code>icon: '&lt;img src = \"icons/minecraft.png\" size=\"48px\" /&gt;'\n</code></pre> Icon with emoji, to use emoji, need to use the html code. https://symbl.cc/en/emoji/ For example, <code>&amp;#9786;</code> \ud83d\ude0a. <pre><code>icon: \"&amp;#9786;\"\n</code></pre></p>"},{"location":"Linux%20Server/olivetin/#third-party","title":"Third-Party","text":"<p>Olivetin only support iconify icons. To use it, search for an icon, under <code>components</code> select <code>Iconify Icon</code>  Add the pasted line into the configuration. <pre><code>  - title: Title\n    icon: &lt;iconify-icon icon=\"openmoji:jellyfin\"&gt;&lt;/iconify-icon&gt;\n</code></pre></p>"},{"location":"Linux%20Server/olivetin/#icon-management","title":"Icon Management","text":"<p>The default icon folder is <code>/var/www/olivetin/icons</code> The icon folder of all homelab icons is in <code>~/icons/homelab</code></p>"},{"location":"Linux%20Server/olivetin/#api","title":"API","text":"<p>Simple action button. <pre><code>curl -X POST \"http://mediaserver:1378/api/StartAction\" -d '{\"actionId\": \"Update Music\"}'\n</code></pre> Action with Arguments. <pre><code>curl -X POST 'http://mediaserver:1378/api/StartAction' -d '{\"actionId\": \"Rename Movies\", \"arguments\": [{\"name\": \"location\", \"value\": \"value\"}]}'\n</code></pre></p> Arguments variable cannot be \u201cpath\u201d <p>If <code>path</code> is used as argument, when executing commands with arguments, it will replace the system <code>$PATH</code> variable, this will render most commands useless even basic ones like <code>sleep</code>, <code>date</code> etc. Use another variable such as <code>directory</code> or <code>location</code></p> Newest Olivetin Version Break Old API Method <p>The <code>actionName</code> key is deprecated and no longer works, newest Olivetin API only allow <code>actionId</code> for <code>StartAction</code> API endpoint. The scripts above are adjusted accordingly. To migrate, the easiest way it to create a ID in configuration that has the same value as action name. <pre><code>- title: action name\n- id: action name\n</code></pre></p>"},{"location":"Linux%20Server/olivetin/#dashboard","title":"Dashboard","text":"<p>Dashboard are a separate page from the default OliveTin page, Fieldsets and Folders are allowed to group actions only in dashboard.</p> <ul> <li>when an action is in dashboards, it does not appear in main view.</li> <li>when refreshing the page, it will always go back to main view even if the page is currently at a dashboard <pre><code>dashboards:\n  - title: My Dashboard\n    contents:\n      - title: Title Desc\n        type: fieldset\n        contents:\n          - title: Fix Epic Games\n          - title: Restart Minecraft\n      - title: Update Metadata\n        type: fieldset\n        contents:\n          - title: Stuff\n            icon: '&lt;img src = \"icons/mcrestart.png\" width=\"64px\" /&gt;'\n            contents:\n               - title: Update Songs\n</code></pre></li> </ul> Preview <p></p>"},{"location":"Linux%20Server/olivetin/#fieldsets","title":"Fieldsets","text":"<p>Fieldsets are group of actions under a title. Any <code>title</code> that has <code>type: fieldset</code> defined is a fieldset, any actions are grouped under <code>contents</code> key and need to have matching title.</p>"},{"location":"Linux%20Server/olivetin/#folders","title":"Folders","text":"<p>Folders also group actions together in a dashboard and user need to click into the folder to see the actions.</p> <ul> <li>it is possible to use custom icons or title for folders as long as <code>type:</code> is not set and it has <code>contents:</code></li> </ul>"},{"location":"Linux%20Server/olivetin/#entities","title":"Entities","text":"<p>To use entities, an action, a dashboard entry, entities json/yaml file and entity update method is needed (when the action interact with the entity).</p> Preview of Entities Flowchart <p></p>"},{"location":"Linux%20Server/olivetin/#entities-file","title":"entities-file","text":"<p>It\u2019s  possible to use json or  YAML <pre><code>entities:\n  - file: /etc/OliveTin/entities/containers.json\n    name: container\n</code></pre></p> <ul> <li>entities file are stored in <code>/etc/OliveTin/entities</code></li> <li>the name of the entity will be reference as <code>container.attributes</code> in configuration</li> </ul>"},{"location":"Linux%20Server/olivetin/#entity-update","title":"entity update","text":"<pre><code>- title: Update container entity file\n  shell: 'docker ps -a --format \"{{ json . }}\" &gt; /etc/OliveTin/entities/entity.json\n  hidden: true\n  execOnStartup: true\n  execOnCron: '*/5 * * * *'\n</code></pre> <ul> <li>this is an action that is trigger by other actions that need to modify the entity, the purpose is to update the entity file</li> </ul>"},{"location":"Linux%20Server/olivetin/#entity-actions","title":"entity-actions","text":"<pre><code>- title: Check {{ container.Names }} Status\n  shell: echo {{ container.Status }}\n  entity: container\n  trigger: Update container entity file\n</code></pre> <p>The entity action is defined the same way as other actions.</p> <ul> <li><code>entity</code> need to be defined</li> <li><code>trigger</code> automatically update entity attributes (since executing this actions could change some attribute of an entity like starting a container)</li> <li>both title and shell can use <code>entity.attributes</code></li> </ul>"},{"location":"Linux%20Server/olivetin/#dashboard-entry","title":"dashboard-entry","text":"<pre><code> - title: CPanel\n    contents:\n      - title: 'Container {{ container.Names }} ({{ container.Image }})'\n        entity: container\n        type: fieldset\n        contents:\n          - type: display\n            title: |\n              {{ container.Status }} &lt;br /&gt;&lt;br /&gt;&lt;strong&gt;{{ container.State }}&lt;&gt;\n          - title: 'Check {{ container.Names }} Status'\n</code></pre> Preview <ul> <li>dashboard is the same configuration as in previous but now is able to utilize entities. </li> </ul>"},{"location":"Linux%20Server/sambasmb-setup/","title":"Samba(SMB) Setup","text":""},{"location":"Linux%20Server/sambasmb-setup/#setting-up-smb-server-on-linux","title":"Setting up SMB Server on Linux","text":"<p>Install the samba tool on Linux.</p> <pre><code>sudo apt update\nsudo apt install samba -y\n</code></pre> <p>Edit the <code>/etc/samba/smb.conf</code></p> <pre><code>[nvme_share]\n   comment = NVMe Share\n   path = /mnt/nvme/share\n   browseable = yes\n   read only = no\n</code></pre> <p><code>nvme_share</code> is the name of the Samba path which will appear in SMB clients and its path is accessed by <code>\\\\192.168.0.1\\nvme_share</code></p> <p></p> <p><code>path</code> is the location where the files are stored</p> <p><code>browseable</code> and <code>read only</code> are flags that are needed to make sure read/write access on the SMB share</p> <p>Lastly, add the user and password for the SMB share</p> <pre><code>sudo smbpasswd -a $USER # enter the password twice\n</code></pre> <p>In the case when Windows fail to write files in the samba share for odd reason. Go to <code>Manage Credentials</code> -&gt; <code>Windows Credentials</code> -&gt; <code>Add a Windows Credential</code> and fill the necessary address, username and password.</p>"}]}